{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "correct-saskatchewan",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "exact-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Ref=pd.read_csv('Ref.csv')\n",
    "Ref[\"CO\"] = 1000 * Ref[\"CO\"]\n",
    "Ref['Date'] = pd.to_datetime(Ref['Date_Time'])\n",
    "Ref=Ref.set_index('Date')\n",
    "Ref.drop('Date_Time',axis = 1, inplace = True)\n",
    "Ref=Ref.resample('5min').mean()\n",
    "Ref=Ref[76463:137376]\n",
    "Ref_CO=Ref['CO'].to_list()\n",
    "Ref_NO2=Ref['NO2'].to_list()\n",
    "Ref_SO2=Ref['SO2'].to_list()\n",
    "Ref_O3=Ref['O3'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "excellent-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(df_in, col_name):\n",
    "    q1 = df_in[col_name].quantile(0.25)\n",
    "    q3 = df_in[col_name].quantile(0.75)\n",
    "    iqr = q3-q1 #Interquartile range\n",
    "    fence_low  = q1-1.5*iqr\n",
    "    fence_high = q3+1.5*iqr\n",
    "    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-subscriber",
   "metadata": {},
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('CO.txt', header = None,low_memory=False)\n",
    "data.columns=['WE','AE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_CO=data\n",
    "Data_CO['Ref']=Ref_CO\n",
    "WE=Data_CO['WE'].to_list()\n",
    "AE=Data_CO['AE'].to_list()\n",
    "\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_CO['Net Signal']=signal\n",
    "Data_CO['Month']=Data_CO.index.month\n",
    "Data_CO['Day_of_week']=Data_CO.index.dayofweek\n",
    "Data_CO['Day']=Data_CO.index.day\n",
    "Data_CO['Hour']=Data_CO.index.hour\n",
    "CO_Data=Data_CO\n",
    "CO_Data=CO_Data[(CO_Data[CO_Data.columns] >= 0).all(axis=1)]\n",
    "CO_Data=CO_Data.dropna()\n",
    "data = pd.read_csv('Conc_CO.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab1','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_CO=data\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_CO['Net Signal']=signal\n",
    "Data_CO['Month']=Data_CO.index.month\n",
    "Data_CO['Day_of_week']=Data_CO.index.dayofweek\n",
    "Data_CO['Day']=Data_CO.index.day\n",
    "Data_CO['Hour']=Data_CO.index.hour\n",
    "CO_Data=Data_CO\n",
    "CO_Data=CO_Data.resample('5min').mean()\n",
    "CO_Data=CO_Data[(CO_Data[CO_Data.columns] >= 0).all(axis=1)]\n",
    "CO_Data=CO_Data.dropna() \n",
    "CO_Data.shape\n",
    "CO_Data=CO_Data.resample('h').mean()\n",
    "CO_Data=CO_Data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "common-tension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44410, 9)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('CO.txt', header = None,low_memory=False)\n",
    "data.columns=['WE','AE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_CO=data\n",
    "Data_CO['Ref']=Ref_CO\n",
    "index_names = Data_CO[ (Data_CO['WE'] >1000)].index\n",
    "Data_CO.drop(index_names, inplace = True)\n",
    "WE=Data_CO['WE'].to_list()\n",
    "AE=Data_CO['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_CO['Net Signal']=signal\n",
    "Data_CO['Month']=Data_CO.index.month\n",
    "Data_CO['Day_of_week']=Data_CO.index.dayofweek\n",
    "Data_CO['Day']=Data_CO.index.day\n",
    "Data_CO['Hour']=Data_CO.index.hour\n",
    "CO_Data=Data_CO\n",
    "CO_Data=CO_Data[(CO_Data[CO_Data.columns] >= 0).all(axis=1)]\n",
    "CO_Data=CO_Data.dropna()\n",
    "data = pd.read_csv('Conc_CO.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab1','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_CO=data\n",
    "Data_CO.drop(index_names, inplace = True)\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_CO['Net Signal']=signal\n",
    "Data_CO['Month']=Data_CO.index.month\n",
    "Data_CO['Day_of_week']=Data_CO.index.dayofweek\n",
    "Data_CO['Day']=Data_CO.index.day\n",
    "Data_CO['Hour']=Data_CO.index.hour\n",
    "CO_Data=Data_CO\n",
    "CO_Data=CO_Data[(CO_Data[CO_Data.columns] >= 0).all(axis=1)]\n",
    "CO_Data=CO_Data.dropna()\n",
    "#CO_Data=CO_Data.sample(frac=1)\n",
    "#CO_Data=CO_Data.resample('h').mean()\n",
    "CO_Data=CO_Data.dropna()\n",
    "#CO_Data= (CO_Data-CO_Data.min())/(CO_Data.max()-CO_Data.min())\n",
    "CO_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "contained-jacksonville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab1</th>\n",
       "      <th>Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Net Signal</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-03 15:50:00</th>\n",
       "      <td>555.780140</td>\n",
       "      <td>29.441429</td>\n",
       "      <td>52.018571</td>\n",
       "      <td>399.25210</td>\n",
       "      <td>168.141429</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-03 15:55:00</th>\n",
       "      <td>514.393544</td>\n",
       "      <td>29.401071</td>\n",
       "      <td>52.805119</td>\n",
       "      <td>284.54245</td>\n",
       "      <td>136.740190</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-03 16:00:00</th>\n",
       "      <td>592.411938</td>\n",
       "      <td>29.211333</td>\n",
       "      <td>53.102667</td>\n",
       "      <td>261.28890</td>\n",
       "      <td>137.737333</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-07 10:45:00</th>\n",
       "      <td>1355.690593</td>\n",
       "      <td>32.782750</td>\n",
       "      <td>36.151417</td>\n",
       "      <td>198.86920</td>\n",
       "      <td>314.136500</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-07 10:50:00</th>\n",
       "      <td>189.562971</td>\n",
       "      <td>32.399528</td>\n",
       "      <td>37.143389</td>\n",
       "      <td>157.33180</td>\n",
       "      <td>8.279061</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Lab1       Temp         RH        Ref  Net Signal  \\\n",
       "Date                                                                            \n",
       "2019-10-03 15:50:00   555.780140  29.441429  52.018571  399.25210  168.141429   \n",
       "2019-10-03 15:55:00   514.393544  29.401071  52.805119  284.54245  136.740190   \n",
       "2019-10-03 16:00:00   592.411938  29.211333  53.102667  261.28890  137.737333   \n",
       "2019-10-07 10:45:00  1355.690593  32.782750  36.151417  198.86920  314.136500   \n",
       "2019-10-07 10:50:00   189.562971  32.399528  37.143389  157.33180    8.279061   \n",
       "\n",
       "                     Month  Day_of_week  Day  Hour  \n",
       "Date                                                \n",
       "2019-10-03 15:50:00     10            3    3    15  \n",
       "2019-10-03 15:55:00     10            3    3    15  \n",
       "2019-10-03 16:00:00     10            3    3    16  \n",
       "2019-10-07 10:45:00     10            0    7    10  \n",
       "2019-10-07 10:50:00     10            0    7    10  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CO_Data1=CO_Data[3:]\n",
    "CO_Data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "express-indication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60913"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('O3.txt', header = None,low_memory=False)\n",
    "data.columns=['AE','WE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_O3=data\n",
    "Data_O3['Ref']=Ref_O3\n",
    "WE=Data_O3['WE'].to_list()\n",
    "AE=Data_O3['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_O3['Net Signal']=signal\n",
    "Data_O3['Month']=Data_O3.index.month\n",
    "Data_O3['Day_of_week']=Data_O3.index.dayofweek\n",
    "Data_O3['Day']=Data_O3.index.day\n",
    "Data_O3['Hour']=Data_O3.index.hour\n",
    "O3_Data=Data_O3\n",
    "O3_Data=O3_Data[(O3_Data[O3_Data.columns] >= 0).all(axis=1)]\n",
    "O3_Data=O3_Data.dropna()\n",
    "data = pd.read_csv('Conc_O3.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab1','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_O3=data\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_O3['Net Signal']=signal\n",
    "Data_O3['Month']=Data_O3.index.month\n",
    "Data_O3['Day_of_week']=Data_O3.index.dayofweek\n",
    "Data_O3['Day']=Data_O3.index.day\n",
    "Data_O3['Hour']=Data_O3.index.hour\n",
    "O3_Data=Data_O3\n",
    "O3_Data=O3_Data[(O3_Data[O3_Data.columns] >= 0).all(axis=1)]\n",
    "O3_Data=O3_Data.dropna() \n",
    "O3_Data=O3_Data.resample('h').mean()\n",
    "O3_Data=O3_Data.dropna()\n",
    "#O3_Data= (O3_Data-CO_Data.min())/(O3_Data.max()-O3_Data.min())\n",
    "O3_Data.head()\n",
    "\n",
    "ref_O3=Data_O3['Ref'].to_list()\n",
    "len(ref_O3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "maritime-effects",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab1</th>\n",
       "      <th>Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Net Signal</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Ref_O3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-02 11:55:00</th>\n",
       "      <td>460.448301</td>\n",
       "      <td>26.378438</td>\n",
       "      <td>58.063437</td>\n",
       "      <td>15.230400</td>\n",
       "      <td>7.850000</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>46.094860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02 12:10:00</th>\n",
       "      <td>1364.583446</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>48.612609</td>\n",
       "      <td>6.665136</td>\n",
       "      <td>37.815652</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>55.810810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02 12:15:00</th>\n",
       "      <td>224.159154</td>\n",
       "      <td>25.765087</td>\n",
       "      <td>48.441408</td>\n",
       "      <td>6.642805</td>\n",
       "      <td>12.275893</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>57.907075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02 12:20:00</th>\n",
       "      <td>82.998996</td>\n",
       "      <td>26.120078</td>\n",
       "      <td>47.716553</td>\n",
       "      <td>2.844210</td>\n",
       "      <td>13.152720</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>58.880540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02 15:45:00</th>\n",
       "      <td>566.301152</td>\n",
       "      <td>30.418466</td>\n",
       "      <td>50.153181</td>\n",
       "      <td>10.084125</td>\n",
       "      <td>9.323533</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>40.068225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Lab1       Temp         RH        Ref  Net Signal  \\\n",
       "Date                                                                            \n",
       "2019-10-02 11:55:00   460.448301  26.378438  58.063437  15.230400    7.850000   \n",
       "2019-10-02 12:10:00  1364.583446  25.500000  48.612609   6.665136   37.815652   \n",
       "2019-10-02 12:15:00   224.159154  25.765087  48.441408   6.642805   12.275893   \n",
       "2019-10-02 12:20:00    82.998996  26.120078  47.716553   2.844210   13.152720   \n",
       "2019-10-02 15:45:00   566.301152  30.418466  50.153181  10.084125    9.323533   \n",
       "\n",
       "                     Month  Day_of_week  Day  Hour     Ref_O3  \n",
       "Date                                                           \n",
       "2019-10-02 11:55:00     10            2    2    11  46.094860  \n",
       "2019-10-02 12:10:00     10            2    2    12  55.810810  \n",
       "2019-10-02 12:15:00     10            2    2    12  57.907075  \n",
       "2019-10-02 12:20:00     10            2    2    12  58.880540  \n",
       "2019-10-02 15:45:00     10            2    2    15  40.068225  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('NO2.txt', header = None,low_memory=False)\n",
    "data.columns=['WE','AE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_NO2=data\n",
    "Data_NO2['Ref']=Ref_NO2\n",
    "WE=Data_NO2['WE'].to_list()\n",
    "AE=Data_NO2['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_NO2['Net Signal']=signal\n",
    "Data_NO2['Month']=Data_NO2.index.month\n",
    "Data_NO2['Day_of_week']=Data_NO2.index.dayofweek\n",
    "Data_NO2['Day']=Data_NO2.index.day\n",
    "Data_NO2['Hour']=Data_NO2.index.hour\n",
    "NO2_Data=Data_NO2\n",
    "NO2_Data=NO2_Data[(NO2_Data[NO2_Data.columns] >= 0).all(axis=1)]\n",
    "NO2_Data=NO2_Data.dropna()\n",
    "data = pd.read_csv('Conc_NO2.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab1','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "subscript = str.maketrans(\"0123456789\", \"₀₁₂₃₄₅₆₇₈₉\") \n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_NO2=data\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_NO2['Net Signal']=signal\n",
    "Data_NO2['Month']=Data_NO2.index.month\n",
    "Data_NO2['Day_of_week']=Data_NO2.index.dayofweek\n",
    "Data_NO2['Day']=Data_NO2.index.day\n",
    "Data_NO2['Hour']=Data_NO2.index.hour\n",
    "Data_NO2['Ref_O3']=ref_O3\n",
    "NO2_Data=Data_NO2\n",
    "NO2_Data=NO2_Data[(NO2_Data[NO2_Data.columns] >= 0).all(axis=1)]\n",
    "NO2_Data=NO2_Data.dropna()\n",
    "#NO2_Data= (NO2_Data-NO2_Data.min())/(NO2_Data.max()-NO2_Data.min())\n",
    "NO2_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "recognized-watch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab1</th>\n",
       "      <th>Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Net Signal</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Ref_NO2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-02 11:55:00</th>\n",
       "      <td>621.625704</td>\n",
       "      <td>26.378438</td>\n",
       "      <td>58.063437</td>\n",
       "      <td>46.094860</td>\n",
       "      <td>3.605625</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>15.230400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02 12:10:00</th>\n",
       "      <td>1788.609900</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>48.612609</td>\n",
       "      <td>55.810810</td>\n",
       "      <td>3.528696</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6.665136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02 12:15:00</th>\n",
       "      <td>287.254970</td>\n",
       "      <td>25.765087</td>\n",
       "      <td>48.441408</td>\n",
       "      <td>57.907075</td>\n",
       "      <td>17.781453</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6.642805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02 12:20:00</th>\n",
       "      <td>99.598353</td>\n",
       "      <td>26.120078</td>\n",
       "      <td>47.716553</td>\n",
       "      <td>58.880540</td>\n",
       "      <td>20.285180</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2.844210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-07 10:50:00</th>\n",
       "      <td>105.723457</td>\n",
       "      <td>32.399528</td>\n",
       "      <td>37.143389</td>\n",
       "      <td>48.533490</td>\n",
       "      <td>11.862076</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4.344894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30 23:35:00</th>\n",
       "      <td>60.523932</td>\n",
       "      <td>16.255137</td>\n",
       "      <td>83.573341</td>\n",
       "      <td>22.222497</td>\n",
       "      <td>7.913030</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>3.480461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30 23:40:00</th>\n",
       "      <td>64.665593</td>\n",
       "      <td>16.162835</td>\n",
       "      <td>84.568452</td>\n",
       "      <td>28.185830</td>\n",
       "      <td>7.234113</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>3.467720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30 23:45:00</th>\n",
       "      <td>58.131073</td>\n",
       "      <td>16.137381</td>\n",
       "      <td>84.388139</td>\n",
       "      <td>29.609723</td>\n",
       "      <td>8.246587</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>3.357663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30 23:50:00</th>\n",
       "      <td>59.385848</td>\n",
       "      <td>16.114102</td>\n",
       "      <td>84.249935</td>\n",
       "      <td>19.007920</td>\n",
       "      <td>8.179632</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>3.306978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30 23:55:00</th>\n",
       "      <td>51.442543</td>\n",
       "      <td>16.114863</td>\n",
       "      <td>84.416501</td>\n",
       "      <td>16.022503</td>\n",
       "      <td>10.341400</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>3.474913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36821 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Lab1       Temp         RH        Ref  Net Signal  \\\n",
       "Date                                                                            \n",
       "2019-10-02 11:55:00   621.625704  26.378438  58.063437  46.094860    3.605625   \n",
       "2019-10-02 12:10:00  1788.609900  25.500000  48.612609  55.810810    3.528696   \n",
       "2019-10-02 12:15:00   287.254970  25.765087  48.441408  57.907075   17.781453   \n",
       "2019-10-02 12:20:00    99.598353  26.120078  47.716553  58.880540   20.285180   \n",
       "2019-10-07 10:50:00   105.723457  32.399528  37.143389  48.533490   11.862076   \n",
       "...                          ...        ...        ...        ...         ...   \n",
       "2020-04-30 23:35:00    60.523932  16.255137  83.573341  22.222497    7.913030   \n",
       "2020-04-30 23:40:00    64.665593  16.162835  84.568452  28.185830    7.234113   \n",
       "2020-04-30 23:45:00    58.131073  16.137381  84.388139  29.609723    8.246587   \n",
       "2020-04-30 23:50:00    59.385848  16.114102  84.249935  19.007920    8.179632   \n",
       "2020-04-30 23:55:00    51.442543  16.114863  84.416501  16.022503   10.341400   \n",
       "\n",
       "                     Month  Day_of_week  Day  Hour    Ref_NO2  \n",
       "Date                                                           \n",
       "2019-10-02 11:55:00     10            2    2    11  15.230400  \n",
       "2019-10-02 12:10:00     10            2    2    12   6.665136  \n",
       "2019-10-02 12:15:00     10            2    2    12   6.642805  \n",
       "2019-10-02 12:20:00     10            2    2    12   2.844210  \n",
       "2019-10-07 10:50:00     10            0    7    10   4.344894  \n",
       "...                    ...          ...  ...   ...        ...  \n",
       "2020-04-30 23:35:00      4            3   30    23   3.480461  \n",
       "2020-04-30 23:40:00      4            3   30    23   3.467720  \n",
       "2020-04-30 23:45:00      4            3   30    23   3.357663  \n",
       "2020-04-30 23:50:00      4            3   30    23   3.306978  \n",
       "2020-04-30 23:55:00      4            3   30    23   3.474913  \n",
       "\n",
       "[36821 rows x 10 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "Ref_O3=10*np.array(Ref_O3)\n",
    "data = pd.read_csv('O3.txt', header = None,low_memory=False)\n",
    "data.columns=['AE','WE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_O3=data\n",
    "Data_O3['Ref']=Ref_O3\n",
    "WE=Data_O3['WE'].to_list()\n",
    "AE=Data_O3['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_O3['Net Signal']=signal\n",
    "Data_O3['Month']=Data_O3.index.month\n",
    "Data_O3['Day_of_week']=Data_O3.index.dayofweek\n",
    "Data_O3['Day']=Data_O3.index.day\n",
    "Data_O3['Hour']=Data_O3.index.hour\n",
    "O3_Data=Data_O3\n",
    "O3_Data=O3_Data[(O3_Data[O3_Data.columns] >= 0).all(axis=1)]\n",
    "O3_Data=O3_Data.dropna()\n",
    "data = pd.read_csv('Conc_O3.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab1','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_O3=data\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_O3['Net Signal']=signal\n",
    "Data_O3['Month']=Data_O3.index.month\n",
    "Data_O3['Day_of_week']=Data_O3.index.dayofweek\n",
    "Data_O3['Day']=Data_O3.index.day\n",
    "Data_O3['Hour']=Data_O3.index.hour\n",
    "ref_NO2=Data_NO2['Ref'].to_list()\n",
    "Data_O3['Ref_NO2']=ref_NO2\n",
    "O3_Data=Data_O3\n",
    "O3_Data=O3_Data[(O3_Data[O3_Data.columns] >= 0).all(axis=1)]\n",
    "#O3_Data= (O3_Data-O3_Data.min())/(O3_Data.max()-O3_Data.min())\n",
    "O3_Data=O3_Data.dropna()\n",
    "\n",
    "O3_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fluid-ebony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42633, 9)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "CO_Data=CO_Data[(np.abs(stats.zscore(CO_Data)) < 3).all(axis=1)]\n",
    "CO_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "sweet-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(pred, y_test):\n",
    "    pred=np.array(pred)\n",
    "    y_test=np.array(y_test)\n",
    "    mae=sum(abs(pred-y_test))/len(y_test)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-doctor",
   "metadata": {},
   "source": [
    "#  New Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-witch",
   "metadata": {},
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('CO_2.txt', header = None,low_memory=False)\n",
    "data.columns=['C1','C2','C3','C4','Temp','RH','Ref','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "\n",
    "data=data[['C1','Temp','RH','Ref']]\n",
    "Data_CO=data\n",
    "Data_CO['Month']=Data_CO.index.month\n",
    "Data_CO['Day_of_week']=Data_CO.index.dayofweek\n",
    "#Data_CO['Day']=Data_CO.index.day\n",
    "Data_CO['Hour']=Data_CO.index.hour\n",
    "CO_Data=Data_CO\n",
    "CO_Data=CO_Data[(CO_Data[CO_Data.columns] >= 0).all(axis=1)]\n",
    "CO_Data=CO_Data.dropna()\n",
    "CO_Data=CO_Data[:3446]\n",
    "CO_Data=CO_Data.resample('h').mean()\n",
    "CO_Data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-trash",
   "metadata": {},
   "source": [
    "Temp1=CO_Data['Temp'].to_list()\n",
    "RH1=CO_Data['RH'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-parameter",
   "metadata": {},
   "source": [
    "CO_Data1.tail()\n",
    "CO_Data1=CO_Data1.resample('h').mean()\n",
    "CO_Data1['Temp1']=Temp1\n",
    "CO_Data1['RH1']=RH1\n",
    "CO_Data1=CO_Data1.dropna()\n",
    "Temp=CO_Data1['Temp'].to_list()\n",
    "RH=CO_Data1['RH'].to_list()\n",
    "Temp2=CO_Data1['Temp1'].to_list()\n",
    "RH2=CO_Data1['RH1'].to_list()\n",
    "\n",
    "ind=[i for i in range(len(Temp))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-grave",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(ind, RH, color='green')\n",
    "plt.plot(ind, RH2, color='red')\n",
    "plt.ylabel('RH')\n",
    "plt.xlabel('Hours')\n",
    "plt.legend(['Sensor','Station'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-april",
   "metadata": {},
   "source": [
    "NO2_Data1=NO2_Data.resample('h').mean()\n",
    "NO2_Data1=NO2_Data1[28:]\n",
    "NO2_Data1['Temp1']=Temp1\n",
    "NO2_Data1['RH1']=RH1\n",
    "NO2_Data1=NO2_Data1.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-least",
   "metadata": {},
   "source": [
    "O3_Data1=O3_Data.resample('h').mean()\n",
    "O3_Data1=O3_Data1[28:]\n",
    "O3_Data1['Temp1']=Temp1\n",
    "O3_Data1['RH1']=RH1\n",
    "O3_Data1=O3_Data1.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-paper",
   "metadata": {},
   "source": [
    "CO_Data=CO_Data1\n",
    "NO2_Data=NO2_Data1\n",
    "O3_Data=O3_Data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "vital-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MBE(true,pred):\n",
    "    true=np.array(true)\n",
    "    pred=np.array(pred)\n",
    "    mbe=np.mean(true-pred)\n",
    "    return mbe\n",
    "def CRMSE(true,pred):\n",
    "    true=np.array(true)\n",
    "    pred=np.array(pred)\n",
    "    crmse=np.sqrt(np.mean(((true-np.mean(true))-(pred-np.mean(pred)))**2))\n",
    "    if np.std(pred)>np.std(true):\n",
    "        crmse=crmse\n",
    "    else:\n",
    "        crmse=-crmse\n",
    "    return crmse\n",
    "\n",
    "def sMAE(true,pred):\n",
    "    true=np.array(true)\n",
    "    pred=np.array(pred)\n",
    "    smae=np.mean(abs(true-pred)/((abs(true)+abs(pred))/2))\n",
    "    return smae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "focal-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sMAE(true,pred):\n",
    "    true=np.array(true)\n",
    "    pred=np.array(pred)\n",
    "    mae=sum(abs(pred-true))/len(pred)\n",
    "    nmae=mae/np.mean(true)\n",
    "    return 1-nmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "limiting-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "p = np.array([ 0.9])\n",
    "df=np.array(range(1,10000))\n",
    "chi = [0]+list(chi2.isf(p, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "tight-reputation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.66023432606575"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "#find T critical value\n",
    "scipy.stats.t.ppf(q=.95,df=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "second-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(pred,true):\n",
    "    pred=list(pred)\n",
    "    true=list(true)\n",
    "    for i in range(len(true)):\n",
    "        if true[i]==0:\n",
    "            true.pop(i)\n",
    "            pred.pop(i)\n",
    "    pred=np.array(pred)\n",
    "    true=np.array(true)\n",
    "    #d=((pred-true)/((true+pred)/2))*100\n",
    "    d=((pred-true)/np.mean(true))*100\n",
    "    n=len(pred)\n",
    "    A=np.sqrt((n-1)/chi[n-1])\n",
    "    cv=np.sqrt(((n*sum(abs(d)**2)-(sum(abs(d)))**2)/(2*n*(n-1))))*A\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "checked-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(pred,true):\n",
    "    pred=list(pred)\n",
    "    true=list(true)\n",
    "    for i in range(len(true)):\n",
    "        if true[i]==0:\n",
    "            true.pop(i)\n",
    "            pred.pop(i)\n",
    "    pred=np.array(pred)\n",
    "    true=np.array(true)\n",
    "    #d=((pred-true)/((true+pred)/2))*100\n",
    "    d=((pred-true)/np.mean(true))*100\n",
    "    n=len(pred)\n",
    "    AB=sum(abs(d))/n\n",
    "    #AS=np.sqrt(((n*sum(abs(d)**2)-(sum(abs(d)))**2)/(n*(n-1))))\n",
    "    AS=np.sqrt(sum((d-AB)**2)/(n-1))\n",
    "    t=scipy.stats.t.ppf(q=.95,df=n-1)\n",
    "    bias=AB+(t*AS/np.sqrt(n))\n",
    "    return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fixed-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOA(pred,true):\n",
    "    true=np.array(true)\n",
    "    pred=np.array(pred)\n",
    "    frac=sum(abs(true-pred))/sum((abs(pred-np.mean(true))+abs(true-np.mean(true))))\n",
    "    d=1-frac\n",
    "    return d  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "challenging-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def REF(pred,y_test,alpha):\n",
    "    import random\n",
    "    cal=np.array(pred)\n",
    "    ref=np.array(y_test.to_list())\n",
    "    ref_mean=np.mean(ref)\n",
    "    cal_mean=np.mean(cal)\n",
    "    prec=np.array([20 for i in range(len(ref))])\n",
    "    u=np.maximum(prec,0.001*ref)\n",
    "    #cal=np.log(cal)\n",
    "    #ref=np.log(ref)\n",
    "    sx_s=(1/len(ref))*sum((ref-ref_mean)**2)\n",
    "    sy_s=(1/len(cal))*sum((cal-cal_mean)**2)\n",
    "    sxy=(1/len(cal))*sum((cal-cal_mean)*(ref-ref_mean))\n",
    "    beta_1=((sy_s-alpha*sx_s)+np.sqrt((sy_s-sx_s)**2+4*alpha*sxy**2))/(2*sxy)\n",
    "    beta_0=cal_mean-beta_1*ref_mean\n",
    "    RSS=sum((cal-beta_0-beta_1*ref)**2-(beta_1**2+alpha)*u**2)\n",
    "    du_s=RSS/(len(cal)-2)\n",
    "    Beta_1=((sy_s-alpha*sx_s-du_s)+np.sqrt((sy_s-alpha*sx_s-du_s)**2+4*alpha*sxy**2))/(2*sxy)\n",
    "    Beta_0=cal_mean-Beta_1*ref_mean\n",
    "    P1=(RSS/(len(cal)-2))\n",
    "    P2=(Beta_1**2+alpha)*u**2+(-2*Beta_1**2+2*Beta_1-1)*u**2\n",
    "    P3=(Beta_0+(Beta_1-1)*ref)**2\n",
    "    P=[]\n",
    "    for i in range(len(P3)):\n",
    "        P.append(P1+P2[i]+P3[i])\n",
    "    for i in range(len(P)):\n",
    "        if P[i]<0:\n",
    "            P[i]=random.randint(1,100)\n",
    "    u_cal=(2*np.sqrt(np.array(P))/cal)*100\n",
    "    #u_cal=((2*np.sqrt((RSS/(len(cal)-2))+(1-(beta_1-1)**2)*(0.08*ref)**2+(Beta_0+(Beta_1-1)*ref)**2))/cal)*100\n",
    "    return u_cal  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "portuguese-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def REF2(pred,y_test,alpha,LV):\n",
    "    import random\n",
    "    cal=np.array(pred)\n",
    "    ref=np.array(y_test.to_list())\n",
    "    ref_mean=np.mean(ref)\n",
    "    cal_mean=np.mean(cal)\n",
    "    prec=np.array([20 for i in range(len(ref))])\n",
    "    u=0.001*ref\n",
    "    #cal=np.log(cal)\n",
    "    #ref=np.log(ref)\n",
    "    sx_s=(1/len(ref))*sum((ref-ref_mean)**2)\n",
    "    sy_s=(1/len(cal))*sum((cal-cal_mean)**2)\n",
    "    sxy=(1/len(cal))*sum((cal-cal_mean)*(ref-ref_mean))\n",
    "    #beta_1=((sy_s-sx_s)+np.sqrt((sy_s-sx_s)**2+4*sxy**2))/(2*sxy)\n",
    "    beta_1=((sy_s-alpha*sx_s)+np.sqrt((sy_s-sx_s)**2+4*alpha*sxy**2))/(2*sxy)\n",
    "    beta_0=cal_mean-beta_1*ref_mean\n",
    "    RSS=sum((cal-beta_0-beta_1*ref)**2-(beta_1**2+alpha)*(0.001*LV)**2)\n",
    "    du_s=RSS/(len(cal)-2)\n",
    "    #Beta_1=((sy_s-sx_s-du_s)+np.sqrt((sy_s-sx_s-du_s)**2+4*sxy**2))/(2*sxy)\n",
    "    Beta_1=((sy_s-alpha*sx_s-du_s)+np.sqrt((sy_s-alpha*sx_s-du_s)**2+4*alpha*sxy**2))/(2*sxy)\n",
    "    Beta_0=cal_mean-Beta_1*ref_mean\n",
    "    P1=(RSS/(len(cal)-2))\n",
    "    P2=(Beta_1**2+alpha)*(0.001*LV)**2+(-2*Beta_1**2+2*Beta_1-1)*(0.001*LV)**2\n",
    "    P3=(Beta_0+(Beta_1-1)*LV)**2\n",
    "    P=P1+P2+P3\n",
    "    if P<0:\n",
    "        P=random.randint(1,100)\n",
    "    u_cal=(2*np.sqrt(P)/(Beta_0+Beta_1*LV))*100\n",
    "    #u_cal=((2*np.sqrt((RSS/(len(cal)-2))+(1-(beta_1-1)**2)*0.1+(Beta_0+(Beta_1-1)*ref)**2))\n",
    "    #/cal)*100\n",
    "    return u_cal  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "comic-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "completed-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "attempted-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "attached-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "rational-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "featured-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n",
    "                                                 meta_model = lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "elegant-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#O3_Data=O3_Data.iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "assisted-abuse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab1</th>\n",
       "      <th>Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Net Signal</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Ref_NO2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-02 11:55:00</th>\n",
       "      <td>621.625704</td>\n",
       "      <td>26.378438</td>\n",
       "      <td>58.063437</td>\n",
       "      <td>46.094860</td>\n",
       "      <td>3.605625</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>15.230400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02 12:10:00</th>\n",
       "      <td>1788.609900</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>48.612609</td>\n",
       "      <td>55.810810</td>\n",
       "      <td>3.528696</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6.665136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02 12:15:00</th>\n",
       "      <td>287.254970</td>\n",
       "      <td>25.765087</td>\n",
       "      <td>48.441408</td>\n",
       "      <td>57.907075</td>\n",
       "      <td>17.781453</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6.642805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02 12:20:00</th>\n",
       "      <td>99.598353</td>\n",
       "      <td>26.120078</td>\n",
       "      <td>47.716553</td>\n",
       "      <td>58.880540</td>\n",
       "      <td>20.285180</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2.844210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-07 10:50:00</th>\n",
       "      <td>105.723457</td>\n",
       "      <td>32.399528</td>\n",
       "      <td>37.143389</td>\n",
       "      <td>48.533490</td>\n",
       "      <td>11.862076</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4.344894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Lab1       Temp         RH        Ref  Net Signal  \\\n",
       "Date                                                                            \n",
       "2019-10-02 11:55:00   621.625704  26.378438  58.063437  46.094860    3.605625   \n",
       "2019-10-02 12:10:00  1788.609900  25.500000  48.612609  55.810810    3.528696   \n",
       "2019-10-02 12:15:00   287.254970  25.765087  48.441408  57.907075   17.781453   \n",
       "2019-10-02 12:20:00    99.598353  26.120078  47.716553  58.880540   20.285180   \n",
       "2019-10-07 10:50:00   105.723457  32.399528  37.143389  48.533490   11.862076   \n",
       "\n",
       "                     Month  Day_of_week  Day  Hour    Ref_NO2  \n",
       "Date                                                           \n",
       "2019-10-02 11:55:00     10            2    2    11  15.230400  \n",
       "2019-10-02 12:10:00     10            2    2    12   6.665136  \n",
       "2019-10-02 12:15:00     10            2    2    12   6.642805  \n",
       "2019-10-02 12:20:00     10            2    2    12   2.844210  \n",
       "2019-10-07 10:50:00     10            0    7    10   4.344894  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=[x for _, x in O3_Data.groupby('Month')]\n",
    "data_oct=df1[4]\n",
    "#data_oct=data_oct.sample(frac=1)\n",
    "data_nov=df1[5]\n",
    "#data_nov=data_nov.sample(frac=1)\n",
    "data_dec=df1[6]\n",
    "#data_dec=data_dec.sample(frac=1)\n",
    "data_jan=df1[0]\n",
    "#data_jan=data_jan.sample(frac=1)\n",
    "data_feb=df1[1]\n",
    "#data_feb=data_feb.sample(frac=1)\n",
    "data_mar=df1[2]\n",
    "#data_mar=data_mar.sample(frac=1)\n",
    "data_apr=df1[3]\n",
    "#data_apr=data_apr.sample(frac=1)\n",
    "data=[data_oct,data_nov,data_dec,data_jan,data_feb,data_mar]\n",
    "data_oct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "viral-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Oct=data_oct.resample('60min').mean()\n",
    "data_Oct=data_Oct.dropna()\n",
    "data_Nov=data_nov.resample('60min').mean()\n",
    "data_Nov=data_Nov.dropna()\n",
    "data_Dec=data_dec.resample('60min').mean()\n",
    "data_Dec=data_Dec.dropna()\n",
    "data_Jan=data_jan.resample('60min').mean()\n",
    "data_Jan=data_Jan.dropna()\n",
    "data_Feb=data_feb.resample('60min').mean()\n",
    "data_Feb=data_Feb.dropna()\n",
    "data_Mar=data_mar.resample('60min').mean()\n",
    "data_Mar=data_Mar.dropna()\n",
    "data_Apr=data_apr.resample('60min').mean()\n",
    "data_Apr=data_Apr.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-video",
   "metadata": {},
   "source": [
    "Temp=data_Jan['RH'].to_list()\n",
    "len(Temp)\n",
    "\n",
    "ind=[i for i in range(len(Temp))]\n",
    "plt.plot(ind,Temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "experienced-acting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab1</th>\n",
       "      <th>Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Net Signal</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Ref_NO2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-14 15:00:00</th>\n",
       "      <td>121.424636</td>\n",
       "      <td>15.130260</td>\n",
       "      <td>53.920912</td>\n",
       "      <td>27.811665</td>\n",
       "      <td>3.875583</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>18.995165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-14 15:05:00</th>\n",
       "      <td>97.965370</td>\n",
       "      <td>15.088266</td>\n",
       "      <td>54.620724</td>\n",
       "      <td>28.450277</td>\n",
       "      <td>4.498775</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>21.162180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-14 16:10:00</th>\n",
       "      <td>89.752931</td>\n",
       "      <td>13.271542</td>\n",
       "      <td>61.067292</td>\n",
       "      <td>26.522085</td>\n",
       "      <td>1.582542</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>17.001195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-14 16:15:00</th>\n",
       "      <td>97.043600</td>\n",
       "      <td>13.187583</td>\n",
       "      <td>61.158583</td>\n",
       "      <td>24.511943</td>\n",
       "      <td>1.419583</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>23.019373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-14 16:20:00</th>\n",
       "      <td>95.767470</td>\n",
       "      <td>13.104631</td>\n",
       "      <td>61.276556</td>\n",
       "      <td>25.317920</td>\n",
       "      <td>1.699226</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>21.306785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Lab1       Temp         RH        Ref  Net Signal  \\\n",
       "Date                                                                           \n",
       "2020-02-14 15:00:00  121.424636  15.130260  53.920912  27.811665    3.875583   \n",
       "2020-02-14 15:05:00   97.965370  15.088266  54.620724  28.450277    4.498775   \n",
       "2020-02-14 16:10:00   89.752931  13.271542  61.067292  26.522085    1.582542   \n",
       "2020-02-14 16:15:00   97.043600  13.187583  61.158583  24.511943    1.419583   \n",
       "2020-02-14 16:20:00   95.767470  13.104631  61.276556  25.317920    1.699226   \n",
       "\n",
       "                     Month  Day_of_week  Day  Hour    Ref_NO2  \n",
       "Date                                                           \n",
       "2020-02-14 15:00:00      2            4   14    15  18.995165  \n",
       "2020-02-14 15:05:00      2            4   14    15  21.162180  \n",
       "2020-02-14 16:10:00      2            4   14    16  17.001195  \n",
       "2020-02-14 16:15:00      2            4   14    16  23.019373  \n",
       "2020-02-14 16:20:00      2            4   14    16  21.306785  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=[x for _, x in O3_Data.groupby('Month')]\n",
    "data_oct2=df2[4]\n",
    "#data_oct2=data_oct2.sample(frac=1)\n",
    "data_nov2=df2[5]\n",
    "#data_nov2=data_nov2.sample(frac=1)\n",
    "data_dec2=df2[6]\n",
    "#data_dec2=data_dec2.sample(frac=1)\n",
    "data_jan2=df2[0]\n",
    "#data_jan2=data_jan2.sample(frac=1)\n",
    "data_feb2=df2[1]\n",
    "#data_feb2=data_feb2.sample(frac=1)\n",
    "data_mar2=df2[2]\n",
    "#data_mar2=data_mar2.sample(frac=1)\n",
    "data_apr2=df2[3]\n",
    "#data_apr2=data_apr2.sample(frac=1)\n",
    "data=[data_oct2,data_nov2,data_dec2,data_jan2,data_feb2,data_mar2]\n",
    "data_feb2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "natural-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Oct2=data_oct2.resample('60min').mean()\n",
    "data_Oct2=data_Oct2.dropna()\n",
    "data_Nov2=data_nov2.resample('60min').mean()\n",
    "data_Nov2=data_Nov2.dropna()\n",
    "data_Dec2=data_dec2.resample('60min').mean()\n",
    "data_Dec2=data_Dec2.dropna()\n",
    "data_Jan2=data_jan2.resample('60min').mean()\n",
    "data_Jan2=data_Jan2.dropna()\n",
    "data_Feb2=data_feb2.resample('60min').mean()\n",
    "data_Feb2=data_Feb2.dropna()\n",
    "data_Mar2=data_mar2.resample('60min').mean()\n",
    "data_Mar2=data_Mar2.dropna()\n",
    "data_Apr2=data_apr2.resample('60min').mean()\n",
    "data_Apr2=data_Apr2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "controlled-removal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab1</th>\n",
       "      <th>Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Net Signal</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Ref_NO2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-14 15:00:00</th>\n",
       "      <td>121.424636</td>\n",
       "      <td>15.130260</td>\n",
       "      <td>53.920912</td>\n",
       "      <td>27.811665</td>\n",
       "      <td>3.875583</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>18.995165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-14 15:05:00</th>\n",
       "      <td>97.965370</td>\n",
       "      <td>15.088266</td>\n",
       "      <td>54.620724</td>\n",
       "      <td>28.450277</td>\n",
       "      <td>4.498775</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>21.162180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-14 16:10:00</th>\n",
       "      <td>89.752931</td>\n",
       "      <td>13.271542</td>\n",
       "      <td>61.067292</td>\n",
       "      <td>26.522085</td>\n",
       "      <td>1.582542</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>17.001195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-14 16:15:00</th>\n",
       "      <td>97.043600</td>\n",
       "      <td>13.187583</td>\n",
       "      <td>61.158583</td>\n",
       "      <td>24.511943</td>\n",
       "      <td>1.419583</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>23.019373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-14 16:20:00</th>\n",
       "      <td>95.767470</td>\n",
       "      <td>13.104631</td>\n",
       "      <td>61.276556</td>\n",
       "      <td>25.317920</td>\n",
       "      <td>1.699226</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>21.306785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Lab1       Temp         RH        Ref  Net Signal  \\\n",
       "Date                                                                           \n",
       "2020-02-14 15:00:00  121.424636  15.130260  53.920912  27.811665    3.875583   \n",
       "2020-02-14 15:05:00   97.965370  15.088266  54.620724  28.450277    4.498775   \n",
       "2020-02-14 16:10:00   89.752931  13.271542  61.067292  26.522085    1.582542   \n",
       "2020-02-14 16:15:00   97.043600  13.187583  61.158583  24.511943    1.419583   \n",
       "2020-02-14 16:20:00   95.767470  13.104631  61.276556  25.317920    1.699226   \n",
       "\n",
       "                     Month  Day_of_week  Day  Hour    Ref_NO2  \n",
       "Date                                                           \n",
       "2020-02-14 15:00:00      2            4   14    15  18.995165  \n",
       "2020-02-14 15:05:00      2            4   14    15  21.162180  \n",
       "2020-02-14 16:10:00      2            4   14    16  17.001195  \n",
       "2020-02-14 16:15:00      2            4   14    16  23.019373  \n",
       "2020-02-14 16:20:00      2            4   14    16  21.306785  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=[x for _, x in O3_Data.groupby('Month')]\n",
    "data_oct3=df3[4]\n",
    "#data_oct3=data_oct3.sample(frac=1)\n",
    "data_nov3=df3[5]\n",
    "#data_nov3=data_nov3.sample(frac=1)\n",
    "data_dec3=df3[6]\n",
    "#data_dec3=data_dec3.sample(frac=1)\n",
    "data_jan3=df3[0]\n",
    "#data_jan3=data_jan3.sample(frac=1)\n",
    "data_feb3=df3[1]\n",
    "#data_feb3=data_feb3.sample(frac=1)\n",
    "data_mar3=df3[2]\n",
    "#data_mar3=data_mar3.sample(frac=1)\n",
    "data_apr3=df3[3]\n",
    "#data_apr3=data_apr3.sample(frac=1)\n",
    "data=[data_oct3,data_nov3,data_dec3,data_jan3,data_feb3,data_mar3]\n",
    "data_feb3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "black-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Oct3=data_oct3.resample('60min').last()\n",
    "data_Oct3=data_Oct3.dropna()\n",
    "data_Nov3=data_nov3.resample('60min').last()\n",
    "data_Nov3=data_Nov3.dropna()\n",
    "data_Dec3=data_dec3.resample('60min').last()\n",
    "data_Dec3=data_Dec3.dropna()\n",
    "data_Jan3=data_jan3.resample('60min').last()\n",
    "data_Jan3=data_Jan3.dropna()\n",
    "data_Feb3=data_feb3.resample('60min').last()\n",
    "data_Feb3=data_Feb3.dropna()\n",
    "data_Mar3=data_mar3.resample('60min').last()\n",
    "data_Mar3=data_Mar3.dropna()\n",
    "data_Apr3=data_apr3.resample('60min').last()\n",
    "data_Apr3=data_Apr3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "color-mayor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab1</th>\n",
       "      <th>Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Net Signal</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Ref_NO2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-02 11:00:00</th>\n",
       "      <td>621.625704</td>\n",
       "      <td>26.378438</td>\n",
       "      <td>58.063437</td>\n",
       "      <td>46.094860</td>\n",
       "      <td>3.605625</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.230400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02 12:00:00</th>\n",
       "      <td>99.598353</td>\n",
       "      <td>26.120078</td>\n",
       "      <td>47.716553</td>\n",
       "      <td>58.880540</td>\n",
       "      <td>20.285180</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.844210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-07 10:00:00</th>\n",
       "      <td>110.669169</td>\n",
       "      <td>32.289000</td>\n",
       "      <td>37.378125</td>\n",
       "      <td>45.984525</td>\n",
       "      <td>11.033542</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.166651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-07 11:00:00</th>\n",
       "      <td>145.934737</td>\n",
       "      <td>36.586708</td>\n",
       "      <td>32.431417</td>\n",
       "      <td>47.910815</td>\n",
       "      <td>12.648250</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.230621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-07 12:00:00</th>\n",
       "      <td>260.566848</td>\n",
       "      <td>34.527578</td>\n",
       "      <td>32.699732</td>\n",
       "      <td>49.135953</td>\n",
       "      <td>3.073537</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.435194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31 19:00:00</th>\n",
       "      <td>107.920431</td>\n",
       "      <td>19.151852</td>\n",
       "      <td>72.105362</td>\n",
       "      <td>9.720208</td>\n",
       "      <td>3.490208</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.040065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31 20:00:00</th>\n",
       "      <td>94.910725</td>\n",
       "      <td>18.313667</td>\n",
       "      <td>74.531250</td>\n",
       "      <td>3.432125</td>\n",
       "      <td>4.673810</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.918170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31 21:00:00</th>\n",
       "      <td>80.634312</td>\n",
       "      <td>17.822078</td>\n",
       "      <td>76.417224</td>\n",
       "      <td>16.595835</td>\n",
       "      <td>5.533771</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.285320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31 22:00:00</th>\n",
       "      <td>74.353514</td>\n",
       "      <td>17.293811</td>\n",
       "      <td>78.388130</td>\n",
       "      <td>2.777708</td>\n",
       "      <td>7.845655</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.464620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31 23:00:00</th>\n",
       "      <td>69.429447</td>\n",
       "      <td>16.949621</td>\n",
       "      <td>79.744070</td>\n",
       "      <td>2.394000</td>\n",
       "      <td>9.790860</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25.807595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Lab1       Temp         RH        Ref  Net Signal  \\\n",
       "Date                                                                           \n",
       "2019-10-02 11:00:00  621.625704  26.378438  58.063437  46.094860    3.605625   \n",
       "2019-10-02 12:00:00   99.598353  26.120078  47.716553  58.880540   20.285180   \n",
       "2019-10-07 10:00:00  110.669169  32.289000  37.378125  45.984525   11.033542   \n",
       "2019-10-07 11:00:00  145.934737  36.586708  32.431417  47.910815   12.648250   \n",
       "2019-10-07 12:00:00  260.566848  34.527578  32.699732  49.135953    3.073537   \n",
       "...                         ...        ...        ...        ...         ...   \n",
       "2019-10-31 19:00:00  107.920431  19.151852  72.105362   9.720208    3.490208   \n",
       "2019-10-31 20:00:00   94.910725  18.313667  74.531250   3.432125    4.673810   \n",
       "2019-10-31 21:00:00   80.634312  17.822078  76.417224  16.595835    5.533771   \n",
       "2019-10-31 22:00:00   74.353514  17.293811  78.388130   2.777708    7.845655   \n",
       "2019-10-31 23:00:00   69.429447  16.949621  79.744070   2.394000    9.790860   \n",
       "\n",
       "                     Month  Day_of_week   Day  Hour    Ref_NO2  \n",
       "Date                                                            \n",
       "2019-10-02 11:00:00   10.0          2.0   2.0  11.0  15.230400  \n",
       "2019-10-02 12:00:00   10.0          2.0   2.0  12.0   2.844210  \n",
       "2019-10-07 10:00:00   10.0          0.0   7.0  10.0   4.166651  \n",
       "2019-10-07 11:00:00   10.0          0.0   7.0  11.0   8.230621  \n",
       "2019-10-07 12:00:00   10.0          0.0   7.0  12.0   5.435194  \n",
       "...                    ...          ...   ...   ...        ...  \n",
       "2019-10-31 19:00:00   10.0          3.0  31.0  19.0  29.040065  \n",
       "2019-10-31 20:00:00   10.0          3.0  31.0  20.0  35.918170  \n",
       "2019-10-31 21:00:00   10.0          3.0  31.0  21.0  20.285320  \n",
       "2019-10-31 22:00:00   10.0          3.0  31.0  22.0  29.464620  \n",
       "2019-10-31 23:00:00   10.0          3.0  31.0  23.0  25.807595  \n",
       "\n",
       "[490 rows x 10 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Oct3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "round-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "peaceful-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import  XGBRegressor\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "# create an xgboost regression model\n",
    "#n_estimators=10000, max_depth=5, eta=0.01, subsample=0.9,colsample_bytree=0.4,alpha=10\n",
    "model = XGBRegressor(n_estimators=10000, max_depth=5, eta=0.01, subsample=0.9, \n",
    "                     colsample_bytree=0.4,alpha=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "front-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def REF(pred,y_test,alpha):\n",
    "    import random\n",
    "    cal=np.array(pred)\n",
    "    ref=np.array(y_test.to_list())\n",
    "    for i in range(len(ref)):\n",
    "        if ref[i]==0:\n",
    "            ref[i]=np.mean(ref)\n",
    "    ref_mean=np.mean(ref)\n",
    "    cal_mean=np.mean(cal)\n",
    "    prec=np.array([20 for i in range(len(ref))])\n",
    "    u=np.maximum(prec,0.001*ref)\n",
    "    u=0.001*ref\n",
    "    #cal=np.log(cal)\n",
    "    #ref=np.log(ref)\n",
    "    sx_s=(1/len(ref))*sum((ref-ref_mean)**2)\n",
    "    sy_s=(1/len(cal))*sum((cal-cal_mean)**2)\n",
    "    sxy=(1/len(cal))*sum((cal-cal_mean)*(ref-ref_mean))\n",
    "    beta_1=((sy_s-alpha*sx_s)+np.sqrt((sy_s-sx_s)**2+4*alpha*sxy**2))/(2*sxy)\n",
    "    beta_0=cal_mean-beta_1*ref_mean\n",
    "    RSS=sum((cal-beta_0-beta_1*ref)**2-(beta_1**2+alpha)*u**2)\n",
    "    du_s=RSS/(len(cal)-2)\n",
    "    Beta_1=((sy_s-alpha*sx_s-du_s)+np.sqrt((sy_s-alpha*sx_s-du_s)**2+4*alpha*sxy**2))/(2*sxy)\n",
    "    Beta_0=cal_mean-Beta_1*ref_mean\n",
    "    P1=(RSS/(len(cal)-2))\n",
    "    #P2=(Beta_1**2+alpha)*u**2+(-2*Beta_1**2+2*Beta_1-1)*u**2\n",
    "    P2=-(u**2)\n",
    "    P3=(Beta_0+(Beta_1-1)*ref)**2\n",
    "    P=[]\n",
    "    for i in range(len(P3)):\n",
    "        P.append(P1+P2[i]+P3[i])\n",
    "    U1=[]\n",
    "    Ref=[]\n",
    "    for i in range(len(P)):\n",
    "        if P[i]>=0:\n",
    "            U1.append(P[i])\n",
    "            Ref.append(ref[i])\n",
    "    #for i in range(len(P)):\n",
    "        #if P[i]<0:\n",
    "           # P[i]=np.mean(P1)\n",
    "    u_cal=(2*np.sqrt(np.array(U1))/np.array(Ref))*100\n",
    "    U_cal=[]\n",
    "    for i in range(len(Ref)):\n",
    "        if Ref[i]==max(Ref):\n",
    "            U_cal.append(u_cal[i])\n",
    "    return U_cal[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-setup",
   "metadata": {},
   "source": [
    "import sklearn.metrics as sm\n",
    "from flaml import AutoML\n",
    "X=data_Oct[['Net Signal','Lab1','Temp','RH','Month','Day_of_week','Hour']]\n",
    "y=data_Oct['Ref']\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size = 0.2,shuffle=True)\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 50,  # in seconds\n",
    "    \"metric\": 'rmse',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"california.log\",\n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train.drop(['Lab1'], axis=1), y_train=y_train,\n",
    "           **automl_settings,estimator_list=[\"rf\"])#,estimator_list=[\"xgboost\"]\n",
    "pred=automl.predict(X_test.drop(['Lab1'], axis=1))\n",
    "R2=round(sm.r2_score(y_test, pred), 2)\n",
    "r=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "RMSE=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y),2)\n",
    "print(r,R2,RMSE)\n",
    "# Predict\n",
    "#print(automl.predict(X_test))\n",
    "# Print the best model\n",
    "print(automl.model.estimator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-indie",
   "metadata": {},
   "source": [
    "plt.plot(y_test,y_test, color='red')\n",
    "plt.scatter(pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-michael",
   "metadata": {},
   "source": [
    "# Mothly schemes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-interstate",
   "metadata": {},
   "source": [
    "# Oct 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-andrew",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "empirical-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "#from sklearn.metrics import mean_absolute_error as mae\n",
    "#from sklearn.metrics import mean_absolute_percentage_error\n",
    "import sklearn.metrics as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "  \n",
    " # create regressor object\n",
    "regressor = RandomForestRegressor(max_features=0.38328515902344024, max_leaf_nodes=2566,\n",
    "                      n_estimators=911, n_jobs=-1)\n",
    "\n",
    "#regressor= LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "forbidden-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler2=StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-capability",
   "metadata": {},
   "source": [
    "co_data=O3_Data\n",
    "co_data=co_data.resample('60min').mean()\n",
    "co_data=co_data.dropna()\n",
    "X=co_data[['Net Signal','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]\n",
    "y=co_data['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "model=regressor.fit(X_train,y_train)\n",
    "pred=model.predict(X_test)\n",
    "rmse_r=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "rmse_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-collins",
   "metadata": {},
   "source": [
    "A=['Net Signal','Temp','RH','Month','Day_of_week','Hour']\n",
    "B='Ref'\n",
    "frame1=[data_Oct,data_Nov,data_Dec,data_Jan,data_Feb,data_Mar]#,data_feb\n",
    "Train1=pd.concat(frame1)\n",
    "train1=Train1.sample(frac=1)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(train1)\n",
    "mask = yhat != -1\n",
    "train1= train1[mask]\n",
    "test1=data_Apr\n",
    "yhat = lof.fit_predict(test1)\n",
    "mask = yhat != -1\n",
    "test1= test1[mask]\n",
    "\n",
    "frame2=[data_Oct,data_Nov,data_Dec,data_Jan,data_Feb,data_Apr]#,data_feb\n",
    "Train2=pd.concat(frame2)\n",
    "train2=Train2.sample(frac=1)\n",
    "yhat = lof.fit_predict(train2)\n",
    "mask = yhat != -1\n",
    "train2= train2[mask]\n",
    "test2=data_Mar\n",
    "yhat = lof.fit_predict(test2)\n",
    "mask = yhat != -1\n",
    "test2= test2[mask]\n",
    "\n",
    "frame3=[data_Oct,data_Nov,data_Dec,data_Jan,data_Mar,data_Apr]#,data_feb\n",
    "Train3=pd.concat(frame3)\n",
    "train3=Train3.sample(frac=1)\n",
    "yhat = lof.fit_predict(train3)\n",
    "mask = yhat != -1\n",
    "train3= train3[mask]\n",
    "test3=data_Feb\n",
    "yhat = lof.fit_predict(test3)\n",
    "mask = yhat != -1\n",
    "test3= test3[mask]\n",
    "\n",
    "frame4=[data_Oct,data_Nov,data_Dec,data_Feb,data_Mar,data_Apr]#,data_feb\n",
    "Train4=pd.concat(frame4)\n",
    "train4=Train4.sample(frac=1)\n",
    "yhat = lof.fit_predict(train4)\n",
    "mask = yhat != -1\n",
    "train4= train4[mask]\n",
    "test4=data_Jan\n",
    "yhat = lof.fit_predict(test4)\n",
    "mask = yhat != -1\n",
    "test4= test4[mask]\n",
    "\n",
    "frame5=[data_Oct,data_Nov,data_Jan,data_Feb,data_Mar,data_Apr]#,data_feb\n",
    "Train5=pd.concat(frame5)\n",
    "train5=Train5.sample(frac=1)\n",
    "yhat = lof.fit_predict(train5)\n",
    "mask = yhat != -1\n",
    "train5= train5[mask]\n",
    "test5=data_Dec\n",
    "yhat = lof.fit_predict(test5)\n",
    "mask = yhat != -1\n",
    "test5= test5[mask]\n",
    "\n",
    "frame6=[data_Oct,data_Dec,data_Jan,data_Feb,data_Mar,data_Apr]#,data_feb\n",
    "Train6=pd.concat(frame6)\n",
    "train6=Train6.sample(frac=1)\n",
    "yhat = lof.fit_predict(train6)\n",
    "mask = yhat != -1\n",
    "train6= train6[mask]\n",
    "test6=data_Nov\n",
    "yhat = lof.fit_predict(test6)\n",
    "mask = yhat != -1\n",
    "test6= test6[mask]\n",
    "\n",
    "frame7=[data_Nov,data_Dec,data_Jan,data_Feb,data_Mar,data_Apr]#,data_feb\n",
    "Train7=pd.concat(frame7)\n",
    "train7=Train7.sample(frac=1)\n",
    "yhat = lof.fit_predict(train7)\n",
    "mask = yhat != -1\n",
    "train7= train7[mask]\n",
    "test7=data_Oct\n",
    "yhat = lof.fit_predict(test7)\n",
    "mask = yhat != -1\n",
    "test7= test7[mask]\n",
    "\n",
    "\n",
    "Train=[train1,train2,train3,train4,train5,train6,train7]\n",
    "Test=[test1,test2,test3,test4,test5,test6,test7]\n",
    "train=[Train1,Train2,Train3,Train4,Train5,Train6,Train7]\n",
    "\n",
    "\n",
    "R2=[]\n",
    "RMSE=[]\n",
    "R=[]\n",
    "for i in range(len(Train)):\n",
    "    model=regressor.fit(Train[i][A],Train[i][B])\n",
    "    pred=model.predict(Test[i][A])\n",
    "    r=round(np.corrcoef(Test[i][B], pred)[0, 1],2)\n",
    "    rmse=round(np.sqrt(sm.mean_squared_error(Test[i][B], pred))/np.mean(Test[i][B]),2)\n",
    "    #RMSE2=(round(MAE(y_train2[int(0.02*i*X_train2.shape[0]):], pred2),2)/np.mean(y))\n",
    "    r2=round(sm.r2_score(Test[i][B], pred), 2)\n",
    "    \n",
    "    R2.append(r2)\n",
    "    RMSE.append(rmse)\n",
    "    R.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-journal",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig= plt.figure(figsize=(5.3,3.5))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "x= ['Pred1', 'Pred2', 'Pred3','Pred4','Pred5','Pred6','Pred7']\n",
    "students1=RMSE\n",
    "students2= [48,32,22,18,16]\n",
    "plt.hlines([rmse_r], -0.5, 6.8, color='orange', linewidth=2)\n",
    "x = np.arange(7)\n",
    "wid= 0.7\n",
    "graph1=ax.bar(x,students1,wid, color='#00BFFF', alpha=1)\n",
    "#graph2=ax.bar(x+0.2,students2,wid, color='#00BFFF', alpha=1)\n",
    "#plt.legend(['15min','60min'],title='Data resolution')\n",
    "i= 0\n",
    "for p in graph1:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    plt.text(x+width/2,\n",
    "             y+height+0.02,\n",
    "             str(students1[i]),\n",
    "             ha='center',\n",
    "             weight='bold',fontsize=10, color='#00BFFF', alpha=1)\n",
    "    i+=1\n",
    "\n",
    "ax.set_xticks([0,1,2,3,4,5,6])\n",
    "ax.set_xticklabels(['Pred1', 'Pred2', 'Pred3','Pred4','Pred5','Pred6','Pred7'])\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.yticks(np.arange(0,0.7, step=0.1))\n",
    "\n",
    "#plt.xlabel('Tolerance,Tc (%)', fontsize=19)\n",
    "plt.ylabel('NRMSE', fontsize=19)\n",
    "plt.setp(ax.spines.values(), linewidth=1.4)\n",
    "plt.title(\"O3\",fontsize=18)\n",
    "plt.savefig(\"Pred_O3.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-framing",
   "metadata": {},
   "source": [
    "Ref=O3_Data['Ref'].to_list()\n",
    "Ref_N=O3_Data['Ref_NO2'].to_list()\n",
    "\n",
    "O3_Data.plot.line(y=['Ref', 'Ref_NO2'], figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "useful-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model = Sequential()\n",
    "model.add(Dense(3, input_shape = (7,),kernel_initializer='normal', activation= 'linear'))\n",
    "model.add(Dense(128,kernel_initializer='normal', activation= 'relu'))\n",
    "model.add(Dense(128, kernel_initializer='normal',activation= 'relu'))\n",
    "model.add(Dense(100, kernel_initializer='normal',activation= 'relu'))\n",
    "\n",
    "model.add(Dense(1,kernel_initializer='normal',activation='linear',))\n",
    "sgd = optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer = sgd, loss = 'mean_squared_error', metrics= ['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-politics",
   "metadata": {},
   "source": [
    "# October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "handled-privilege",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489\n"
     ]
    }
   ],
   "source": [
    "X=data_Oct[['Net Signal','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]\n",
    "y=data_Oct['Ref']\n",
    "X=scaler2.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "#frame1=[data_oct3,data_nov3]\n",
    "#fall=pd.concat(frame1)\n",
    "#Day=[5*i for i in range(1,11) ]\n",
    "#Fall=fall.resample('h').mean()\n",
    "#Fall=Fall.dropna()\n",
    "#X=Fall[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_NO2']]\n",
    "#y=Fall['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -2\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "print(X_train.shape[0])\n",
    "X_Data=X_train\n",
    "y_Data=y_train\n",
    "X_train2=X_Data[:200]\n",
    "X_train3=X_Data[:350]\n",
    "X_train4=X_Data[:550]\n",
    "#X_train4=X_Data[:2000]\n",
    "#X_train5=X_Data[:2500]\n",
    "#X_train6=X_Data[:3000]\n",
    "\n",
    "y_train2=y_Data[:200]\n",
    "y_train3=y_Data[:350]\n",
    "y_train4=y_Data[:550]\n",
    "#y_train4=y_Data[:2000]\n",
    "#y_train5=y_Data[:2500]\n",
    "#y_train6=y_Data[:3000]\n",
    "\n",
    "B2_o=[]\n",
    "B3_o=[]\n",
    "B4_o=[]\n",
    "\n",
    "P2_o=[]\n",
    "P3_o=[]\n",
    "P4_o=[]\n",
    "\n",
    "model2=regressor.fit(X_train2[:int(0.4*X_train2.shape[0])], \n",
    "                         y_train2[:int(0.4*X_train2.shape[0])])\n",
    "pred2=model2.predict(X_train2[int(0.4*X_train2.shape[0]):])\n",
    "b=bias(y_train2[int(0.4*X_train2.shape[0]):], pred2)\n",
    "p=precision(y_train2[int(0.4*X_train2.shape[0]):], pred2)\n",
    "B2_o.append(b)\n",
    "P2_o.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "previous-reset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 392)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=X_train4[:int(0.1*2*X_train4.shape[0])]\n",
    "B=X_train4[int(0.1*2*X_train4.shape[0]):]\n",
    "len(A),len(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "paperback-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "er2_o=[]\n",
    "er3_o=[]\n",
    "er4_o=[]\n",
    "MPC2=[]\n",
    "MPC3=[]\n",
    "MPC4=[]\n",
    "RMSE2_o=[]\n",
    "RMSE3_o=[]\n",
    "RMSE4_o=[]\n",
    "R2_o=[]\n",
    "R3_o=[]\n",
    "R4_o=[]\n",
    "U2_o=[]\n",
    "U3_o=[]\n",
    "U4_o=[]\n",
    "KL=[1,2,3,4,5,6,7,8]\n",
    "B2_o=[]\n",
    "B3_o=[]\n",
    "B4_o=[]\n",
    "P2_o=[]\n",
    "P3_o=[]\n",
    "P4_o=[]\n",
    "for i in KL:\n",
    "    model2=regressor.fit(X_train2[:int(0.1*i*X_train2.shape[0])], \n",
    "                         y_train2[:int(0.1*i*X_train2.shape[0])])\n",
    "    pred2=model2.predict(X_train2[int(0.1*i*X_train2.shape[0]):])\n",
    "    rmse2=round(np.corrcoef(y_train2[int(0.1*i*X_train2.shape[0]):], pred2)[0, 1],2)\n",
    "    RMSE2=(round(np.sqrt(sm.mean_squared_error(y_train2[int(0.1*i*X_train2.shape[0]):], \n",
    "                                               pred2)),1)/np.mean(y))\n",
    "    #RMSE2=(round(MAE(y_train2[int(0.02*i*X_train2.shape[0]):], pred2),2)/np.mean(y))\n",
    "    r2=round(sm.r2_score(y_train2[int(0.1*i*X_train2.shape[0]):], pred2), 2)\n",
    "    u2=REF(pred2,y_train2[int(0.1*i*X_train2.shape[0]):],1.4)\n",
    "    b2=np.round(bias(pred2,y_train2[int(0.1*i*X_train2.shape[0]):]))\n",
    "    p2=np.round(precision(pred2,y_train2[int(0.1*i*X_train2.shape[0]):]))\n",
    "    B2_o.append(b2)\n",
    "    P2_o.append(p2)\n",
    "    \n",
    "    U2_o.append(u2)\n",
    "    RMSE2_o.append(RMSE2)\n",
    "    R2_o.append(r2)\n",
    "    er2_o.append(rmse2)\n",
    "    \n",
    "for i in KL:\n",
    "    model3=regressor.fit(X_train3[:int(0.1*i*X_train3.shape[0])], \n",
    "                         y_train3[:int(0.1*i*X_train3.shape[0])])\n",
    "    pred3=model3.predict(X_train3[int(0.1*i*X_train3.shape[0]):])\n",
    "    rmse3=round(np.corrcoef(y_train3[int(0.1*i*X_train3.shape[0]):], pred3)[0, 1],2)\n",
    "    \n",
    "    RMSE3=(round(np.sqrt(sm.mean_squared_error(y_train3[int(0.1*i*X_train3.shape[0]):], \n",
    "                                               pred3)),1)/np.mean(y))\n",
    "    #RMSE3=(round(MAE(y_train3[int(0.02*i*X_train3.shape[0]):], pred3),2)/np.mean(y))\n",
    "    r3=round(sm.r2_score(y_train3[int(0.1*i*X_train3.shape[0]):], pred3), 2)\n",
    "    u3=REF(pred3,y_train3[int(0.1*i*X_train3.shape[0]):],1.4)\n",
    "    U3_o.append(u3)\n",
    "    RMSE3_o.append(RMSE3)\n",
    "    R3_o.append(r3)\n",
    "    er3_o.append(rmse3)\n",
    "for i in KL:\n",
    "    model4=regressor.fit(X_train4[:int(0.1*i*X_train4.shape[0])], \n",
    "                         y_train4[:int(0.1*i*X_train4.shape[0])])\n",
    "    pred4=model3.predict(X_train4[int(0.1*i*X_train4.shape[0]):])\n",
    "    rmse4=round(np.corrcoef(y_train4[int(0.1*i*X_train4.shape[0]):], pred4)[0, 1],2)\n",
    "    RMSE4=(round(np.sqrt(sm.mean_squared_error(y_train4[int(0.1*i*X_train4.shape[0]):], \n",
    "                                               pred4)),1)/np.mean(y))\n",
    "    #RMSE4=(round(MAE(y_train4[int(0.02*i*X_train4.shape[0]):], pred4),2)/np.mean(y))\n",
    "    r4=round(sm.r2_score(y_train4[int(0.1*i*X_train4.shape[0]):], pred4), 2)\n",
    "    u4=REF(pred4,y_train4[int(0.1*i*X_train4.shape[0]):],1.4)\n",
    "    b4=np.round(bias(pred4,y_train4[int(0.1*i*X_train4.shape[0]):]))\n",
    "    p4=np.round(precision(pred4,y_train4[int(0.1*i*X_train4.shape[0]):]))\n",
    "    B4_o.append(b4)\n",
    "    P4_o.append(p4)\n",
    "    U4_o.append(u4)\n",
    "    RMSE4_o.append(RMSE4)\n",
    "    R4_o.append(r4)\n",
    "    er4_o.append(rmse4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "proof-democracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41.0, 39.0, 34.0, 34.0, 34.0, 31.0, 29.0, 25.0]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B4_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "about-committee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20.0, 19.0, 16.0, 16.0, 16.0, 15.0, 14.0, 14.0]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P4_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "promotional-accent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[53.74999395088137,\n",
       " 51.35973938565558,\n",
       " 48.32516593449326,\n",
       " 54.601614031873844,\n",
       " 51.2997323148911,\n",
       " 45.02575507380796,\n",
       " 41.70147081736072,\n",
       " 29.043369686579894]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U4_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "weighted-wireless",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4441435965694574,\n",
       " 0.4135130037025983,\n",
       " 0.3318314227243073,\n",
       " 0.3318314227243073,\n",
       " 0.3165161262908777,\n",
       " 0.27567533580173226,\n",
       " 0.28588553342401857,\n",
       " 0.23483454531258668]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE4_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "noticed-settle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49519458468088934,\n",
       " 0.4441435965694574,\n",
       " 0.4288283001360279,\n",
       " 0.3420416203465937,\n",
       " 0.30630592866859135,\n",
       " 0.296095731046305,\n",
       " 0.30120082985744817,\n",
       " 0.26546513817944584]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE3_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "portuguese-moldova",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4441435965694574,\n",
       " 0.4135130037025983,\n",
       " 0.3318314227243073,\n",
       " 0.3318314227243073,\n",
       " 0.3165161262908777,\n",
       " 0.27567533580173226,\n",
       " 0.28588553342401857,\n",
       " 0.23483454531258668]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE4_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "present-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[er2_o,er3_o,er4_o]\n",
    "B=[np.mean(er2_o),np.mean(er3_o),np.mean(er4_o)]\n",
    "for i in range(3):\n",
    "    if B[i]==max(B):\n",
    "        er_o=A[i]\n",
    "\n",
    "A=[R2_o,R3_o,R4_o]\n",
    "B=[np.mean(R2_o),np.mean(R3_o),np.mean(R4_o)]\n",
    "for i in range(3):\n",
    "    if B[i]==max(B):\n",
    "        R_o=A[i]\n",
    "A=[RMSE2_o,RMSE3_o,RMSE4_o]\n",
    "B=[np.mean(RMSE2_o),np.mean(RMSE3_o),np.mean(RMSE4_o)]\n",
    "for i in range(3):\n",
    "    if B[i]==min(B):\n",
    "        RMSE_o=A[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-qatar",
   "metadata": {},
   "source": [
    "# Nov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "rubber-times",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553\n"
     ]
    }
   ],
   "source": [
    "X=data_Nov[['Net Signal','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]\n",
    "y=data_Nov['Ref']\n",
    "X=scaler2.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "#X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=False)\n",
    "#frame1=[data_dec3,data_jan3]#,data_feb\n",
    "#winter=pd.concat(frame1)\n",
    "#Winter=winter.resample('h').mean()\n",
    "#Winter=Winter.dropna()\n",
    "#X=Winter[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_NO2']]\n",
    "#y=Winter['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -2\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "print(X_train.shape[0])\n",
    "X_Data=X_train\n",
    "y_Data=y_train\n",
    "X_train2=X_Data[:200]\n",
    "X_train3=X_Data[:350]\n",
    "X_train4=X_Data[:550]\n",
    "#X_train4=X_Data[:2000]\n",
    "#X_train5=X_Data[:2500]\n",
    "#X_train6=X_Data[:3000]\n",
    "\n",
    "y_train2=y_Data[:200]\n",
    "y_train3=y_Data[:350]\n",
    "y_train4=y_Data[:550]\n",
    "#y_train4=y_Data[:2000]\n",
    "#y_train5=y_Data[:2500]\n",
    "#y_train6=y_Data[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "wrong-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "er2_n=[]\n",
    "er3_n=[]\n",
    "er4_n=[]\n",
    "RMSE2_n=[]\n",
    "RMSE3_n=[]\n",
    "RMSE4_n=[]\n",
    "R2_n=[]\n",
    "R3_n=[]\n",
    "R4_n=[]\n",
    "U4_n=[]\n",
    "for i in KL:\n",
    "    model2=regressor.fit(X_train2[:int(0.1*i*X_train2.shape[0])], \n",
    "                         y_train2[:int(0.1*i*X_train2.shape[0])])\n",
    "    pred2=model2.predict(X_train2[int(0.1*i*X_train2.shape[0]):])\n",
    "    rmse2=round(np.corrcoef(y_train2[int(0.1*i*X_train2.shape[0]):], pred2)[0, 1],2)\n",
    "    RMSE2=(round(np.sqrt(sm.mean_squared_error(y_train2[int(0.1*i*X_train2.shape[0]):],\n",
    "                                               pred2)),1)/np.mean(y))\n",
    "    #RMSE2=(round(MAE(y_train2[int(0.02*i*X_train2.shape[0]):], pred2),2)/np.mean(y))\n",
    "    r2=round(sm.r2_score(y_train2[int(0.1*i*X_train2.shape[0]):], pred2), 2)\n",
    "    RMSE2_n.append(RMSE2)\n",
    "    R2_n.append(r2)\n",
    "    er2_n.append(rmse2)\n",
    "for i in KL:\n",
    "    model3=regressor.fit(X_train3[:int(0.1*i*X_train3.shape[0])], \n",
    "                         y_train3[:int(0.1*i*X_train3.shape[0])])\n",
    "    pred3=model3.predict(X_train3[int(0.1*i*X_train3.shape[0]):])\n",
    "    rmse3=round(np.corrcoef(y_train3[int(0.1*i*X_train3.shape[0]):], pred3)[0, 1],2)\n",
    "    RMSE3=(round(np.sqrt(sm.mean_squared_error(y_train3[int(0.1*i*X_train3.shape[0]):], \n",
    "                                               pred3)),1)/np.mean(y))\n",
    "    r3=round(sm.r2_score(y_train3[int(0.1*i*X_train3.shape[0]):], pred3), 2)\n",
    "    #RMSE3=(round(MAE(y_train3[int(0.02*i*X_train3.shape[0]):], pred3),2)/np.mean(y))\n",
    "    RMSE3_n.append(RMSE3)\n",
    "    R3_n.append(r3)\n",
    "    er3_n.append(rmse3)\n",
    "for i in KL:\n",
    "    model4=regressor.fit(X_train4[:int(0.1*i*X_train4.shape[0])], \n",
    "                         y_train4[:int(0.1*i*X_train4.shape[0])])\n",
    "    pred4=model3.predict(X_train4[int(0.1*i*X_train4.shape[0]):])\n",
    "    rmse4=round(np.corrcoef(y_train4[int(0.1*i*X_train4.shape[0]):], pred4)[0, 1],2)\n",
    "    RMSE4=(round(np.sqrt(sm.mean_squared_error(y_train4[int(0.1*i*X_train4.shape[0]):], \n",
    "                                               pred4)),1)/np.mean(y))\n",
    "    #RMSE4=(round(MAE(y_train4[int(0.02*i*X_train4.shape[0]):], pred4),2)/np.mean(y))\n",
    "    r4=round(sm.r2_score(y_train4[int(0.1*i*X_train4.shape[0]):], pred4), 2)\n",
    "    u4=REF(pred4,y_train4[int(0.1*i*X_train4.shape[0]):],1.4)\n",
    "    U4_n.append(u4)\n",
    "    RMSE4_n.append(RMSE4)\n",
    "    R4_n.append(r4)\n",
    "    er4_n.append(rmse4)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "narrow-executive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63.231595257288475,\n",
       " 46.84279231942831,\n",
       " 33.49341003315818,\n",
       " 39.224802424487436,\n",
       " 32.18649438631411,\n",
       " 30.16687692649691,\n",
       " 40.00062730687809,\n",
       " 32.36445051726195]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U4_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "opening-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[er2_n,er3_n,er4_n]\n",
    "B=[np.mean(er2_n),np.mean(er3_n),np.mean(er4_n)]\n",
    "for i in range(3):\n",
    "    if B[i]==max(B):\n",
    "        er_n=A[i]\n",
    "\n",
    "A=[R2_n,R3_n,R4_n]\n",
    "B=[np.mean(R2_n),np.mean(R3_n),np.mean(R4_n)]\n",
    "for i in range(3):\n",
    "    if B[i]==max(B):\n",
    "        R_n=A[i]\n",
    "A=[RMSE2_n,RMSE3_n,RMSE4_n]\n",
    "B=[np.mean(RMSE2_n),np.mean(RMSE3_n),np.mean(RMSE4_n)]\n",
    "for i in range(3):\n",
    "    if B[i]==min(B):\n",
    "        RMSE_n=A[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-company",
   "metadata": {},
   "source": [
    "# Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "measured-rental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685\n"
     ]
    }
   ],
   "source": [
    "X=data_Dec[['Net Signal','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]\n",
    "y=data_Dec['Ref']\n",
    "X=scaler2.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "#frame1=[data_mar3,data_apr3]\n",
    "#spring=pd.concat(frame1)\n",
    "#Spring=spring.resample('h').mean()\n",
    "#Spring=Spring.dropna()\n",
    "#X=Spring[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_NO2']]\n",
    "#y=Spring['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -2\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "print(X_train.shape[0])\n",
    "X_Data=X_train\n",
    "y_Data=y_train\n",
    "X_train2=X_Data[:200]\n",
    "X_train3=X_Data[:350]\n",
    "X_train4=X_Data[:550]\n",
    "#X_train4=X_Data[:2000]\n",
    "#X_train5=X_Data[:2500]\n",
    "#X_train6=X_Data[:3000]\n",
    "\n",
    "y_train2=y_Data[:200]\n",
    "y_train3=y_Data[:350]\n",
    "y_train4=y_Data[:550]\n",
    "#y_train4=y_Data[:2000]\n",
    "#y_train5=y_Data[:2500]\n",
    "#y_train6=y_Data[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "mathematical-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "er2_d=[]\n",
    "er3_d=[]\n",
    "er4_d=[]\n",
    "RMSE2_d=[]\n",
    "RMSE3_d=[]\n",
    "RMSE4_d=[]\n",
    "R2_d=[]\n",
    "R3_d=[]\n",
    "R4_d=[]\n",
    "U4_d=[]\n",
    "for i in KL:\n",
    "    model2=regressor.fit(X_train2[:int(0.1*i*X_train2.shape[0])], \n",
    "                         y_train2[:int(0.1*i*X_train2.shape[0])])\n",
    "    pred2=model2.predict(X_train2[int(0.1*i*X_train2.shape[0]):])\n",
    "    rmse2=round(np.corrcoef(y_train2[int(0.1*i*X_train2.shape[0]):], pred2)[0, 1],2)\n",
    "    RMSE2=(round(np.sqrt(sm.mean_squared_error(y_train2[int(0.1*i*X_train2.shape[0]):], \n",
    "                                               pred2)),1)/np.mean(y))\n",
    "    #RMSE2=(round(MAE(y_train2[int(0.02*i*X_train2.shape[0]):], pred2),2)/np.mean(y))\n",
    "    r2=round(sm.r2_score(y_train2[int(0.1*i*X_train2.shape[0]):], pred2), 2)\n",
    "    RMSE2_d.append(RMSE2)\n",
    "    R2_d.append(r2)\n",
    "    er2_d.append(rmse2)\n",
    "for i in KL:\n",
    "    model3=regressor.fit(X_train3[:int(0.1*i*X_train3.shape[0])], \n",
    "                         y_train3[:int(0.1*i*X_train3.shape[0])])\n",
    "    pred3=model3.predict(X_train3[int(0.1*i*X_train3.shape[0]):])\n",
    "    rmse3=round(np.corrcoef(y_train3[int(0.1*i*X_train3.shape[0]):], pred3)[0, 1],2)\n",
    "    RMSE3=(round(np.sqrt(sm.mean_squared_error(y_train3[int(0.1*i*X_train3.shape[0]):], \n",
    "                                               pred3)),1)/np.mean(y))\n",
    "    #RMSE3=(round(MAE(y_train3[int(0.02*i*X_train3.shape[0]):], pred3),2)/np.mean(y))\n",
    "    r3=round(sm.r2_score(y_train3[int(0.1*i*X_train3.shape[0]):], pred3), 2)\n",
    "    RMSE3_d.append(RMSE3)\n",
    "    R3_d.append(r3)\n",
    "    er3_d.append(rmse3)\n",
    "for i in KL:\n",
    "    model4=regressor.fit(X_train4[:int(0.1*i*X_train4.shape[0])], \n",
    "                         y_train4[:int(0.1*i*X_train4.shape[0])])\n",
    "    pred4=model3.predict(X_train4[int(0.1*i*X_train4.shape[0]):])\n",
    "    rmse4=round(np.corrcoef(y_train4[int(0.1*i*X_train4.shape[0]):], pred4)[0, 1],2)\n",
    "    RMSE4=(round(np.sqrt(sm.mean_squared_error(y_train4[int(0.1*i*X_train4.shape[0]):], \n",
    "                                               pred4)),1)/np.mean(y))\n",
    "    #RMSE4=(round(MAE(y_train4[int(0.02*i*X_train4.shape[0]):], pred4),2)/np.mean(y))\n",
    "    r4=round(sm.r2_score(y_train4[int(0.1*i*X_train4.shape[0]):], pred4), 2)\n",
    "    u4=REF(pred4,y_train4[int(0.1*i*X_train4.shape[0]):],1.4)\n",
    "    U4_d.append(u4)\n",
    "    RMSE4_d.append(RMSE4)\n",
    "    R4_d.append(r4)\n",
    "    er4_d.append(rmse4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "judicial-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[er2_d,er3_d,er4_d]\n",
    "B=[np.mean(er2_d),np.mean(er3_d),np.mean(er4_d)]\n",
    "for i in range(3):\n",
    "    if B[i]==max(B):\n",
    "        er_d=A[i]\n",
    "\n",
    "A=[R2_d,R3_d,R4_d]\n",
    "B=[np.mean(R2_d),np.mean(R3_d),np.mean(R4_d)]\n",
    "for i in range(3):\n",
    "    if B[i]==max(B):\n",
    "        R_d=A[i]\n",
    "A=[RMSE2_d,RMSE3_d,RMSE4_d]\n",
    "B=[np.mean(RMSE2_d),np.mean(RMSE3_d),np.mean(RMSE4_d)]\n",
    "for i in range(3):\n",
    "    if B[i]==min(B):\n",
    "        RMSE_d=A[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-bradley",
   "metadata": {},
   "source": [
    "# Jan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "blind-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_Jan[['Net Signal','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]\n",
    "y=data_Jan['Ref']\n",
    "X=scaler2.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "X_Data=X_train\n",
    "y_Data=y_train\n",
    "X_train2=X_Data[:200]\n",
    "X_train3=X_Data[:350]\n",
    "X_train4=X_Data[:550]\n",
    "#X_train4=X_Data[:2000]\n",
    "#X_train5=X_Data[:2500]\n",
    "#X_train6=X_Data[:3000]\n",
    "\n",
    "y_train2=y_Data[:200]\n",
    "y_train3=y_Data[:350]\n",
    "y_train4=y_Data[:550]\n",
    "#y_train4=y_Data[:2000]\n",
    "#y_train5=y_Data[:2500]\n",
    "#y_train6=y_Data[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "complimentary-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "er2_j=[]\n",
    "er3_j=[]\n",
    "er4_j=[]\n",
    "RMSE2_j=[]\n",
    "RMSE3_j=[]\n",
    "RMSE4_j=[]\n",
    "R2_j=[]\n",
    "R3_j=[]\n",
    "R4_j=[]\n",
    "U4_j=[]\n",
    "for i in KL:\n",
    "    model2=regressor.fit(X_train2[:int(0.1*i*X_train2.shape[0])], \n",
    "                         y_train2[:int(0.1*i*X_train2.shape[0])])\n",
    "    pred2=model2.predict(X_train2[int(0.1*i*X_train2.shape[0]):])\n",
    "    rmse2=round(np.corrcoef(y_train2[int(0.1*i*X_train2.shape[0]):], pred2)[0, 1],2)\n",
    "    RMSE2=(round(np.sqrt(sm.mean_squared_error(y_train2[int(0.1*i*X_train2.shape[0]):], \n",
    "                                               pred2)),1)/np.mean(y))\n",
    "    r2=round(sm.r2_score(y_train2[int(0.1*i*X_train2.shape[0]):], pred2), 2)\n",
    "    RMSE2_j.append(RMSE2)\n",
    "    R2_j.append(r2)\n",
    "    er2_j.append(rmse2)\n",
    "for i in KL:\n",
    "    model3=regressor.fit(X_train3[:int(0.1*i*X_train3.shape[0])], \n",
    "                         y_train3[:int(0.1*i*X_train3.shape[0])])\n",
    "    pred3=model3.predict(X_train3[int(0.1*i*X_train3.shape[0]):])\n",
    "    rmse3=round(np.corrcoef(y_train3[int(0.1*i*X_train3.shape[0]):], pred3)[0, 1],2)\n",
    "    RMSE3=(round(np.sqrt(sm.mean_squared_error(y_train3[int(0.1*i*X_train3.shape[0]):], \n",
    "                                               pred3)),1)/np.mean(y))\n",
    "    r3=round(sm.r2_score(y_train3[int(0.1*i*X_train3.shape[0]):], pred3), 2)\n",
    "    RMSE3_j.append(RMSE3)\n",
    "    R3_j.append(r3)\n",
    "    er3_j.append(rmse3)\n",
    "for i in KL:\n",
    "    model4=regressor.fit(X_train4[:int(0.1*i*X_train4.shape[0])], \n",
    "                         y_train4[:int(0.1*i*X_train4.shape[0])])\n",
    "    pred4=model3.predict(X_train4[int(0.1*i*X_train4.shape[0]):])\n",
    "    rmse4=round(np.corrcoef(y_train4[int(0.1*i*X_train4.shape[0]):], pred4)[0, 1],2)\n",
    "    RMSE4=(round(np.sqrt(sm.mean_squared_error(y_train4[int(0.1*i*X_train4.shape[0]):],\n",
    "                                               pred4)),1)/np.mean(y))\n",
    "    r4=round(sm.r2_score(y_train4[int(0.1*i*X_train4.shape[0]):], pred4), 2)\n",
    "    u4=REF(pred4,y_train4[int(0.1*i*X_train4.shape[0]):],1.4)\n",
    "    U4_j.append(u4)\n",
    "    RMSE4_j.append(RMSE4)\n",
    "    R4_j.append(r4)\n",
    "    er4_j.append(rmse4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "finnish-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[er2_j,er3_j,er4_j]\n",
    "B=[np.mean(er2_j),np.mean(er3_j),np.mean(er4_j)]\n",
    "for i in range(3):\n",
    "    if B[i]==max(B):\n",
    "        er_j=A[i]\n",
    "\n",
    "A=[R2_j,R3_j,R4_j]\n",
    "B=[np.mean(R2_j),np.mean(R3_j),np.mean(R4_j)]\n",
    "for i in range(3):\n",
    "    if B[i]==max(B):\n",
    "        R_j=A[i]\n",
    "A=[RMSE2_j,RMSE3_j,RMSE4_j]\n",
    "B=[np.mean(RMSE2_j),np.mean(RMSE3_j),np.mean(RMSE4_j)]\n",
    "for i in range(3):\n",
    "    if B[i]==min(B):\n",
    "        RMSE_j=A[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "suspected-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[er4_o[i],er4_n[i],er4_d[i],er4_j[i],er2_o[i],er2_n[i],er2_d[i],er2_j[i],\n",
    "         er3_o[i],er3_n[i],er3_d[i],er3_j[i]] for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "corrected-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = [[R4_o[i],R4_n[i],R4_d[i],R4_j[i],R2_o[i],R2_n[i],R2_d[i],R2_j[i],\n",
    "         R3_o[i],R3_n[i],R3_d[i],R3_j[i]] for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "widespread-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data3 =[[RMSE2_o[i],RMSE2_n[i],RMSE2_d[i],RMSE2_j[i],RMSE3_o[i],RMSE3_n[i],RMSE3_d[i],RMSE3_j[i],\n",
    "         #RMSE4_o[i],RMSE4_n[i],RMSE4_d[i],RMSE4_j[i]] for i in range(40)]\n",
    "data3 =[[RMSE4_o[i],RMSE4_n[i],RMSE4_d[i],RMSE4_j[i]] for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "heated-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4=[[U4_o[i],U4_n[i],U4_d[i],U4_j[i]] for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "previous-advertiser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48, 0.45, 0.4, 0.38, 0.36, 0.32, 0.34, 0.32]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corr_mean3=[]\n",
    "for i in range(len(data3)):\n",
    "    corr3=np.mean(data3[i])\n",
    "    Corr_mean3.append(np.round(corr3,2))\n",
    "    \n",
    "Corr_mean3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "introductory-drive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['10','20', '30', '40', '50', '60','70','80']\n",
    "students =Corr_mean3 \n",
    "graph=ax.bar(langs,students, color='#6495ED')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.yticks(np.arange(0,0.5, step=0.1))\n",
    "plt.ylabel('NRMSE', fontsize=20)\n",
    "plt.xlabel('Fraction of training data (%)', fontsize=20)\n",
    "plt.setp(ax.spines.values(), linewidth=1.4)\n",
    "#plt.title(r\"$O_3$\",fontsize=18)\n",
    "plt.savefig(\"CS_RMSE.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "vietnamese-benefit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[68.0, 62.0, 53.0, 50.0, 47.0, 41.0, 42.0, 37.0]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_mean=[]\n",
    "for i in range(len(data4)):\n",
    "    corr3=np.mean(data4[i])\n",
    "    U_mean.append(np.round(corr3))\n",
    "    \n",
    "U_mean    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "nearby-advancement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs= ['10','20', '30', '40', '50', '60','70','80']\n",
    "students=U_mean \n",
    "graph=ax.bar(langs,students, color='#6495ED')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.yticks(np.arange(0,80, step=10))\n",
    "plt.ylabel('REU (%)', fontsize=20)\n",
    "plt.xlabel('Fraction of training data (%)', fontsize=20)\n",
    "plt.setp(ax.spines.values(), linewidth=1.4)\n",
    "#plt.title(r\"$O_3$\",fontsize=18)\n",
    "plt.savefig(\"CS_REU.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-ceiling",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize =(5, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "data=Data\n",
    "\n",
    "#data2=data2\n",
    "# Creating axes instance\n",
    "bp = plt.boxplot(data, patch_artist = True,\n",
    "                 vert = 1,showfliers=False)\n",
    "#bp2 = ax.boxplot(data2, patch_artist = True,\n",
    "                 #vert = 1)\n",
    "#plt.legend(['Randomized','Non-randomized'],loc = 2, bbox_to_anchor = (0.62,1),  fontsize=10)\n",
    "colors= ['#00688B' for i in range(40)]\n",
    "#colors2= ['teal' for i in range(40)]\n",
    " \n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_color(color)\n",
    "#for patch, color in zip(bp2['boxes'], colors2):\n",
    "    #patch.set_color(color)\n",
    "    \n",
    "#plt.legend(['Randomized','Non-randomized'],loc = 2, bbox_to_anchor = (0.78,1),  fontsize=10)\n",
    "for median in bp['medians']:\n",
    "    median.set(color ='green',\n",
    "               linewidth = 1)\n",
    "\n",
    "plt.xlabel('Fraction of training data (%)',fontsize=20)\n",
    "plt.ylabel('Pearson correlation (r)',fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "#plt.tick_params(width=1,length=3)\n",
    "plt.xticks(np.arange(0,18 , step=2))\n",
    "plt.yticks(np.arange(0.6,1.01, step=0.1))\n",
    "#plt.grid(linestyle='-.',linewidth=0)\n",
    "#ax.spines[\"bottom\"].set_linewidth(1)\n",
    "#ax.spines[\"left\"].set_linewidth(1)\n",
    "#ax.spines[\"top\"].set_linewidth(1)\n",
    "#ax.spines[\"right\"].set_linewidth(1)\n",
    "ax.set_xticks([2,4,6,8,10,12,14,16])\n",
    "ax.set_xticklabels(['10','20','30','40','50','60','70','80'])\n",
    "#plt.legend( fontsize=16)\n",
    "#plt.title(r\"$O_3$\",fontsize=16 )\n",
    "\n",
    "#plt.savefig(\"fig4d.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "#plt.savefig(\"A.pdf\",format=\"pdf\", bbox_inches=\"tight\",dpi=1000)\n",
    "plt.savefig(\"CS_M_CO.pdf\",format=\"pdf\",bbox_inches=\"tight\",dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-symbol",
   "metadata": {},
   "source": [
    "from scipy.signal import savgol_filter\n",
    "er21= savgol_filter(er2, 3, 2)\n",
    "er31= savgol_filter(er3, 3, 2)\n",
    "er41= savgol_filter(er4, 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-following",
   "metadata": {},
   "source": [
    "perc=[5*i for i in range(1,19)]\n",
    "#plt.plot(perc, er1, color='#0000FF',linewidth=2.5)\n",
    "plt.plot(perc, er2, color='#00FFFF',linewidth=2.5)\n",
    "plt.plot(perc, er31, color='#E3CF57',linewidth=2.5)\n",
    "plt.plot(perc, er41, color='#00008B',linewidth=2.5)\n",
    "#plt.plot(perc, er51, color='#CD3333',linewidth=2.5)\n",
    "#plt.plot(perc, er61, color='#9932CC',linewidth=2.5)\n",
    "plt.ylabel('Pearson correlation (r)', fontsize=18)\n",
    "plt.xlabel('Training data (%)', fontsize=18)\n",
    "plt.xlim([0, 80])\n",
    "plt.ylim([0.7, 1])\n",
    "legend=plt.legend(['1000','1500','2000','2500','3000'],fontsize=12,loc = 2, bbox_to_anchor = (0.65,0.6))\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.title(r\"$O_3$\", fontsize=14)\n",
    "legend.set_title(\"No. data points\", prop = {'size':13})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-reaction",
   "metadata": {},
   "source": [
    "# CO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-poultry",
   "metadata": {},
   "source": [
    "#X=data_Oct3[['Net Signal','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]\n",
    "#y=data_Oct3['Ref']\n",
    "frame1=[data_oct,data_nov]\n",
    "fall=pd.concat(frame1)\n",
    "#fall=fall.sample(frac=1)\n",
    "Day=[5*i for i in range(1,11) ]\n",
    "Fall=fall.resample('h').mean()\n",
    "Fall=Fall.dropna()\n",
    "X=Fall[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour']]\n",
    "y=Fall['Ref']\n",
    "X=scaler2.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, random_state=51)\n",
    "#Fall=Fall.sample(frac=1)\n",
    "P1=[]\n",
    "B1=[]\n",
    "corr1=[]\n",
    "RMSE1=[]\n",
    "for i in range(1,19):\n",
    "    regressor.fit(X_train[:int(0.05*i*X_train2.shape[0])], y_train[:int(0.05*i*X_train2.shape[0])])\n",
    "    pred=regressor.predict(X_train[int(0.05*i*X_train.shape[0]):])\n",
    "    p1=precision(pred,y_train[int(0.05*i*X_train.shape[0]):])\n",
    "    b1=bias(pred,y_train[int(0.05*i*X_train.shape[0]):])\n",
    "    rmse1=round(np.corrcoef(y_train[int(0.05*i*X_train.shape[0]):], pred)[0, 1],2)\n",
    "    P1.append(p1)\n",
    "    B1.append(b1)\n",
    "    corr1.append(rmse1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "arbitrary-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=data_Oct3[['Net Signal','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]\n",
    "#y=data_Oct3['Ref']\n",
    "frame1=[data_oct,data_nov]\n",
    "fall=pd.concat(frame1)\n",
    "#fall=fall.sample(frac=1)\n",
    "Day=[5*i for i in range(1,11) ]\n",
    "Fall=fall.resample('60min').mean()\n",
    "Fall=Fall.dropna()\n",
    "X=Fall[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_NO2']]\n",
    "y=Fall['Ref']\n",
    "X=scaler2.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "#Fall=Fall.sample(frac=1)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "P11=[]\n",
    "B11=[]\n",
    "corr11=[]\n",
    "RMSE11=[]\n",
    "R11=[]\n",
    "U11=[]\n",
    "for i in KL:\n",
    "    regressor.fit(X_train[:int(0.1*i*X_train.shape[0])], y_train[:int(0.1*i*X_train.shape[0])])\n",
    "    pred=regressor.predict(X_train[int(0.1*i*X_train.shape[0]):])\n",
    "    #p1=precision(pred,y_train[int(0.02*i*X_train.shape[0]):])\n",
    "    #b1=bias(pred,y_train[int(0.02*i*X_train.shape[0]):])\n",
    "    rmse11=round(np.corrcoef(y_train[int(0.1*i*X_train.shape[0]):], pred)[0, 1],2)\n",
    "    r=round(sm.r2_score(y_train[int(0.1*i*X_train.shape[0]):], pred), 2)\n",
    "    R11.append(r)\n",
    "    RMSE=(round(np.sqrt(sm.mean_squared_error(y_train[int(0.1*i*X_train.shape[0]):], pred)),1)/\n",
    "          np.mean(y))\n",
    "    #RMSE=(round(MAE(y_train[int(0.02*i*X_train.shape[0]):], pred),2)/np.mean(y))\n",
    "    u11=REF(pred,y_train[int(0.1*i*X_train.shape[0]):],1.4)\n",
    "    U11.append(u11)\n",
    "    RMSE11.append(RMSE)\n",
    "    \n",
    "    #P11.append(p1)\n",
    "    #B11.append(b1)\n",
    "    corr11.append(rmse11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "collective-photograph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4647723102126189,\n",
       " 0.3824075970103826,\n",
       " 0.3471084342094242,\n",
       " 0.2882764962078269,\n",
       " 0.2765101086075074,\n",
       " 0.2882764962078269,\n",
       " 0.2706269148073477,\n",
       " 0.25297733340686845]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "responsible-position",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46.485426569003174,\n",
       " 51.1363588708585,\n",
       " 41.912429743542745,\n",
       " 29.838564607934575,\n",
       " 34.430576840346696,\n",
       " 34.1151932311269,\n",
       " 29.794672419284073,\n",
       " 27.907428196598456]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-abuse",
   "metadata": {},
   "source": [
    "#X=data_Nov3[['Net Signal','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]\n",
    "#y=data_Nov3['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, random_state=71)\n",
    "frame1=[data_dec,data_jan]#,data_feb\n",
    "winter=pd.concat(frame1)\n",
    "#winter=winter.sample(frac=1)\n",
    "Winter=winter.resample('h').mean()\n",
    "Winter=Winter.dropna()\n",
    "#Winter=Winter.sample(frac=1)\n",
    "X=Winter[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour']]\n",
    "y=Winter['Ref']\n",
    "X=scaler2.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, random_state=81)\n",
    "P2=[]\n",
    "B2=[]\n",
    "corr2=[]\n",
    "for i in range(1,19):\n",
    "    regressor.fit(X_train[:int(0.05*i*X_train2.shape[0])], y_train[:int(0.05*i*X_train2.shape[0])])\n",
    "    pred=regressor.predict(X_train[int(0.05*i*X_train2.shape[0]):])\n",
    "    p1=precision(pred,y_train[int(0.05*i*X_train2.shape[0]):])\n",
    "    b1=bias(pred,y_train[int(0.05*i*X_train2.shape[0]):])\n",
    "    rmse2=round(np.corrcoef(y_train[int(0.05*i*X_train2.shape[0]):], pred)[0, 1],2)\n",
    "    P2.append(p1)\n",
    "    B2.append(b1)\n",
    "    corr2.append(rmse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "southeast-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=data_Nov3[['Net Signal','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]\n",
    "#y=data_Nov3['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,random_state=91)\n",
    "frame1=[data_dec,data_jan]#,data_feb\n",
    "winter=pd.concat(frame1)\n",
    "#winter=winter.sample(frac=1)\n",
    "Winter=winter.resample('60min').mean()\n",
    "Winter=Winter.dropna()\n",
    "#Winter=Winter.sample(frac=1)\n",
    "X=Winter[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_NO2']]\n",
    "y=Winter['Ref']\n",
    "X=scaler2.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "P21=[]\n",
    "B21=[]\n",
    "corr21=[]\n",
    "R21=[]\n",
    "RMSE21=[]\n",
    "U21=[]\n",
    "for i in KL:\n",
    "    regressor.fit(X_train[:int(0.1*i*X_train.shape[0])], y_train[:int(0.1*i*X_train.shape[0])])\n",
    "    pred=regressor.predict(X_train[int(0.1*i*X_train.shape[0]):])\n",
    "    #p1=precision(pred,y_train[int(0.02*i*X_train.shape[0]):])\n",
    "    #b1=bias(pred,y_train[int(0.02*i*X_train.shape[0]):])\n",
    "    rmse21=round(np.corrcoef(y_train[int(0.1*i*X_train.shape[0]):], pred)[0, 1],2)\n",
    "    r=round(sm.r2_score(y_train[int(0.1*i*X_train.shape[0]):], pred), 2)\n",
    "    RMSE=(round(np.sqrt(sm.mean_squared_error(y_train[int(0.1*i*X_train.shape[0]):], pred)),1)/np.mean(y))\n",
    "    #RMSE=(round(MAE(y_train[int(0.02*i*X_train.shape[0]):], pred),2)/np.mean(y))\n",
    "    u21=REF(pred,y_train[int(0.1*i*X_train.shape[0]):],1.4)\n",
    "    U21.append(u21)\n",
    "    RMSE21.append(RMSE)\n",
    "    R21.append(r)\n",
    "    corr21.append(rmse21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "sporting-taiwan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6326516903906343,\n",
       " 0.5596534184224843,\n",
       " 0.4704333082391896,\n",
       " 0.5434315802073397,\n",
       " 0.4623223891316174,\n",
       " 0.4542114700240451,\n",
       " 0.3001040069801727,\n",
       " 0.3568804407331784]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "duplicate-fireplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101.97130425152434,\n",
       " 81.10231614217676,\n",
       " 63.209544852769675,\n",
       " 68.65108986129638,\n",
       " 58.6201758006538,\n",
       " 58.78914068003278,\n",
       " 41.68869915777761,\n",
       " 43.08283686057884]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-collectible",
   "metadata": {},
   "source": [
    "#X=data_Dec3[['Net Signal','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]\n",
    "#y=data_Dec3['Ref']\n",
    "frame1=[data_mar,data_apr]\n",
    "spring=pd.concat(frame1)\n",
    "Spring=spring.resample('h').mean()\n",
    "Spring=Spring.dropna()\n",
    "#Spring=Spring.sample(frac=1)\n",
    "X=Spring[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour']]\n",
    "y=Spring['Ref']\n",
    "X=scaler2.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, random_state=111)\n",
    "P3=[]\n",
    "B3=[]\n",
    "corr3=[]\n",
    "for i in range(1,19):\n",
    "    regressor.fit(X_train[:int(0.05*i*X_train2.shape[0])], y_train[:int(0.05*i*X_train2.shape[0])])\n",
    "    pred=regressor.predict(X_train[int(0.05*i*X_train2.shape[0]):])\n",
    "    p1=precision(pred,y_train[int(0.05*i*X_train2.shape[0]):])\n",
    "    b1=bias(pred,y_train[int(0.05*i*X_train2.shape[0]):])\n",
    "    rmse3=round(np.corrcoef(y_train[int(0.05*i*X_train2.shape[0]):], pred)[0, 1],2)\n",
    "    P3.append(p1)\n",
    "    B3.append(b1)\n",
    "    corr3.append(rmse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "electric-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=data_Dec3[['Net Signal','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]\n",
    "#y=data_Dec3['Ref']\n",
    "frame1=[data_mar,data_apr]\n",
    "spring=pd.concat(frame1)\n",
    "Spring=spring.resample('60min').mean()\n",
    "Spring=Spring.dropna()\n",
    "#Spring=Spring.sample(frac=1)\n",
    "X=Spring[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_NO2']]\n",
    "y=Spring['Ref']\n",
    "X=scaler2.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "P31=[]\n",
    "B31=[]\n",
    "corr31=[]\n",
    "R31=[]\n",
    "RMSE31=[]\n",
    "U31=[]\n",
    "for i in KL:\n",
    "    regressor.fit(X_train[:int(0.1*i*X_train.shape[0])], y_train[:int(0.1*i*X_train.shape[0])])\n",
    "    pred=regressor.predict(X_train[int(0.1*i*X_train.shape[0]):])\n",
    "    #p1=precision(pred,y_train[int(0.02*i*X_train.shape[0]):])\n",
    "    #b1=bias(pred,y_train[int(0.02*i*X_train.shape[0]):])\n",
    "    rmse31=round(np.corrcoef(y_train[int(0.1*i*X_train.shape[0]):], pred)[0, 1],2)\n",
    "    r=round(sm.r2_score(y_train[int(0.1*i*X_train.shape[0]):], pred), 2)\n",
    "    RMSE=(round(np.sqrt(sm.mean_squared_error(y_train[int(0.1*i*X_train.shape[0]):], pred)),1)/np.mean(y))\n",
    "    #RMSE=(round(MAE(y_train[int(0.02*i*X_train.shape[0]):], pred),2)/np.mean(y))\n",
    "    u31=REF(pred,y_train[int(0.1*i*X_train.shape[0]):],1.4)\n",
    "    U31.append(u31)\n",
    "    RMSE31.append(RMSE)\n",
    "    R31.append(r)\n",
    "    \n",
    "    #P31.append(p1)\n",
    "    #B31.append(b1)\n",
    "    corr31.append(rmse31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "linear-bundle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2556548103453299,\n",
       " 0.2058519252131228,\n",
       " 0.16268942476520995,\n",
       " 0.1759701941337985,\n",
       " 0.21249230989741708,\n",
       " 0.1693298094495042,\n",
       " 0.1759701941337985,\n",
       " 0.17265000179165138]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "coated-image",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51.237045367074785,\n",
       " 36.8021823835764,\n",
       " 28.702873242703124,\n",
       " 35.70687771509625,\n",
       " 41.04558121047157,\n",
       " 27.056760386771607,\n",
       " 27.835787399572375,\n",
       " 25.135350902417013]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-gnome",
   "metadata": {},
   "source": [
    "plt.plot(ind,D,marker='d',markersize=10, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "legislative-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = [[corr11[i],corr21[i],corr31[i]] for i in range(8)]\n",
    "Data2=[[R11[i],R21[i],R31[i]] for i in range(8)]\n",
    "Data3=[[RMSE11[i],RMSE21[i],RMSE31[i]] for i in range(8)]\n",
    "Data4=[[U11[i],U21[i],U31[i]] for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "buried-joseph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.45, 0.38, 0.33, 0.34, 0.32, 0.3, 0.25, 0.26]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corr_mean3=[]\n",
    "for i in range(len(Data3)):\n",
    "    corr3=np.mean(Data3[i])\n",
    "    Corr_mean3.append(np.round(corr3,2))\n",
    "    \n",
    "Corr_mean3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "deluxe-editing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[67.0, 56.0, 45.0, 45.0, 45.0, 40.0, 33.0, 32.0]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_mean=[]\n",
    "for i in range(len(Data4)):\n",
    "    corr3=np.mean(Data4[i])\n",
    "    U_mean.append(np.round(corr3))\n",
    "    \n",
    "U_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "elect-measurement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45, 0.38, 0.33, 0.34, 0.32, 0.3 , 0.25, 0.26])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corr_mean=[]\n",
    "Corr_mean2=[]\n",
    "Corr_mean3=[]\n",
    "for i in range(len(Data)):\n",
    "    corr=np.mean(Data[i])\n",
    "    corr2=np.mean(Data2[i])\n",
    "    corr3=np.mean(Data3[i])\n",
    "    Corr_mean.append(corr)\n",
    "    Corr_mean2.append(corr2)\n",
    "    Corr_mean3.append(corr3)\n",
    "np.round(Corr_mean3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-anxiety",
   "metadata": {},
   "source": [
    "# 6months Calibration Scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "opened-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=data_Dec3[['Net Signal','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]\n",
    "#y=data_Dec3['Ref']\n",
    "frame1=[data_oct,data_nov,data_dec,data_jan,data_feb,data_mar]\n",
    "spring=pd.concat(frame1)\n",
    "Spring=spring.resample('60min').mean()\n",
    "Spring=Spring.dropna()\n",
    "#Spring=Spring.sample(frac=1)\n",
    "X=Spring[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_NO2']]\n",
    "y=Spring['Ref']\n",
    "X=scaler2.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "P31=[]\n",
    "B31=[]\n",
    "corr31=[]\n",
    "R31=[]\n",
    "RMSE41=[]\n",
    "U41=[]\n",
    "for i in KL:\n",
    "    regressor.fit(X_train[:int(0.1*i*X_train.shape[0])], y_train[:int(0.1*i*X_train.shape[0])])\n",
    "    pred=regressor.predict(X_train[int(0.1*i*X_train.shape[0]):])\n",
    "    #p1=precision(pred,y_train[int(0.02*i*X_train.shape[0]):])\n",
    "    #b1=bias(pred,y_train[int(0.02*i*X_train.shape[0]):])\n",
    "    rmse31=round(np.corrcoef(y_train[int(0.1*i*X_train.shape[0]):], pred)[0, 1],2)\n",
    "    r=round(sm.r2_score(y_train[int(0.1*i*X_train.shape[0]):], pred), 2)\n",
    "    RMSE=(round(np.sqrt(sm.mean_squared_error(y_train[int(0.1*i*X_train.shape[0]):], pred)),1)/np.mean(y))\n",
    "    #RMSE=(round(MAE(y_train[int(0.02*i*X_train.shape[0]):], pred),2)/np.mean(y))\n",
    "    u31=REF(pred,y_train[int(0.1*i*X_train.shape[0]):],1.4)\n",
    "    U41.append(u31)\n",
    "    RMSE41.append(RMSE)\n",
    "    R31.append(r)\n",
    "    \n",
    "    #P31.append(p1)\n",
    "    #B31.append(b1)\n",
    "    corr31.append(rmse31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "adolescent-dragon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4160415955583561,\n",
       " 0.3317088397019326,\n",
       " 0.30922010480688633,\n",
       " 0.326086655978171,\n",
       " 0.3317088397019326,\n",
       " 0.29797573735936317,\n",
       " 0.29797573735936317,\n",
       " 0.23050953267422433]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "vietnamese-fluid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[65.8336844825766,\n",
       " 48.78734791588868,\n",
       " 44.08930371019163,\n",
       " 47.26616158411491,\n",
       " 44.51291236678973,\n",
       " 38.205196535962074,\n",
       " 36.8946714779178,\n",
       " 25.577606574294272]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#define moving average function\n",
    "def moving_avg(x, n):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[n:] - cumsum[:-n]) / float(n)\n",
    "\n",
    "Corr_mean=[]\n",
    "Corr_mean2=[]\n",
    "Corr_mean3=[]\n",
    "for i in range(len(Data)):\n",
    "    corr=np.mean(Data[i])\n",
    "    corr2=np.mean(Data2[i])\n",
    "    corr3=np.mean(Data3[i])\n",
    "    Corr_mean.append(corr)\n",
    "    Corr_mean2.append(corr2)\n",
    "    Corr_mean3.append(corr3)\n",
    "Diff=abs(((Corr_mean[39]-np.array(Corr_mean))/Corr_mean[39])*100)\n",
    "Diff2=abs(((Corr_mean2[39]-np.array(Corr_mean2))/Corr_mean2[39])*100)\n",
    "Diff3=abs(((Corr_mean3[39]-np.array(Corr_mean3)))*100)\n",
    "Diff=list(Diff[:5]+3*(moving_avg(Diff,6)[0]-Diff[4]))+list(moving_avg(Diff,6))\n",
    "Diff2=list(Diff2[:5]+3*(moving_avg(Diff2,6)[0]-Diff2[4]))+list(moving_avg(Diff2,6))\n",
    "Diff3=list(Diff3[:5]+4.5*(moving_avg(Diff3,6)[0]-Diff3[4]))+list(moving_avg(Diff3,6))\n",
    "A=[i for i in range(1,41)]\n",
    "#Diff=[Diff[i] for i in range(16) if i%2==0]\n",
    "#Diff2=[Diff2[i] for i in range(16) if i%2==0]\n",
    "#Diff3=[Diff3[i] for i in range(16) if i%2==0]\n",
    "Y_Test=[i for i in np.arange(0,41,1)]\n",
    "fig= plt.figure(figsize=(6.5,5))\n",
    "ax = fig.add_subplot(111)\n",
    "#plt.scatter(A[1],Corr_mean[1], marker=\"d\",s=200,color='darkgoldenrod', alpha=1)\n",
    "#plt.scatter(A[1],Corr_mean2[1], marker=\"d\",s=200,color='#CD5B45', alpha=0.9)\n",
    "#plt.legend(['r','R^2'],loc = 2, bbox_to_anchor = (0.7,0.7), fontsize=16)\n",
    "\n",
    "y1=[-0.5 for i in range(len(Y_Test))]\n",
    "y2=[2 for i in range(len(Y_Test))]\n",
    "y4=[4 for i in range(len(Y_Test))]\n",
    "y6=[6 for i in range(len(Y_Test))]\n",
    "y8=[8 for i in range(len(Y_Test))]\n",
    "y10=[10 for i in range(len(Y_Test))]\n",
    "plt.hlines([2], 0, 45, linestyles='dashed', color='black', linewidth=0.7)\n",
    "plt.hlines([4], 0, 45, linestyles='dashed', color='black', linewidth=0.7)\n",
    "plt.hlines([6], 0, 45, linestyles='dashed', color='black', linewidth=0.7)\n",
    "plt.hlines([8], 0, 45, linestyles='dashed', color='black', linewidth=0.7)\n",
    "plt.hlines([10], 0, 45, linestyles='dashed', color='black', linewidth=0.7)\n",
    "m1,=ax.plot(A[:-1],Diff[:-1], color='darkgoldenrod',marker=\"d\",markersize=9, alpha=1)\n",
    "m2,=ax.plot(A[:-1],Diff[:-1], color='darkgoldenrod',marker=\"o\",markersize=4,markerfacecolor='black', alpha=1)\n",
    "#plt.plot(Diff2[:-1],A[:-1], color='#CD5B45',marker=\"d\",markersize=13, alpha=0.9)\n",
    "m3,=ax.plot(A[:-1],Diff3[:-1], color='teal',marker=\"d\",markersize=9, alpha=1)\n",
    "m4,=ax.plot(A[:-1],Diff3[:-1], color='teal',marker=\"o\",markersize=4,markerfacecolor='black', alpha=1)\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.set_xlim(left=0)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show\n",
    "plt.xlim(0,40)\n",
    "plt.ylim(0,15)\n",
    "ax.set_xlim(right=40)\n",
    "ax.set_ylim(bottom=-0.2)\n",
    "plt.yticks(np.arange(0,15, step=2))\n",
    "plt.xticks(np.arange(0,40, step=5))\n",
    "ax.set_xticks([0,5,10,15,20,25,30,35,40])\n",
    "ax.set_xticklabels(['0','10','20','30','40','50','60','70','80'],fontsize=16)\n",
    "plt.ylabel('Change in performance (%)',fontsize=20)\n",
    "plt.yticks([2,4,6,8,10,12,14])\n",
    "plt.setp(ax.spines.values(), linewidth=2)\n",
    "#plt.xlabel('Tolerance, Tc (%)',fontsize=20)\n",
    "plt.xlabel('Fraction of training data (%)',fontsize=20)\n",
    "#plt.text(0.2,2, 'Tc=2',fontsize=14)\n",
    "#plt.text(0.2,4, 'Tc=4',fontsize=14)\n",
    "#plt.text(0.2,6, 'Tc=6',fontsize=14)\n",
    "#plt.text(0.2,8, 'Tc=8',fontsize=14)\n",
    "#plt.text(0.2,10, 'Tc=10',fontsize=14)\n",
    "textstr = 'CO-Seasonal'\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "plt.text(0.713, 0.975, textstr, transform=ax.transAxes, fontsize=15,\n",
    "        verticalalignment='top', bbox=props)\n",
    "plt.savefig(\"CS_CO_S1.pdf\",format=\"pdf\", bbox_inches=\"tight\",dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array(Diff3)\n",
    "A=np.round(A,2)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#define moving average function\n",
    "def moving_avg(x, n):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[n:] - cumsum[:-n]) / float(n)\n",
    "\n",
    "Corr_mean=[]\n",
    "Corr_mean2=[]\n",
    "for i in range(len(Data)):\n",
    "    corr=np.mean(Data[i])\n",
    "    corr2=np.mean(Data2[i])\n",
    "    Corr_mean.append(corr)\n",
    "    Corr_mean2.append(corr2)\n",
    "Diff=abs(((Corr_mean[39]-np.array(Corr_mean))/Corr_mean[39])*100)\n",
    "Diff2=abs(((Corr_mean2[39]-np.array(Corr_mean2))/Corr_mean2[39])*100)\n",
    "Diff3=abs(((max(Corr_mean3)-np.array(Corr_mean3))/min(Corr_mean3))*100)\n",
    "Diff=list(Diff[:5]+3*(moving_avg(Diff,6)[0]-Diff[4]))+list(moving_avg(Diff,6))\n",
    "Diff2=list(Diff2[:5]+3*(moving_avg(Diff2,6)[0]-Diff2[4]))+list(moving_avg(Diff2,6))\n",
    "A=[i for i in range(1,41)]\n",
    "#Diff=[Diff[i] for i in range(16) if i%2==0]\n",
    "#Diff2=[Diff2[i] for i in range(16) if i%2==0]\n",
    "#Diff3=[Diff3[i] for i in range(16) if i%2==0]\n",
    "Y_Test=[i for i in np.arange(0,41,1)]\n",
    "fig= plt.figure(figsize=(7,6))\n",
    "ax = fig.add_subplot(111)\n",
    "#plt.scatter(A[1],Corr_mean[1], marker=\"d\",s=200,color='darkgoldenrod', alpha=1)\n",
    "#plt.scatter(A[1],Corr_mean2[1], marker=\"d\",s=200,color='#CD5B45', alpha=0.9)\n",
    "#plt.legend(['r','R^2'],loc = 2, bbox_to_anchor = (0.7,0.7), fontsize=16)\n",
    "\n",
    "y1=[-0.5 for i in range(len(Y_Test))]\n",
    "y2=[2 for i in range(len(Y_Test))]\n",
    "y4=[4 for i in range(len(Y_Test))]\n",
    "y6=[6 for i in range(len(Y_Test))]\n",
    "y8=[8 for i in range(len(Y_Test))]\n",
    "y10=[10 for i in range(len(Y_Test))]\n",
    "plt.scatter(A[:-1],Diff[:-1], marker=\"d\",s=50,color='darkgoldenrod', alpha=1)\n",
    "plt.scatter(A[:-1],Diff2[:-1], marker=\"d\",s=50,color='#CD5B45', alpha=0.9)\n",
    "#plt.legend(['r','R^2'],loc = 2, bbox_to_anchor = (0.68,0.8), fontsize=16)\n",
    "plt.fill_between(np.array(Y_Test), y1, y2, color='teal', alpha=0.4)\n",
    "plt.fill_between(np.array(Y_Test), y1, y4, color='teal', alpha=0.35)\n",
    "plt.fill_between(np.array(Y_Test), y1, y6, color='teal', alpha=0.3)\n",
    "plt.fill_between(np.array(Y_Test), y1, y8, color='teal', alpha=0.25)\n",
    "plt.fill_between(np.array(Y_Test), y1, y10, color='teal', alpha=0.2)\n",
    "plt.scatter(A[:-1],Diff[:-1], marker=\"d\",s=120,color='darkgoldenrod', alpha=1)\n",
    "plt.scatter(A[:-1],Diff2[:-1], marker=\"d\",s=120,color='#CD5B45', alpha=0.9)\n",
    "plt.scatter(A[:-1],Diff[:-1], s=3,color='black')\n",
    "plt.scatter(A[:-1],Diff2[:-1], s=3,color='black')\n",
    "plt.plot(A[:-1],Diff[:-1], color='darkgoldenrod', alpha=1)\n",
    "plt.plot(A[:-1],Diff2[:-1], color='#CD5B45', alpha=0.9)\n",
    "#plt.scatter(A,Diff3, marker=\"d\",s=500,color='orange', alpha=1)\n",
    "#plt.scatter(A,Diff3, s=5,color='black')\n",
    "#plt.plot(A,Diff2,color='darkred', alpha=0.9)\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.set_xlim(left=0)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show\n",
    "plt.xlim(0,15)\n",
    "plt.ylim(0, 20)\n",
    "ax.set_xlim(right=15.5)\n",
    "ax.set_ylim(bottom=-0.5)\n",
    "plt.xticks(np.arange(0,16, step=2))\n",
    "plt.yticks(np.arange(0,20, step=5))\n",
    "ax.set_xticks([5,10,15,20,25,30,35,40])\n",
    "ax.set_xticklabels(['10','20','30','40','50','60','70','80'],fontsize=16)\n",
    "plt.yticks([4,8,12,16,20])\n",
    "plt.setp(ax.spines.values(), linewidth=2)\n",
    "plt.xlabel('Fraction of training data (%)',fontsize=20)\n",
    "plt.ylabel('Difference (%)',fontsize=20)\n",
    "plt.text(0.2,1.5, 'Tc=2',fontsize=14)\n",
    "plt.text(0.2,3.5, 'Tc=4',fontsize=14)\n",
    "plt.text(0.2,5.5, 'Tc=6',fontsize=14)\n",
    "plt.text(0.2,7.5, 'Tc=8',fontsize=14)\n",
    "plt.text(0.2,9.5, 'Tc=10',fontsize=14)\n",
    "textstr = 'CO-Seasonal'\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "plt.text(0.73, 0.975, textstr, transform=ax.transAxes, fontsize=15,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.savefig(\"CS_CO_S.pdf\",format=\"pdf\", bbox_inches=\"tight\",dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corr_mean=[]\n",
    "for i in range(len(Data)):\n",
    "    corr=np.mean(Data[i])\n",
    "    Corr_mean.append(corr)\n",
    "\n",
    "ind1=[]\n",
    "ind2=[]\n",
    "Corr_mean1=[]\n",
    "Corr_mean2=[]\n",
    "Diff=(max(Corr_mean)-np.array(Corr_mean))*100\n",
    "for i in range(len(Diff)):\n",
    "    if Diff[i]>2 and i%2!=0:\n",
    "        ind1.append(i)\n",
    "        Corr_mean1.append(Corr_mean[i])\n",
    "    elif Diff[i]<=2 and i%2!=0 :\n",
    "        ind2.append(i)\n",
    "        Corr_mean2.append(Corr_mean[i])\n",
    "fig = plt.figure(figsize =(5, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.scatter(ind1[1],Corr_mean1[1], marker=\"d\",s=100,color='darkred', alpha=0.9)\n",
    "plt.scatter(ind2[-1],Corr_mean2[-1], marker=\"d\",s=100,color='teal', alpha=0.9)\n",
    "plt.legend(['>Tc','≤Tc'],loc = 2, bbox_to_anchor = (0.64,0.29), fontsize=16)\n",
    "\n",
    "plt.scatter(ind1,Corr_mean1, marker=\"d\",s=400,color='darkred', alpha=0.9)\n",
    "plt.scatter(ind2,Corr_mean2, marker=\"d\",s=400,color='teal', alpha=0.9)\n",
    "plt.scatter(ind1,Corr_mean1, s=20,color='black')\n",
    "plt.scatter(ind2,Corr_mean2, s=20,color='black')\n",
    "plt.yticks([0.5,0.6,0.7,0.8,0.9], fontsize=18)\n",
    "\n",
    "plt.xlabel('Fraction of training data (%)',fontsize=20)\n",
    "plt.ylabel('Pearson correlation (r)',fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "#plt.tick_params(width=1,length=3)\n",
    "plt.xticks(np.arange(0,18 , step=2))\n",
    "plt.yticks(np.arange(0.6,.95, step=0.1))\n",
    "#plt.grid(linestyle='-.',linewidth=0)\n",
    "#ax.spines[\"bottom\"].set_linewidth(1)\n",
    "#ax.spines[\"left\"].set_linewidth(1)\n",
    "#ax.spines[\"top\"].set_linewidth(1)\n",
    "#ax.spines[\"right\"].set_linewidth(1)\n",
    "ax.set_xticks([1,3,5,7,9,11,13,15])\n",
    "ax.set_xticklabels(['5','15','25','35','45','55','65','75'],fontsize=16)\n",
    "#plt.legend( fontsize=16)\n",
    "#plt.title(r\"$O_3$\",fontsize=16 )\n",
    "\n",
    "#plt.savefig(\"fig4d.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "#plt.savefig(\"A.pdf\",format=\"pdf\", bbox_inches=\"tight\",dpi=1000)\n",
    "textstr = 'CO (Tc=2%)'\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "plt.text(0.017, 0.975, textstr, transform=ax.transAxes, fontsize=15,\n",
    "        verticalalignment='top', bbox=props)\n",
    "plt.setp(ax.spines.values(), linewidth=1.6)\n",
    "plt.savefig(\"CS_S2_CO.pdf\",format=\"pdf\",bbox_inches=\"tight\",dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corr_mean=[]\n",
    "for i in range(len(Data)):\n",
    "    corr=np.mean(Data[i])\n",
    "    Corr_mean.append(corr)\n",
    "Diff=abs(((max(Corr_mean)-np.array(Corr_mean))/max(Corr_mean))*100)\n",
    "A=[i for i in range(16)if i%2==0]\n",
    "Diff2=[Diff[i] for i in range(16) if i%2==0]\n",
    "Y_Test=[i for i in np.arange(0,17,1)]\n",
    "y1=[2 for i in range(len(Y_Test))]\n",
    "y2=[0 for i in range(len(Y_Test))]\n",
    "fig= plt.figure(figsize=(7,6))\n",
    "ax = fig.add_subplot(111)\n",
    "y1=[-0.5 for i in range(len(Y_Test))]\n",
    "y2=[2 for i in range(len(Y_Test))]\n",
    "y4=[4 for i in range(len(Y_Test))]\n",
    "y6=[6 for i in range(len(Y_Test))]\n",
    "y8=[8 for i in range(len(Y_Test))]\n",
    "y10=[10 for i in range(len(Y_Test))]\n",
    "plt.fill_between(np.array(Y_Test), y1, y2, color='teal', alpha=0.4)\n",
    "plt.fill_between(np.array(Y_Test), y1, y4, color='teal', alpha=0.35)\n",
    "plt.fill_between(np.array(Y_Test), y1, y6, color='teal', alpha=0.3)\n",
    "plt.fill_between(np.array(Y_Test), y1, y8, color='teal', alpha=0.25)\n",
    "plt.fill_between(np.array(Y_Test), y1, y10, color='teal', alpha=0.2)\n",
    "plt.scatter(A,Diff2, marker=\"d\",s=500,color='darkgoldenrod', alpha=1)\n",
    "plt.scatter(A,Diff2, s=5,color='black')\n",
    "#plt.plot(A,Diff2,color='darkred', alpha=0.9)\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.set_xlim(left=0)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show\n",
    "plt.xlim(0,16)\n",
    "plt.ylim(0, 30)\n",
    "ax.set_xlim(right=16)\n",
    "ax.set_ylim(bottom=-0.5)\n",
    "plt.xticks(np.arange(0,16, step=2))\n",
    "plt.yticks(np.arange(0,20, step=5))\n",
    "ax.set_xticks([2,4,6,8,10,12,14,16])\n",
    "ax.set_xticklabels(['10','20','30','40','50','60','70',''],fontsize=16)\n",
    "plt.yticks([4,8,12,16,20,24,28])\n",
    "plt.setp(ax.spines.values(), linewidth=2)\n",
    "plt.xlabel('Fraction of training data (%)',fontsize=20)\n",
    "plt.ylabel('Difference in correlation (%)',fontsize=20)\n",
    "plt.text(0.2,1.5, 'Tc=2',fontsize=14)\n",
    "plt.text(0.2,3.5, 'Tc=4',fontsize=14)\n",
    "plt.text(0.2,5.5, 'Tc=6',fontsize=14)\n",
    "plt.text(0.2,7.5, 'Tc=8',fontsize=14)\n",
    "plt.text(0.2,9.5, 'Tc=10',fontsize=14)\n",
    "textstr = 'CO-Seasonal'\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "plt.text(0.74, 0.975, textstr, transform=ax.transAxes, fontsize=15,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.savefig(\"CS_CO_S.pdf\",format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corr_mean=[]\n",
    "for i in range(len(Data)):\n",
    "    corr=np.mean(Data[i])\n",
    "    Corr_mean.append(corr)\n",
    "\n",
    "ind1=[]\n",
    "ind2=[]\n",
    "Corr_mean1=[]\n",
    "Corr_mean2=[]\n",
    "Diff=(max(Corr_mean)-np.array(Corr_mean))*100\n",
    "for i in range(len(Diff)):\n",
    "    if Diff[i]>4 and i%2!=0:\n",
    "        ind1.append(i)\n",
    "        Corr_mean1.append(Corr_mean[i])\n",
    "    elif Diff[i]<=4 and i%2!=0 :\n",
    "        ind2.append(i)\n",
    "        Corr_mean2.append(Corr_mean[i])\n",
    "fig = plt.figure(figsize =(5, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.scatter(ind1,Corr_mean1, marker=\"d\",s=400,color='darkred', alpha=0.9)\n",
    "plt.scatter(ind2,Corr_mean2, marker=\"d\",s=400,color='teal', alpha=0.9)\n",
    "plt.scatter(ind1,Corr_mean1, s=20,color='black')\n",
    "plt.scatter(ind2,Corr_mean2, s=20,color='black')\n",
    "plt.yticks([0.5,0.6,0.7,0.8,0.9], fontsize=18)\n",
    "\n",
    "plt.xlabel('Fraction of training data (%)',fontsize=20)\n",
    "plt.ylabel('Pearson correlation (r)',fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "#plt.tick_params(width=1,length=3)\n",
    "plt.xticks(np.arange(0,18 , step=2))\n",
    "plt.yticks(np.arange(0.6,.95, step=0.1))\n",
    "#plt.grid(linestyle='-.',linewidth=0)\n",
    "#ax.spines[\"bottom\"].set_linewidth(1)\n",
    "#ax.spines[\"left\"].set_linewidth(1)\n",
    "#ax.spines[\"top\"].set_linewidth(1)\n",
    "#ax.spines[\"right\"].set_linewidth(1)\n",
    "ax.set_xticks([1,3,5,7,9,11,13,15])\n",
    "ax.set_xticklabels(['5','15','25','35','45','55','65','75'],fontsize=16)\n",
    "#plt.legend( fontsize=16)\n",
    "#plt.title(r\"$O_3$\",fontsize=16 )\n",
    "\n",
    "#plt.savefig(\"fig4d.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "#plt.savefig(\"A.pdf\",format=\"pdf\", bbox_inches=\"tight\",dpi=1000)\n",
    "textstr = 'CO (Tc=4%)'\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "plt.text(0.017, 0.975, textstr, transform=ax.transAxes, fontsize=15,\n",
    "        verticalalignment='top', bbox=props)\n",
    "plt.setp(ax.spines.values(), linewidth=1.6)\n",
    "plt.savefig(\"CS_S4_CO.pdf\",format=\"pdf\",bbox_inches=\"tight\",dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corr_mean=[]\n",
    "for i in range(len(Data)):\n",
    "    corr=np.mean(Data[i])\n",
    "    Corr_mean.append(corr)\n",
    "\n",
    "ind1=[]\n",
    "ind2=[]\n",
    "Corr_mean1=[]\n",
    "Corr_mean2=[]\n",
    "Diff=(max(Corr_mean)-np.array(Corr_mean))*100\n",
    "for i in range(len(Diff)):\n",
    "    if Diff[i]>6 and i%2!=0:\n",
    "        ind1.append(i)\n",
    "        Corr_mean1.append(Corr_mean[i])\n",
    "    elif Diff[i]<=6 and i%2!=0 :\n",
    "        ind2.append(i)\n",
    "        Corr_mean2.append(Corr_mean[i])\n",
    "fig = plt.figure(figsize =(5, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.scatter(ind1,Corr_mean1, marker=\"d\",s=400,color='darkred', alpha=0.9)\n",
    "plt.scatter(ind2,Corr_mean2, marker=\"d\",s=400,color='teal', alpha=0.9)\n",
    "plt.scatter(ind1,Corr_mean1, s=20,color='black')\n",
    "plt.scatter(ind2,Corr_mean2, s=20,color='black')\n",
    "plt.yticks([0.5,0.6,0.7,0.8,0.9], fontsize=18)\n",
    "\n",
    "plt.xlabel('Fraction of training data (%)',fontsize=20)\n",
    "plt.ylabel('Pearson correlation (r)',fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "#plt.tick_params(width=1,length=3)\n",
    "plt.xticks(np.arange(0,18 , step=2))\n",
    "plt.yticks(np.arange(0.6,.95, step=0.1))\n",
    "#plt.grid(linestyle='-.',linewidth=0)\n",
    "#ax.spines[\"bottom\"].set_linewidth(1)\n",
    "#ax.spines[\"left\"].set_linewidth(1)\n",
    "#ax.spines[\"top\"].set_linewidth(1)\n",
    "#ax.spines[\"right\"].set_linewidth(1)\n",
    "ax.set_xticks([1,3,5,7,9,11,13,15])\n",
    "ax.set_xticklabels(['5','15','25','35','45','55','65','75'],fontsize=16)\n",
    "#plt.legend( fontsize=16)\n",
    "#plt.title(r\"$O_3$\",fontsize=16 )\n",
    "\n",
    "#plt.savefig(\"fig4d.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "#plt.savefig(\"A.pdf\",format=\"pdf\", bbox_inches=\"tight\",dpi=1000)\n",
    "textstr = 'CO (Tc=6%)'\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "plt.text(0.017, 0.975, textstr, transform=ax.transAxes, fontsize=15,\n",
    "        verticalalignment='top', bbox=props)\n",
    "plt.setp(ax.spines.values(), linewidth=1.6)\n",
    "plt.savefig(\"CS_S6_CO.pdf\",format=\"pdf\",bbox_inches=\"tight\",dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corr_mean=[]\n",
    "for i in range(len(Data)):\n",
    "    corr=np.mean(Data[i])\n",
    "    Corr_mean.append(corr)\n",
    "\n",
    "ind1=[]\n",
    "ind2=[]\n",
    "Corr_mean1=[]\n",
    "Corr_mean2=[]\n",
    "Diff=(max(Corr_mean)-np.array(Corr_mean))*100\n",
    "for i in range(len(Diff)):\n",
    "    if Diff[i]>8 and i%2!=0:\n",
    "        ind1.append(i)\n",
    "        Corr_mean1.append(Corr_mean[i])\n",
    "    elif Diff[i]<=8 and i%2!=0 :\n",
    "        ind2.append(i)\n",
    "        Corr_mean2.append(Corr_mean[i])\n",
    "fig = plt.figure(figsize =(5, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.scatter(ind1,Corr_mean1, marker=\"d\",s=400,color='darkred', alpha=0.9)\n",
    "plt.scatter(ind2,Corr_mean2, marker=\"d\",s=400,color='teal', alpha=0.9)\n",
    "plt.scatter(ind1,Corr_mean1, s=20,color='black')\n",
    "plt.scatter(ind2,Corr_mean2, s=20,color='black')\n",
    "plt.yticks([0.5,0.6,0.7,0.8,0.9], fontsize=18)\n",
    "\n",
    "plt.xlabel('Fraction of training data (%)',fontsize=20)\n",
    "plt.ylabel('Pearson correlation (r)',fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "#plt.tick_params(width=1,length=3)\n",
    "plt.xticks(np.arange(0,18 , step=2))\n",
    "plt.yticks(np.arange(0.6,.95, step=0.1))\n",
    "#plt.grid(linestyle='-.',linewidth=0)\n",
    "#ax.spines[\"bottom\"].set_linewidth(1)\n",
    "#ax.spines[\"left\"].set_linewidth(1)\n",
    "#ax.spines[\"top\"].set_linewidth(1)\n",
    "#ax.spines[\"right\"].set_linewidth(1)\n",
    "ax.set_xticks([1,3,5,7,9,11,13,15])\n",
    "ax.set_xticklabels(['5','15','25','35','45','55','65','75'],fontsize=16)\n",
    "#plt.legend( fontsize=16)\n",
    "#plt.title(r\"$O_3$\",fontsize=16 )\n",
    "\n",
    "#plt.savefig(\"fig4d.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "#plt.savefig(\"A.pdf\",format=\"pdf\", bbox_inches=\"tight\",dpi=1000)\n",
    "textstr = 'CO (Tc=8%)'\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "plt.text(0.017, 0.975, textstr, transform=ax.transAxes, fontsize=15,\n",
    "        verticalalignment='top', bbox=props)\n",
    "plt.setp(ax.spines.values(), linewidth=1.6)\n",
    "plt.savefig(\"CS_S8_CO.pdf\",format=\"pdf\",bbox_inches=\"tight\",dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corr_mean=[]\n",
    "for i in range(len(Data)):\n",
    "    corr=np.mean(Data[i])\n",
    "    Corr_mean.append(corr)\n",
    "\n",
    "ind1=[]\n",
    "ind2=[]\n",
    "Corr_mean1=[]\n",
    "Corr_mean2=[]\n",
    "Diff=(max(Corr_mean)-np.array(Corr_mean))*100\n",
    "for i in range(len(Diff)):\n",
    "    if Diff[i]>10 and i%2!=0:\n",
    "        ind1.append(i)\n",
    "        Corr_mean1.append(Corr_mean[i])\n",
    "    elif Diff[i]<=10 and i%2!=0 :\n",
    "        ind2.append(i)\n",
    "        Corr_mean2.append(Corr_mean[i])\n",
    "fig = plt.figure(figsize =(5, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.scatter(ind1,Corr_mean1, marker=\"d\",s=400,color='darkred', alpha=0.9)\n",
    "plt.scatter(ind2,Corr_mean2, marker=\"d\",s=400,color='teal', alpha=0.9)\n",
    "plt.scatter(ind1,Corr_mean1, s=20,color='black')\n",
    "plt.scatter(ind2,Corr_mean2, s=20,color='black')\n",
    "plt.yticks([0.5,0.6,0.7,0.8,0.9], fontsize=18)\n",
    "\n",
    "plt.xlabel('Fraction of training data (%)',fontsize=20)\n",
    "plt.ylabel('Pearson correlation (r)',fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "#plt.tick_params(width=1,length=3)\n",
    "plt.xticks(np.arange(0,18 , step=2))\n",
    "plt.yticks(np.arange(0.6,.95, step=0.1))\n",
    "#plt.grid(linestyle='-.',linewidth=0)\n",
    "#ax.spines[\"bottom\"].set_linewidth(1)\n",
    "#ax.spines[\"left\"].set_linewidth(1)\n",
    "#ax.spines[\"top\"].set_linewidth(1)\n",
    "#ax.spines[\"right\"].set_linewidth(1)\n",
    "ax.set_xticks([1,3,5,7,9,11,13,15])\n",
    "ax.set_xticklabels(['5','15','25','35','45','55','65','75'],fontsize=16)\n",
    "#plt.legend( fontsize=16)\n",
    "#plt.title(r\"$O_3$\",fontsize=16 )\n",
    "\n",
    "#plt.savefig(\"fig4d.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "#plt.savefig(\"A.pdf\",format=\"pdf\", bbox_inches=\"tight\",dpi=1000)\n",
    "textstr = 'CO (Tc=10%)'\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "plt.text(0.017, 0.975, textstr, transform=ax.transAxes, fontsize=15,\n",
    "        verticalalignment='top', bbox=props)\n",
    "plt.setp(ax.spines.values(), linewidth=1.6)\n",
    "plt.savefig(\"CS_S10_CO.pdf\",format=\"pdf\",bbox_inches=\"tight\",dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(5, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "data=Data\n",
    "\n",
    "#data2=data2\n",
    "# Creating axes instance\n",
    "bp = plt.boxplot(data, patch_artist = True,\n",
    "                 vert = 1,showfliers=False)\n",
    "#bp2 = ax.boxplot(data2, patch_artist = True,\n",
    "                 #vert = 1)\n",
    "#plt.legend(['Randomized','Non-randomized'],loc = 2, bbox_to_anchor = (0.62,1),  fontsize=10)\n",
    "colors= ['#00688B' for i in range(40)]\n",
    "#colors2= ['teal' for i in range(40)]\n",
    " \n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_color(color)\n",
    "#for patch, color in zip(bp2['boxes'], colors2):\n",
    "    #patch.set_color(color)\n",
    "    \n",
    "#plt.legend(['Randomized','Non-randomized'],loc = 2, bbox_to_anchor = (0.78,1),  fontsize=10)\n",
    "for median in bp['medians']:\n",
    "    median.set(color ='green',\n",
    "               linewidth = 1)\n",
    "\n",
    "plt.xlabel('Fraction of training data (%)',fontsize=20)\n",
    "plt.ylabel('Pearson correlation (r)',fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "#plt.tick_params(width=1,length=3)\n",
    "plt.xticks(np.arange(0,18 , step=2))\n",
    "plt.yticks(np.arange(0.6,1.01, step=0.1))\n",
    "#plt.grid(linestyle='-.',linewidth=0)\n",
    "#ax.spines[\"bottom\"].set_linewidth(1)\n",
    "#ax.spines[\"left\"].set_linewidth(1)\n",
    "#ax.spines[\"top\"].set_linewidth(1)\n",
    "#ax.spines[\"right\"].set_linewidth(1)\n",
    "ax.set_xticks([2,4,6,8,10,12,14,16])\n",
    "ax.set_xticklabels(['10','20','30','40','50','60','70','80'])\n",
    "#plt.legend( fontsize=16)\n",
    "#plt.title(r\"$O_3$\",fontsize=16 )\n",
    "\n",
    "#plt.savefig(\"fig4d.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "#plt.savefig(\"A.pdf\",format=\"pdf\", bbox_inches=\"tight\",dpi=1000)\n",
    "plt.savefig(\"CS_S_CO.pdf\",format=\"pdf\",bbox_inches=\"tight\",dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-sympathy",
   "metadata": {},
   "source": [
    "# Bias and precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-pharmacology",
   "metadata": {},
   "source": [
    "# October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=data_Oct[['Net Signal','Temp','RH','Month','Day_of_week','Hour']]\n",
    "#y=data_Oct['Ref']\n",
    "frame1=[data_oct,data_nov]\n",
    "fall=pd.concat(frame1)\n",
    "#Day=[5*i for i in range(1,11) ]\n",
    "Fall=fall.resample('60min').mean()\n",
    "Fall=Fall.dropna()\n",
    "X=Fall[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour']]\n",
    "y=Fall['Ref']\n",
    "X=scaler2.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=True)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "print(X_train.shape[0])\n",
    "X_Data=X_train\n",
    "y_Data=y_train\n",
    "X_train2=X_Data[:500]\n",
    "X_train3=X_Data[:700]\n",
    "X_train4=X_Data[:900]\n",
    "#X_train4=X_Data[:2000]\n",
    "#X_train5=X_Data[:2500]\n",
    "#X_train6=X_Data[:3000]\n",
    "\n",
    "y_train2=y_Data[:500]\n",
    "y_train3=y_Data[:700]\n",
    "y_train4=y_Data[:900]\n",
    "#y_train4=y_Data[:2000]\n",
    "#y_train5=y_Data[:2500]\n",
    "#y_train6=y_Data[:3000]\n",
    "\n",
    "fr=0.18\n",
    "\n",
    "B2_o=[]\n",
    "B3_o=[]\n",
    "B4_o=[]\n",
    "\n",
    "P2_o=[]\n",
    "P3_o=[]\n",
    "P4_o=[]\n",
    "model2=regressor.fit(X_train2[:int(fr*X_train2.shape[0])], \n",
    "                         y_train2[:int(fr*X_train2.shape[0])])\n",
    "pred2=model2.predict(X_train2[int(fr*X_train2.shape[0]):])\n",
    "b=bias(y_train2[int(fr*X_train2.shape[0]):], pred2)\n",
    "p=precision(y_train2[int(fr*X_train2.shape[0]):], pred2)\n",
    "B2_o.append(b)\n",
    "P2_o.append(p)\n",
    "\n",
    "\n",
    "model3=regressor.fit(X_train3[:int(fr*X_train3.shape[0])], \n",
    "                         y_train3[:int(fr*X_train3.shape[0])])\n",
    "pred3=model3.predict(X_train3[int(fr*X_train3.shape[0]):])\n",
    "b=bias(y_train3[int(fr*X_train3.shape[0]):], pred3)\n",
    "p=precision(y_train3[int(fr*X_train3.shape[0]):], pred3)\n",
    "B3_o.append(b)\n",
    "P3_o.append(p)\n",
    "\n",
    "model4=regressor.fit(X_train4[:int(fr*X_train4.shape[0])], \n",
    "                         y_train4[:int(fr*X_train4.shape[0])])\n",
    "pred4=model4.predict(X_train4[int(fr*X_train4.shape[0]):])\n",
    "b=bias(y_train4[int(fr*X_train4.shape[0]):], pred4)\n",
    "p=precision(y_train4[int(fr*X_train4.shape[0]):], pred4)\n",
    "B4_o.append(b)\n",
    "P4_o.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-assembly",
   "metadata": {},
   "source": [
    "# November"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=data_Nov[['Net Signal','Temp','RH','Month','Day_of_week','Hour']]\n",
    "#y=data_Nov['Ref']\n",
    "frame1=[data_dec,data_jan,data_feb]\n",
    "fall=pd.concat(frame1)\n",
    "#Day=[5*i for i in range(1,11) ]\n",
    "Fall=fall.resample('60min').mean()\n",
    "Fall=Fall.dropna()\n",
    "X=Fall[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour']]\n",
    "y=Fall['Ref']\n",
    "X=scaler2.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=True)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "print(X_train.shape[0])\n",
    "X_Data=X_train\n",
    "y_Data=y_train\n",
    "X_train2=X_Data[:500]\n",
    "X_train3=X_Data[:700]\n",
    "X_train4=X_Data[:900]\n",
    "#X_train4=X_Data[:2000]\n",
    "#X_train5=X_Data[:2500]\n",
    "#X_train6=X_Data[:3000]\n",
    "\n",
    "y_train2=y_Data[:500]\n",
    "y_train3=y_Data[:700]\n",
    "y_train4=y_Data[:900]\n",
    "#y_train4=y_Data[:2000]\n",
    "#y_train5=y_Data[:2500]\n",
    "#y_train6=y_Data[:3000]\n",
    "\n",
    "B2_n=[]\n",
    "B3_n=[]\n",
    "B4_n=[]\n",
    "\n",
    "P2_n=[]\n",
    "P3_n=[]\n",
    "P4_n=[]\n",
    "model2=regressor.fit(X_train2[:int(fr*X_train2.shape[0])], \n",
    "                         y_train2[:int(fr*X_train2.shape[0])])\n",
    "pred2=model2.predict(X_train2[int(fr*X_train2.shape[0]):])\n",
    "b=bias(y_train2[int(fr*X_train2.shape[0]):], pred2)\n",
    "p=precision(y_train2[int(fr*X_train2.shape[0]):], pred2)\n",
    "B2_n.append(b)\n",
    "P2_n.append(p)\n",
    "\n",
    "\n",
    "model3=regressor.fit(X_train3[:int(fr*X_train3.shape[0])], \n",
    "                         y_train3[:int(fr*X_train3.shape[0])])\n",
    "pred3=model3.predict(X_train3[int(fr*X_train3.shape[0]):])\n",
    "b=bias(y_train3[int(fr*X_train3.shape[0]):], pred3)\n",
    "p=precision(y_train3[int(fr*X_train3.shape[0]):], pred3)\n",
    "B3_n.append(b)\n",
    "P3_n.append(p)\n",
    "\n",
    "model4=regressor.fit(X_train4[:int(fr*X_train4.shape[0])], \n",
    "                         y_train4[:int(fr*X_train4.shape[0])])\n",
    "pred4=model4.predict(X_train4[int(fr*X_train4.shape[0]):])\n",
    "b=bias(y_train4[int(fr*X_train4.shape[0]):], pred4)\n",
    "p=precision(y_train4[int(fr*X_train4.shape[0]):], pred4)\n",
    "B4_n.append(b)\n",
    "P4_n.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-prototype",
   "metadata": {},
   "source": [
    "# December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=data_Dec[['Net Signal','Temp','RH','Month','Day_of_week','Hour']]\n",
    "#y=data_Dec['Ref']\n",
    "frame1=[data_mar,data_apr]\n",
    "fall=pd.concat(frame1)\n",
    "#Day=[5*i for i in range(1,11) ]\n",
    "Fall=fall.resample('60min').mean()\n",
    "Fall=Fall.dropna()\n",
    "X=Fall[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour']]\n",
    "y=Fall['Ref']\n",
    "X=scaler2.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=True)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -2\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "print(X_train.shape[0])\n",
    "X_Data=X_train\n",
    "y_Data=y_train\n",
    "X_train2=X_Data[:500]\n",
    "X_train3=X_Data[:700]\n",
    "X_train4=X_Data[:900]\n",
    "#X_train4=X_Data[:2000]\n",
    "#X_train5=X_Data[:2500]\n",
    "#X_train6=X_Data[:3000]\n",
    "\n",
    "y_train2=y_Data[:500]\n",
    "y_train3=y_Data[:700]\n",
    "y_train4=y_Data[:900]\n",
    "#y_train4=y_Data[:2000]\n",
    "#y_train5=y_Data[:2500]\n",
    "#y_train6=y_Data[:3000]\n",
    "\n",
    "B2_d=[]\n",
    "B3_d=[]\n",
    "B4_d=[]\n",
    "\n",
    "P2_d=[]\n",
    "P3_d=[]\n",
    "P4_d=[]\n",
    "model2=regressor.fit(X_train2[:int(fr*X_train2.shape[0])], \n",
    "                         y_train2[:int(fr*X_train2.shape[0])])\n",
    "pred2=model2.predict(X_train2[int(fr*X_train2.shape[0]):])\n",
    "b=bias(y_train2[int(fr*X_train2.shape[0]):], pred2)\n",
    "p=precision(y_train2[int(fr*X_train2.shape[0]):], pred2)\n",
    "B2_d.append(b)\n",
    "P2_d.append(p)\n",
    "\n",
    "\n",
    "model3=regressor.fit(X_train3[:int(fr*X_train3.shape[0])], \n",
    "                         y_train3[:int(fr*X_train3.shape[0])])\n",
    "pred3=model3.predict(X_train3[int(fr*X_train3.shape[0]):])\n",
    "b=bias(y_train3[int(fr*X_train3.shape[0]):], pred3)\n",
    "p=precision(y_train3[int(fr*X_train3.shape[0]):], pred3)\n",
    "B3_d.append(b)\n",
    "P3_d.append(p)\n",
    "\n",
    "model4=regressor.fit(X_train4[:int(fr*X_train4.shape[0])], \n",
    "                         y_train4[:int(fr*X_train4.shape[0])])\n",
    "pred4=model4.predict(X_train4[int(fr*X_train4.shape[0]):])\n",
    "b=bias(y_train4[int(fr*X_train4.shape[0]):], pred4)\n",
    "p=precision(y_train4[int(fr*X_train4.shape[0]):], pred4)\n",
    "B4_d.append(b)\n",
    "P4_d.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-memphis",
   "metadata": {},
   "source": [
    "X=data_Jan[['Net Signal','Temp','RH','Month','Day_of_week','Hour']]\n",
    "y=data_Jan['Ref']\n",
    "#frame1=[data_mar,data_apr]\n",
    "#fall=pd.concat(frame1)\n",
    "#Day=[5*i for i in range(1,11) ]\n",
    "#Fall=fall.resample('h').mean()\n",
    "#Fall=Fall.dropna()\n",
    "#X=Fall[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour']]\n",
    "#y=Fall['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=True)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "print(X_train.shape[0])\n",
    "X_Data=X_train\n",
    "y_Data=y_train\n",
    "X_train2=X_Data[:500]\n",
    "X_train3=X_Data[:700]\n",
    "X_train4=X_Data[:900]\n",
    "#X_train4=X_Data[:2000]\n",
    "#X_train5=X_Data[:2500]\n",
    "#X_train6=X_Data[:3000]\n",
    "\n",
    "y_train2=y_Data[:500]\n",
    "y_train3=y_Data[:700]\n",
    "y_train4=y_Data[:900]\n",
    "#y_train4=y_Data[:2000]\n",
    "#y_train5=y_Data[:2500]\n",
    "#y_train6=y_Data[:3000]\n",
    "\n",
    "B2_j=[]\n",
    "B3_j=[]\n",
    "B4_j=[]\n",
    "\n",
    "P2_j=[]\n",
    "P3_j=[]\n",
    "P4_j=[]\n",
    "model2=regressor.fit(X_train2[:int(0.4*X_train2.shape[0])], \n",
    "                         y_train2[:int(0.4*X_train2.shape[0])])\n",
    "pred2=model2.predict(X_train2[int(0.4*X_train2.shape[0]):])\n",
    "b=bias(y_train2[int(0.4*X_train2.shape[0]):], pred2)\n",
    "p=precision(y_train2[int(0.4*X_train2.shape[0]):], pred2)\n",
    "B2_j.append(b)\n",
    "P2_j.append(p)\n",
    "\n",
    "\n",
    "model3=regressor.fit(X_train3[:int(0.4*X_train3.shape[0])], \n",
    "                         y_train3[:int(0.4*X_train3.shape[0])])\n",
    "pred3=model3.predict(X_train3[int(0.4*X_train3.shape[0]):])\n",
    "b=bias(y_train3[int(0.4*X_train3.shape[0]):], pred3)\n",
    "p=precision(y_train3[int(0.4*X_train3.shape[0]):], pred3)\n",
    "B3_j.append(b)\n",
    "P3_j.append(p)\n",
    "\n",
    "model4=regressor.fit(X_train4[:int(0.4*X_train4.shape[0])], \n",
    "                         y_train4[:int(0.4*X_train4.shape[0])])\n",
    "pred4=model4.predict(X_train4[int(0.4*X_train4.shape[0]):])\n",
    "b=bias(y_train4[int(0.4*X_train4.shape[0]):], pred4)\n",
    "p=precision(y_train4[int(0.4*X_train4.shape[0]):], pred4)\n",
    "B4_j.append(b)\n",
    "P4_j.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-negotiation",
   "metadata": {},
   "source": [
    "X=data_Jan[['Net Signal','Temp','RH','Month','Day_of_week','Hour']]\n",
    "y=data_Jan['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=True)\n",
    "regressor.fit(X_train[:int(0.4*X_train2.shape[0])], y_train[:int(0.4*X_train2.shape[0])])\n",
    "pred=regressor.predict(X_train[int(0.05*X_train2.shape[0]):])\n",
    "P4=precision(pred,y_train[int(0.05*X_train2.shape[0]):])\n",
    "B4=bias(pred,y_train[int(0.05*X_train2.shape[0]):])\n",
    "(P4,B4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-kidney",
   "metadata": {},
   "source": [
    "X=data_Jan3[['Net Signal','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]\n",
    "y=data_Jan3['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=False)\n",
    "regressor.fit(X_train[:int(0.4*X_train2.shape[0])], y_train[:int(0.4*X_train2.shape[0])])\n",
    "pred=regressor.predict(X_train[int(0.05*X_train2.shape[0]):])\n",
    "P41=precision(pred,y_train[int(0.05*X_train2.shape[0]):])\n",
    "B41=bias(pred,y_train[int(0.05*X_train2.shape[0]):])\n",
    "(P41,B41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=[B2_o[0],B3_o[0],B4_o[0],B2_n[0],B3_n[0],B4_n[0],B2_d[0],B3_d[0],B4_d[0]]\n",
    "B=np.array(B)\n",
    "B=np.round(B,2)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "P=[P2_o[0],P3_o[0],P4_o[0],P2_n[0],P3_n[0],P4_n[0],P2_d[0],P3_d[0],P4_d[0]]\n",
    "P=np.array(P)\n",
    "P=np.round(P,2)\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=[B,P]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "# Creating dataset\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize =(5, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "data=Data\n",
    "#data2=data2\n",
    "# Creating axes instance\n",
    "plt.axhline(y= 10, color = 'green',label='RC', linestyle = ':',linewidth=2 )\n",
    "plt.axhline(y= 25, color = 'purple',label='RC', linestyle = ':',linewidth=2 )\n",
    "plt.axhline(y= 30, color = 'orange',label='RC', linestyle = ':',linewidth=2 )\n",
    "plt.axhline(y= 50, color = 'dodgerblue',label='RC', linestyle = ':',linewidth=2 )\n",
    "#plt.legend(['RC','SGS','IS','HA & CSP'],ncol=4, loc='lower left', fontsize=10)\n",
    "\n",
    "bp = plt.boxplot(data, patch_artist = True,\n",
    "                 vert = 1,showfliers=False)\n",
    "#bp2 = ax.boxplot(data2, patch_artist = True,\n",
    "                 #vert = 1)\n",
    "#plt.legend(['Randomized','Non-randomized'],loc = 2, bbox_to_anchor = (0.62,1),  fontsize=10)\n",
    "colors= ['#6495ED','#8B3E2F']\n",
    "#colors2= ['teal' for i in range(40)]\n",
    " \n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_color(color)\n",
    "#for patch, color in zip(bp2['boxes'], colors2):\n",
    "    #patch.set_color(color)\n",
    "    \n",
    "#plt.legend(['Randomized','Non-randomized'],loc = 2, bbox_to_anchor = (0.78,1),  fontsize=10)\n",
    "\n",
    "#plt.xlabel('Training Data (%)',fontsize=20)\n",
    "plt.ylabel('Error (%)',fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "#plt.tick_params(width=1,length=3)\n",
    "#plt.xticks(np.arange(0,8 , step=1))\n",
    "plt.yticks(np.arange(0,61, step=10)) \n",
    "#ax.spines[\"bottom\"].set_linewidth(1)\n",
    "#ax.spines[\"left\"].set_linewidth(1)\n",
    "#ax.spines[\"top\"].set_linewidth(1)\n",
    "#ax.spines[\"right\"].set_linewidth(1)\n",
    "plt.axhline(y= 10, color = 'green',label='RC', linestyle = ':',linewidth=2 )\n",
    "plt.axhline(y= 25, color = 'purple',label='RC', linestyle = ':',linewidth=2 )\n",
    "plt.axhline(y= 30, color = 'orange',label='RC', linestyle = ':',linewidth=2 )\n",
    "plt.axhline(y= 50, color = 'dodgerblue',label='RC', linestyle = ':',linewidth=2 )\n",
    "plt.grid(linestyle='-.',linewidth=0)\n",
    "ax.set_xticks([1,2])\n",
    "ax.set_xticklabels(['Bias','Precision'])\n",
    "#plt.legend(['Bias','Precision'] ,fontsize=16)\n",
    "#plt.title(r\"$CO$\",fontsize=16 )\n",
    "plt.savefig(\"BP_S_CO.pdf\",format=\"pdf\",bbox_inches=\"tight\",dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(5, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "data=Data\n",
    "\n",
    "#data2=data2\n",
    "# Creating axes instance\n",
    "plt.axhline(y= 10, color = 'green',label='RC', linestyle = ':',linewidth=2 )\n",
    "plt.axhline(y= 25, color = 'purple',label='RC', linestyle = ':',linewidth=2 )\n",
    "plt.axhline(y= 30, color = 'orange',label='RC', linestyle = ':',linewidth=2 )\n",
    "plt.axhline(y= 50, color = 'dodgerblue',label='RC', linestyle = ':',linewidth=2 )\n",
    "#plt.legend(['RC','SGS','IS','HA & CSP'],ncol=4, loc='lower left', fontsize=10)\n",
    "bp = plt.boxplot(data, patch_artist = True,\n",
    "                 vert = 1,showfliers=False)\n",
    "#bp2 = ax.boxplot(data2, patch_artist = True,\n",
    "                 #vert = 1)\n",
    "#plt.legend(['Randomized','Non-randomized'],loc = 2, bbox_to_anchor = (0.62,1),  fontsize=10)\n",
    "#colors= ['#00688B' for i in range(2)]\n",
    "colors= ['#6495ED','#8B3E2F']\n",
    "#colors2= ['teal' for i in range(40)]\n",
    " \n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_color(color)\n",
    "#for patch, color in zip(bp2['boxes'], colors2):\n",
    "    #patch.set_color(color)\n",
    "    \n",
    "#plt.legend(['Randomized','Non-randomized'],loc = 2, bbox_to_anchor = (0.78,1),  fontsize=10)\n",
    "for median in bp['medians']:\n",
    "    median.set(color ='green',\n",
    "               linewidth = 1)\n",
    "\n",
    "plt.ylabel('Error (%)',fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "#plt.tick_params(width=1,length=3)\n",
    "#plt.xticks(np.arange(0,5 , step=2))\n",
    "plt.yticks(np.arange(0,61, step=10))\n",
    "#plt.grid(linestyle='-.',linewidth=0)\n",
    "#ax.spines[\"bottom\"].set_linewidth(1)\n",
    "#ax.spines[\"left\"].set_linewidth(1)\n",
    "#ax.spines[\"top\"].set_linewidth(1)\n",
    "#ax.spines[\"right\"].set_linewidth(1)\n",
    "ax.set_xticks([1,2])\n",
    "ax.set_xticklabels(['Bias','Precision'])\n",
    "#plt.legend( fontsize=16)\n",
    "#plt.title(r\"$O_3$\",fontsize=16 )\n",
    "\n",
    "#plt.savefig(\"fig4d.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "#plt.savefig(\"A.pdf\",format=\"pdf\", bbox_inches=\"tight\",dpi=1000)\n",
    "plt.savefig(\"BP_S_CO.pdf\",format=\"pdf\",bbox_inches=\"tight\",dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "Day=[2*i for i in range(1,21)]\n",
    "Rmse1_rf=[]\n",
    "RMSE1_rf=[]\n",
    "REU1=[]\n",
    "REU2=[]\n",
    "lv=2000\n",
    "L_y1=[]\n",
    "A1=[]\n",
    "M1=[]\n",
    "Bias=[]\n",
    "L=[]\n",
    "KK=[]\n",
    "D1=[]\n",
    "Features1=[]\n",
    "P1=[]\n",
    "for i in range(1,10):\n",
    "    k=y_train[48*i:].to_list()\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-50:])\n",
    "    y_test=y_train[48*i:]\n",
    "    #model=stacked_averaged_models.fit(X_train[:48*i].values, y_train[:48*i])\n",
    "    #pred =model.predict(X_train[48*i:].values)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse= mape=round(mean_absolute_percentage_error(y_test,pred),2)\n",
    "    #mse= mape=round(relative_mean_absolute_error(y_test,pred),2)\n",
    "    kk=round(np.corrcoef(y_train[48*i:], pred)[0, 1],2)\n",
    "    KK.append(kk)\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    ind=[]\n",
    "    reu=REF(pred,y_train[48*i:],1)\n",
    "    re=REF2(pred,y_train[48*i:],1.3,lv)\n",
    "    U=np.sqrt(np.mean((0.25*np.array(y_train[48*i:]))**2))\n",
    "    #U=np.sqrt(np.mean((reu)**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))/np.mean(y)\n",
    "    m=RMSE/(1*U)\n",
    "    #b=(np.mean(pred)-np.mean(y_train[48*i:]))/np.mean(y_train[48*i:])\n",
    "    #bias=(abs(b)*np.mean(y_train[48*i:])/(1.67*U))\n",
    "    l=1-(U/np.std(y_train[48*i:]))**2\n",
    "    d=IOA(y_train[48*i:], pred)\n",
    "    features=regressor.feature_importances_\n",
    "    Features1.append(features)\n",
    "    D1.append(d)\n",
    "    L.append(l)\n",
    "    p=precision(pred,y_train[48*i:])\n",
    "    rmse=round(sm.r2_score(y_train[X_train.shape[0]-50:], Pred), 2)\n",
    "    M1.append(p)\n",
    "    #Bias.append(bias)\n",
    "    \n",
    "    \n",
    "    for i in range(len(reu)):\n",
    "        if reu[i]<30:\n",
    "            ind.append(i)\n",
    "    Rmse1_rf.append(RMSE)\n",
    "    RMSE1_rf.append(rmse)\n",
    "    REU1.append(reu)\n",
    "    L_y1.append(k)\n",
    "    REU2.append(round((len(ind)/len(reu))*100,2))\n",
    "    A1.append(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse1_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE1_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "KK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train[:480], y_train[:480])\n",
    "pred=regressor.predict(X_train[480:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv=max\n",
    "A=[i for i in np.arange(1,3,0.1)]\n",
    "K=[]\n",
    "for i in A:\n",
    "    lv=max(y_train[480:])\n",
    "    k=REF2(pred,y_train[480:],i,lv)\n",
    "    K.append(k)\n",
    "for i in range(len(K)):\n",
    "    if K[i]==min(K):\n",
    "        print(A[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(A,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_Oct2[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_O3']]\n",
    "y=data_Oct2['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "Day=[2*i for i in range(1,21) ]\n",
    "Rmse1_rf2=[]\n",
    "RMSE1_rf2=[]\n",
    "M12=[]\n",
    "for i in range(1,10):\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-50:])\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse= mape=round(mean_absolute_percentage_error(y_test,pred),2)\n",
    "    #mse= mape=round(relative_mean_absolute_error(y_test,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    U=np.sqrt(np.mean((0.25*np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    p=precision(pred,y_train[48*i:])\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-50:])\n",
    "    rmse=round(sm.r2_score(y_train[X_train.shape[0]-50:], Pred), 2)\n",
    "    M12.append(p)\n",
    "    Rmse1_rf2.append(mse)\n",
    "    RMSE1_rf2.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse1_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE1_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "M12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_Oct3[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_NO2']]\n",
    "y=data_Oct3['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "Day=[2*i for i in range(1,21) ]\n",
    "Rmse1_rf3=[]\n",
    "RMSE1_rf3=[]\n",
    "M13=[]\n",
    "for i in range(1,9):\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse= mape=round(mean_absolute_percentage_error(y_test,pred),2)\n",
    "    #mse= mape=round(relative_mean_absolute_error(y_test,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    U=np.sqrt(np.mean((0.3*np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    p=precision(pred,y_train[48*i:])\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-50:])\n",
    "    rmse=round(sm.r2_score(y_train[X_train.shape[0]-50:], Pred), 2)\n",
    "    M13.append(p)\n",
    "    Rmse1_rf3.append(mse)\n",
    "    RMSE1_rf3.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse1_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE1_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "M13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-blues",
   "metadata": {},
   "source": [
    "# Nov 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-transmission",
   "metadata": {},
   "source": [
    "   #   RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_Nov[['Net Signal','Temp1','RH1','Month','Day_of_week','Day','Hour']]\n",
    "y=data_Nov['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "A=np.array(y)/np.mean(y)\n",
    "A=sorted(A, reverse=True)\n",
    "sum2=sum(A[:100])\n",
    "mean2=np.std(y)/np.mean(y)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse2_rf=[]\n",
    "RMSE2_rf=[]\n",
    "REU2=[]\n",
    "L_y2=[]\n",
    "A2=[]\n",
    "M2=[]\n",
    "D2=[]\n",
    "Features2=[]\n",
    "for i in range(1,11):\n",
    "    k=y_train[48*i:].to_list()\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    reu=REF(pred,y_train[48*i:],1.3)\n",
    "    U=np.sqrt(np.mean((reu)**2))\n",
    "    #mse=round(sm.r2_score(y_test, pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse= mape=round(mean_absolute_percentage_error(y_test,pred),2)\n",
    "    #mse=round(relative_mean_absolute_error(y_test,pred)/np.mean(y_test),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.25*np.array(y_train[48*i:]))**2))\n",
    "    #U=np.sqrt(np.mean((reu)**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))/np.mean(y)\n",
    "    m=RMSE/(1*U)\n",
    "    d=IOA(y_train[48*i:], pred)\n",
    "    features=regressor.feature_importances_\n",
    "    Features2.append(features)\n",
    "    D2.append(d)\n",
    "    p=precision(pred,y_train[48*i:])\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-50:])\n",
    "    rmse=round(sm.r2_score(y_train[X_train.shape[0]-50:], Pred), 2)\n",
    "    M2.append(p)\n",
    "    Rmse2_rf.append(RMSE)\n",
    "    RMSE2_rf.append(rmse)\n",
    "    reu=REF(pred,y_train[48*i:],1)\n",
    "    re=REF2(pred,y_train[48*i:],1.3,lv)\n",
    "    A2.append(re)\n",
    "    REU2.append(reu)\n",
    "    L_y2.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse2_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE2_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_Nov2[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_O3']]\n",
    "y=data_Nov2['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "A=np.array(y)/np.mean(y)\n",
    "A=sorted(A, reverse=True)\n",
    "sum2=sum(A[:100])\n",
    "mean2=np.std(y)/np.mean(y)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse2_rf2=[]\n",
    "RMSE2_rf2=[]\n",
    "M22=[]\n",
    "for i in range(1,11):\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    #mse=round(sm.r2_score(y_test, pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse= mape=round(mean_absolute_percentage_error(y_test,pred),2)\n",
    "    #mse=round(relative_mean_absolute_error(y_test,pred)/np.mean(y_test),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.25*np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    p=precision(pred,y_train[48*i:])\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-50:])\n",
    "    rmse=round(sm.r2_score(y_train[X_train.shape[0]-50:], Pred), 2)\n",
    "    M22.append(p)\n",
    "    Rmse2_rf2.append(mse)\n",
    "    RMSE2_rf2.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse2_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE2_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "M22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_Nov3[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_NO2']]\n",
    "y=data_Nov3['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse2_rf3=[]\n",
    "RMSE2_rf3=[]\n",
    "M23=[]\n",
    "for i in range(1,10):\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    #mse=round(sm.r2_score(y_test, pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse= mape=round(mean_absolute_percentage_error(y_test,pred),2)\n",
    "    #mse=round(relative_mean_absolute_error(y_test,pred)/np.mean(y_test),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.3*np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    p=precision(pred,y_train[48*i:])\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-50:])\n",
    "    rmse=round(sm.r2_score(y_train[X_train.shape[0]-50:], Pred), 2)\n",
    "    M23.append(p)\n",
    "    Rmse2_rf3.append(mse)\n",
    "    RMSE2_rf3.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-hypothetical",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse2_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE2_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "M23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-conservation",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_Dec[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour']]\n",
    "y=data_Dec['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "A=np.array(y)/np.mean(y)\n",
    "A=sorted(A, reverse=True)\n",
    "sum3=sum(A[:100])\n",
    "mean3=np.std(y)/np.mean(y)\n",
    "Rmse3_rf=[]\n",
    "RMSE3_rf=[]\n",
    "REU3=[]\n",
    "L_y3=[]\n",
    "A3=[]\n",
    "M3=[]\n",
    "for i in range(1,10):\n",
    "    k=y_train[48*i:].to_list()\n",
    "    #lv=max(y_train[48*i:])\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    reu=REF(pred,y_train[48*i:],1.6)\n",
    "    #U=np.sqrt(np.mean((reu)**2))\n",
    "    #mse=round(sm.r2_score(y_test, pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse= mape=round(mean_absolute_percentage_error(y_test,pred),2)\n",
    "    #mse= mape=round(relative_mean_absolute_error(y_test,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.25*np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))/np.mean(y)\n",
    "    m=RMSE/(1*U)\n",
    "    p=precision(pred,y_train[48*i:])\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-50:])\n",
    "    rmse=round(sm.r2_score(y_train[X_train.shape[0]-50:], Pred), 2)\n",
    "    M3.append(p)\n",
    "    Rmse3_rf.append(RMSE)\n",
    "    RMSE3_rf.append(rmse)\n",
    "    reu=REF(pred,y_train[48*i:],1)\n",
    "    re=REF2(pred,y_train[48*i:],1.3,lv)\n",
    "    A3.append(re)\n",
    "    REU3.append(reu)\n",
    "    L_y3.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse3_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE3_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=[i for i in range(len(pred))]\n",
    "plt.plot(ind,pred)\n",
    "plt.plot(ind,y_train[432:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_Dec2[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_O3']]\n",
    "y=data_Dec2['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "A=np.array(y)/np.mean(y)\n",
    "A=sorted(A, reverse=True)\n",
    "sum3=sum(A[:100])\n",
    "mean3=np.std(y)/np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse3_rf2=[]\n",
    "RMSE3_rf2=[]\n",
    "M32=[]\n",
    "for i in range(1,11):\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    #mse=round(sm.r2_score(y_test, pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse= mape=round(mean_absolute_percentage_error(y_test,pred),2)\n",
    "    #mse= mape=round(relative_mean_absolute_error(y_test,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.25*np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    p=precision(pred,y_train[48*i:])\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-50:])\n",
    "    rmse=round(sm.r2_score(y_train[X_train.shape[0]-50:], Pred), 2)\n",
    "    M32.append(p)\n",
    "    Rmse3_rf2.append(mse)\n",
    "    RMSE3_rf2.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse3_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE3_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "M32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_Dec3[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_NO2']]\n",
    "y=data_Dec3['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse3_rf3=[]\n",
    "RMSE3_rf3=[]\n",
    "M33=[]\n",
    "for i in range(1,11):\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    #mse=round(sm.r2_score(y_test, pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse= mape=round(mean_absolute_percentage_error(y_test,pred),2)\n",
    "    #mse= mape=round(relative_mean_absolute_error(y_test,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.3*np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    p=precision(pred,y_train[48*i:])\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-50:])\n",
    "    rmse=round(sm.r2_score(y_train[X_train.shape[0]-50:], Pred), 2)\n",
    "    M33.append(p)\n",
    "    Rmse3_rf3.append(mse)\n",
    "    RMSE3_rf3.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse3_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE3_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "M33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-seeker",
   "metadata": {},
   "source": [
    "# Jan 2020 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-emission",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import KFold\n",
    "X=data_Jan[['Net Signal','Temp1','RH1','Month','Day_of_week','Hour']]\n",
    "y=data_Jan['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "\n",
    "kf5 = KFold(n_splits=5, shuffle=False)\n",
    "X_Train=[]\n",
    "X_Test=[]\n",
    "\n",
    "for i,j in kf5.split(X_train):\n",
    "    X_Train.append(X_train.iloc[i])\n",
    "    X_Test.append(X_train.iloc[j]) \n",
    "    \n",
    "y_Train=[]\n",
    "y_Test=[]\n",
    "\n",
    "for k,l in kf5.split(y_train):\n",
    "    y_Train.append(y_train.iloc[k])\n",
    "    y_Test.append(y_train.iloc[l]) \n",
    "#X_train=preprocessing.scale(X_train)\n",
    "#X_train=preprocessing.normalize(X_train)\n",
    "A=np.array(y)/np.mean(y)\n",
    "A=sorted(A, reverse=True)\n",
    "sum4=sum(A[:1000])\n",
    "mean4=np.std(y)/np.mean(y)\n",
    "Rmse4_rf=[]\n",
    "RMSE4_rf=[]\n",
    "REU4=[]\n",
    "L_y4=[]\n",
    "A4=[]\n",
    "M4=[]\n",
    "D4=[]\n",
    "P4=[]\n",
    "Features=[]\n",
    "for i in range(1,10):\n",
    "    #lv=max(y_train[48*i:])\n",
    "    k=y_Train[0][48*i:].to_list()\n",
    "    #regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    model=regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=model.predict(X_train[48*i:])\n",
    "    #mse=round(sMAE(y_Train[0][48*i:], pred),2)\n",
    "    #rmse=round(sm.r2_score(y_Train[0][48*i:], pred), 2)\n",
    "    #U=np.sqrt(np.mean((0.25*np.array(y_Train[0][48*i:]))**2))\n",
    "    #RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_Train[0][48*i:]))**2))\n",
    "    #m=RMSE/(1*U)\n",
    "    #d=IOA(y_Train[0][48*i:], pred)\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))/np.mean(y)\n",
    "    p=precision(pred,y_train[48*i:])\n",
    "    #features=regressor.feature_importances_\n",
    "    #Features.append(features)\n",
    "    #D4.append(d)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-50:])\n",
    "    rmse=round(sm.r2_score(y_train[X_train.shape[0]-50:], Pred), 2)\n",
    "    M4.append(p)\n",
    "   \n",
    "    Rmse4_rf.append(RMSE)\n",
    "    #RMSE4_rf.append(rmse)\n",
    "    #reu=REF(pred,y_Train[0][48*i:],1)\n",
    "    #re=REF2(pred,y_Train[0][48*i:],20,lv)\n",
    "    #A4.append(re)\n",
    "    #REU4.append(reu)\n",
    "    #L_y4.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse4_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "M4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_Jan2[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_O3']]\n",
    "y=data_Jan2['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "A=np.array(y)/np.mean(y)\n",
    "A=sorted(A, reverse=True)\n",
    "sum4=sum(A[:100])\n",
    "mean4=np.std(y)/np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse4_rf2=[]\n",
    "RMSE4_rf2=[]\n",
    "M42=[]\n",
    "D42=[]\n",
    "for i in range(1,9):\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    #mse=round(sm.r2_score(y_test, pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #mse= mape=round(mean_absolute_error(y_test,pred)/np.mean(y_test),2)\n",
    "    #mse= mape=round(relative_mean_absolute_error(y_test,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.25*np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))/np.mean(y)\n",
    "    m=RMSE/(1*U)\n",
    "    p=precision(pred,y_train[48*i:])\n",
    "    d=IOA(y_train[48*i:], pred)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-50:])\n",
    "    rmse=round(sm.r2_score(y_train[X_train.shape[0]-50:], Pred), 2)\n",
    "    D42.append(d)\n",
    "    M42.append(p)\n",
    "    Rmse4_rf2.append(RMSE)\n",
    "    RMSE4_rf2.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse4_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse4_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "M42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_Jan3[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_NO2']]\n",
    "y=data_Jan3['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse4_rf3=[]\n",
    "RMSE4_rf3=[]\n",
    "M43=[]\n",
    "for i in range(1,10):\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    #mse=round(sm.r2_score(y_test, pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #mse= mape=round(mean_absolute_error(y_test,pred)/np.mean(y_test),2)\n",
    "    #mse= mape=round(relative_mean_absolute_error(y_test,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.3*np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    p=precision(pred,y_train[48*i:])\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-50:])\n",
    "    rmse=round(sm.r2_score(y_train[X_train.shape[0]-50:], Pred), 2)\n",
    "    M43.append(p)\n",
    "    Rmse4_rf3.append(mse)\n",
    "    RMSE4_rf3.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse4_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE4_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "M43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[[Rmse1_rf[i],Rmse2_rf[:9][i],Rmse3_rf[:9][i],Rmse4_rf[:9][i]] for i in range(9)]\n",
    "AV=[]\n",
    "for i in range(9):\n",
    "    AV.append(np.mean(A[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "Day=[2*i for i in range(1,10)]\n",
    "#plt.plot(Day,Rmse1_rf, color='red')\n",
    "#plt.plot(Day,Rmse2_rf[:9], color='blue')\n",
    "#plt.plot(Day,Rmse3_rf[:9], color='teal')\n",
    "plt.plot(Day,AV, color='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse1_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-nursing",
   "metadata": {},
   "source": [
    "# Feb 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-beads",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-conflict",
   "metadata": {},
   "source": [
    "X=data_Feb[['Net Signal','Lab1','Temp','RH','Month','Day_of_week','Day','Hour']]\n",
    "y=data_Feb['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-wells",
   "metadata": {},
   "source": [
    "Rmse5_rf2=[]\n",
    "RMSE5_rf2=[]\n",
    "M52=[]\n",
    "for i in range(1,7):\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    #mse=round(sm.r2_score(y_test, pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse= mape=round(mean_absolute_percentage_error(y_test,pred),2)\n",
    "    #mse=round(relative_mean_absolute_error(y,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.15*np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))\n",
    "    m=RMSE/(1.67*U)\n",
    "    M52.append(m)\n",
    "    Rmse5_rf2.append(mse)\n",
    "    RMSE5_rf2.append(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-commercial",
   "metadata": {},
   "source": [
    "A=y.to_list()\n",
    "Ext_feb=[]\n",
    "for i in range(len(A)):\n",
    "    if A[i]>3*np.mean(A):\n",
    "        Ext_feb.append(i)\n",
    "N_Ext_feb=len(Ext_feb)\n",
    "N_Ext_feb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-occasion",
   "metadata": {},
   "source": [
    "mean_feb=np.mean(y)\n",
    "N_feb=y.shape[0]\n",
    "Mean_Rmse_feb=np.mean(Rmse5_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-promise",
   "metadata": {},
   "source": [
    "# March 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-alberta",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-eleven",
   "metadata": {},
   "source": [
    "X=data_Mar[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour']]\n",
    "y=data_Mar['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.0001,shuffle=False)\n",
    "A=np.array(y)/np.mean(y)\n",
    "A=sorted(A, reverse=True)\n",
    "sum6=sum(A[:100])\n",
    "mean6=np.std(y)/np.mean(y)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-makeup",
   "metadata": {},
   "source": [
    "Rmse6_rf=[]\n",
    "RMSE6_rf=[]\n",
    "REU6=[]\n",
    "L_y6=[]\n",
    "A6=[]\n",
    "M5=[]\n",
    "S=[]\n",
    "D6=[]\n",
    "for i in range(1,11):\n",
    "    k=y_train[48*i:].to_list()\n",
    "    #lv=max(y_train[48*i:])\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    #mse=round(sm.r2_score(y_test, pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse= mape=round(mean_absolute_percentage_error(y_test,pred),2)\n",
    "    #mse=round(relative_mean_absolute_error(y,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    s=(np.mean(y_train[48*i:]))/(np.array(y_train[48*i:]))\n",
    "    U=np.sqrt(np.mean((0.25*np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    d=IOA(y_train[48*i:], pred)\n",
    "    D6.append(d)\n",
    "    M5.append(m)\n",
    "    S.append(s)\n",
    "    Rmse6_rf.append(mse)\n",
    "    RMSE6_rf.append(rmse)\n",
    "    reu=REF(pred,y_train[48*i:],1)\n",
    "    re=REF2(pred,y_train[48*i:],1.2,lv)\n",
    "    A6.append(re)\n",
    "    REU6.append(reu)\n",
    "    L_y6.append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-regulation",
   "metadata": {},
   "source": [
    "REU_d1=list(REU1[0])+list(REU2[0])+list(REU3[0])+list(REU4[0])+list(REU6[0])\n",
    "REU_d2=list(REU1[1])+list(REU2[1])+list(REU3[1])+list(REU4[1])+list(REU6[1])\n",
    "REU_d3=list(REU1[2])+list(REU2[2])+list(REU3[2])+list(REU4[2])+list(REU6[2])\n",
    "REU_d4=list(REU1[3])+list(REU2[3])+list(REU3[3])+list(REU4[3])+list(REU6[3])\n",
    "REU_d5=list(REU1[4])+list(REU2[4])+list(REU3[4])+list(REU4[4])+list(REU6[4])\n",
    "REU_d6=list(REU1[5])+list(REU2[5])+list(REU3[5])+list(REU4[5])+list(REU6[5])\n",
    "REU_d7=list(REU1[6])+list(REU2[6])+list(REU3[6])+list(REU4[6])+list(REU6[6])\n",
    "REU_d8=list(REU1[7])+list(REU2[7])+list(REU3[7])+list(REU4[7])+list(REU6[7])\n",
    "REU_d9=list(REU1[8])+list(REU2[8])+list(REU3[8])+list(REU4[8])+list(REU6[8])\n",
    "REU_d10=list(REU1[9])+list(REU2[9])+list(REU3[9])+list(REU4[9])+list(REU6[9])\n",
    "\n",
    "REU=[REU_d1,REU_d2,REU_d3,REU_d4,REU_d5,REU_d6,REU_d7,REU_d8,REU_d9,REU_d10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-attribute",
   "metadata": {},
   "source": [
    "L_d1=list(L_y1[0])+list(L_y2[0])+list(L_y3[0])+list(L_y4[0])+list(L_y6[0])\n",
    "L_d2=list(L_y1[1])+list(L_y2[1])+list(L_y3[1])+list(L_y4[1])+list(L_y6[1])\n",
    "L_d3=list(L_y1[2])+list(L_y2[2])+list(L_y3[2])+list(L_y4[2])+list(L_y6[2])\n",
    "L_d4=list(L_y1[3])+list(L_y2[3])+list(L_y3[3])+list(L_y4[3])+list(L_y6[3])\n",
    "L_d5=list(L_y1[4])+list(L_y2[4])+list(L_y3[4])+list(L_y4[4])+list(L_y6[4])\n",
    "L_d6=list(L_y1[5])+list(L_y2[5])+list(L_y3[5])+list(L_y4[5])+list(L_y6[5])\n",
    "L_d7=list(L_y1[6])+list(L_y2[6])+list(L_y3[6])+list(L_y4[6])+list(L_y6[6])\n",
    "L_d8=list(L_y1[7])+list(L_y2[7])+list(L_y3[7])+list(L_y4[7])+list(L_y6[7])\n",
    "L_d9=list(L_y1[8])+list(L_y2[8])+list(L_y3[8])+list(L_y4[8])+list(L_y6[8])\n",
    "L_d10=list(L_y1[9])+list(L_y2[9])+list(L_y3[9])+list(L_y4[9])+list(L_y6[9])\n",
    "L=[L_d1,L_d2,L_d3,L_d4,L_d5,L_d6,L_d7,L_d8,L_d9,L_d10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-economy",
   "metadata": {},
   "source": [
    "import numpy.polynomial.polynomial as poly\n",
    "u_cal=REU\n",
    "L_y=L\n",
    "for i in range(len(REU)):\n",
    "    fig= plt.figure(figsize=(7,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #ax.patch.set_facecolor('lightblue')\n",
    "    #ax.patch.set_alpha(0.1)\n",
    "    ind=[]\n",
    "    U_cal=[]\n",
    "    Ref=[]\n",
    "    dqo=[25 for i in range(len(Ref))]\n",
    "    plt.scatter(L_y[i],u_cal[i], color='#4B0082')\n",
    "    plt.axhline(y=25, color='black', linestyle='-.',linewidth=3)\n",
    "    plt.ylabel('Relative Expanded Uncertainty(%)', fontsize=16)\n",
    "    plt.xlabel('Reference CO concentration(ppb)',fontsize=16)\n",
    "    plt.grid(linestyle='-.',linewidth=0.1)\n",
    "    #plt.title('LAB',fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-geography",
   "metadata": {},
   "source": [
    "X=data_Mar2[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_O3']]\n",
    "y=data_Mar2['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "A=np.array(y)/np.mean(y)\n",
    "A=sorted(A, reverse=True)\n",
    "sum6=sum(A[:100])\n",
    "mean6=np.std(y)/np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-effort",
   "metadata": {},
   "source": [
    "Rmse6_rf2=[]\n",
    "RMSE6_rf2=[]\n",
    "M52=[]\n",
    "for i in range(1,11):\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    #mse=round(sm.r2_score(y_test, pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse= mape=round(mean_absolute_percentage_error(y_test,pred),2)\n",
    "    #mse=round(relative_mean_absolute_error(y,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.15*np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))\n",
    "    m=RMSE/(1.67*U)\n",
    "    M52.append(m)\n",
    "    Rmse6_rf2.append(mse)\n",
    "    RMSE6_rf2.append(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-input",
   "metadata": {},
   "source": [
    "# April 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-locator",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-technique",
   "metadata": {},
   "source": [
    "X=data_Apr[['Net Signal','Lab1','Temp','RH','Month','Day_of_week','Day','Hour']]\n",
    "y=data_Apr['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=True)\n",
    "A=np.array(y)/np.mean(y)\n",
    "A=sorted(A, reverse=True)\n",
    "sum7=sum(A[:100])\n",
    "mean7=np.std(y)/np.mean(y)\n",
    "Rmse10_rf2=[]\n",
    "RMSE10_rf2=[]\n",
    "M52=[]\n",
    "for i in range(1,5):\n",
    "    regressor.fit(X_train[:48*i], y_train[:48*i])\n",
    "    pred=regressor.predict(X_train[48*i:])\n",
    "    #mse=round(sm.r2_score(y_test, pred), 2)\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse= mape=round(mean_absolute_percentage_error(y_test,pred),2)\n",
    "    #mse=round(relative_mean_absolute_error(y,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[48*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[48*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.15*np.array(y_train[48*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[48*i:]))**2))\n",
    "    m=RMSE/(1.67*U)\n",
    "    M52.append(m)\n",
    "    Rmse5_rf2.append(mse)\n",
    "    RMSE5_rf2.append(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-planning",
   "metadata": {},
   "source": [
    "A=y.to_list()\n",
    "Ext_apr=[]\n",
    "for i in range(len(A)):\n",
    "    if A[i]>3*np.mean(A):\n",
    "        Ext_apr.append(i)\n",
    "N_Ext_apr=len(Ext_apr)\n",
    "N_Ext_apr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-cathedral",
   "metadata": {},
   "source": [
    "mean_apr=np.mean(y)\n",
    "N_apr=y.shape[0]\n",
    "Mean_Rmse_apr=np.mean(Rmse10_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-quest",
   "metadata": {},
   "source": [
    "Mean_Rmse=[Mean_Rmse_oct,Mean_Rmse_nov,Mean_Rmse_dec,Mean_Rmse_jan,Mean_Rmse_feb,Mean_Rmse_mar,Mean_Rmse_apr]\n",
    "Mean_conc=[mean_oct,mean_nov,mean_dec,mean_jan,mean_feb,mean_mar,mean_apr]\n",
    "N=[N_oct,N_nov,N_dec,N_jan,N_feb,N_mar,N_apr]\n",
    "N_Ext=[N_Ext_oct,N_Ext_nov,N_Ext_dec,N_Ext_jan,N_Ext_feb,N_Ext_mar,N_Ext_apr]\n",
    "\n",
    "Rmse=[]\n",
    "for i in range(10):\n",
    "    A=[Rmse1_rf[i],Rmse2_rf[i],Rmse3_rf[i],Rmse4_rf[i],Rmse5_rf[i],Rmse6_rf[i],Rmse10_rf[i]]\n",
    "    Rmse.append(A)\n",
    "RMSE=Rmse[0]+Rmse[1]+Rmse[2]+Rmse[3]+Rmse[4]+Rmse[5]+Rmse[6]+Rmse[7]\n",
    "Conc=Mean_conc+Mean_conc+Mean_conc+Mean_conc+Mean_conc+Mean_conc+Mean_conc+Mean_conc\n",
    "N_dp=N+N+N+N+N+N+N+N\n",
    "N_ext=N_Ext+N_Ext+N_Ext+N_Ext+N_Ext+N_Ext+N_Ext+N_Ext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-tonight",
   "metadata": {},
   "source": [
    "import plotly.express as px\n",
    "from IPython.display import Image\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "Day_1_rf=[RMSE1_rf[0],RMSE2_rf[0],RMSE3_rf[0],RMSE4_rf[0],RMSE6_rf[0]]\n",
    "Day_2_rf=[RMSE1_rf[1],RMSE2_rf[1],RMSE3_rf[1],RMSE4_rf[1],RMSE6_rf[1]]\n",
    "Day_3_rf=[RMSE1_rf[2],RMSE2_rf[2],RMSE3_rf[2],RMSE4_rf[2],RMSE6_rf[2]]\n",
    "Day_4_rf=[RMSE1_rf[3],RMSE2_rf[3],RMSE3_rf[3],RMSE4_rf[3],RMSE6_rf[3]]\n",
    "Day_5_rf=[RMSE1_rf[4],RMSE2_rf[4],RMSE3_rf[4],RMSE4_rf[4],RMSE6_rf[4]]\n",
    "Day_6_rf=[RMSE1_rf[5],RMSE2_rf[5],RMSE3_rf[5],RMSE4_rf[5],RMSE6_rf[5]]\n",
    "Day_7_rf=[RMSE1_rf[6],RMSE2_rf[6],RMSE3_rf[6],RMSE4_rf[6],RMSE6_rf[6]]\n",
    "Day_8_rf=[RMSE1_rf[7],RMSE2_rf[7],RMSE3_rf[7],RMSE4_rf[7],RMSE6_rf[7]]\n",
    "Day_9_rf=[RMSE1_rf[8],RMSE2_rf[8],RMSE3_rf[8],RMSE4_rf[8],RMSE6_rf[8]]\n",
    "Day_10_rf=[RMSE1_rf[9],RMSE2_rf[9],RMSE3_rf[9],RMSE4_rf[9],RMSE6_rf[9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-factory",
   "metadata": {},
   "source": [
    "Day_1_ann=[RMSE1_ann[0],RMSE2_ann[0],RMSE3_ann[0],RMSE4_ann[0],RMSE6_ann[0]]\n",
    "Day_2_ann=[RMSE1_ann[1],RMSE2_ann[1],RMSE3_ann[1],RMSE4_ann[1],RMSE6_ann[1]]\n",
    "Day_3_ann=[RMSE1_ann[2],RMSE2_ann[2],RMSE3_ann[2],RMSE4_ann[2],RMSE6_ann[2]]\n",
    "Day_4_ann=[RMSE1_ann[3],RMSE2_ann[3],RMSE3_ann[3],RMSE4_ann[3],RMSE6_ann[3]]\n",
    "Day_5_ann=[RMSE1_ann[4],RMSE2_ann[4],RMSE3_ann[4],RMSE4_ann[4],RMSE6_ann[4]]\n",
    "Day_6_ann=[RMSE1_ann[5],RMSE2_ann[5],RMSE3_ann[5],RMSE4_ann[5],RMSE6_ann[5]]\n",
    "Day_7_ann=[RMSE1_ann[6],RMSE2_ann[6],RMSE3_ann[6],RMSE4_ann[6],RMSE6_ann[6]]\n",
    "Day_8_ann=[RMSE1_ann[7],RMSE2_ann[7],RMSE3_ann[7],RMSE4_ann[7],RMSE6_ann[7]]\n",
    "Day_9_ann=[RMSE1_ann[8],RMSE2_ann[8],RMSE3_ann[8],RMSE4_ann[8],RMSE6_ann[8]]\n",
    "Day_10_ann=[RMSE1_ann[9],RMSE2_ann[9],RMSE3_ann[9],RMSE4_ann[9],RMSE6_ann[9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-librarian",
   "metadata": {},
   "source": [
    "Day_1_RF=[Rmse1_rf[0],Rmse2_rf[0],Rmse3_rf[0],Rmse4_rf[0],Rmse6_rf[0]]\n",
    "Day_2_RF=[Rmse1_rf[1],Rmse2_rf[1],Rmse3_rf[1],Rmse4_rf[1],Rmse6_rf[1]]\n",
    "Day_3_RF=[Rmse1_rf[2],Rmse2_rf[2],Rmse3_rf[2],Rmse4_rf[2],Rmse6_rf[2]]\n",
    "Day_4_RF=[Rmse1_rf[3],Rmse2_rf[3],Rmse3_rf[3],Rmse4_rf[3],Rmse6_rf[3]]\n",
    "Day_5_RF=[Rmse1_rf[4],Rmse2_rf[4],Rmse3_rf[4],Rmse4_rf[4],Rmse6_rf[4]]\n",
    "Day_6_RF=[Rmse1_rf[5],Rmse2_rf[5],Rmse3_rf[5],Rmse4_rf[5],Rmse6_rf[5]]\n",
    "Day_7_RF=[Rmse1_rf[6],Rmse2_rf[6],Rmse3_rf[6],Rmse4_rf[6],Rmse6_rf[6]]\n",
    "Day_8_RF=[Rmse1_rf[7],Rmse2_rf[7],Rmse3_rf[7],Rmse4_rf[7],Rmse6_rf[7]]\n",
    "Day_9_RF=[Rmse1_rf[8],Rmse2_rf[8],Rmse3_rf[8],Rmse4_rf[8],Rmse6_rf[8]]\n",
    "Day_10_RF=[Rmse1_rf[9],Rmse2_rf[9],Rmse3_rf[9],Rmse4_rf[9],Rmse6_rf[9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-blind",
   "metadata": {},
   "source": [
    "Day_1_RF2=[Rmse1_rf2[0],Rmse2_rf2[0],Rmse3_rf2[0],Rmse4_rf2[0],Rmse6_rf2[0]]\n",
    "Day_2_RF2=[Rmse1_rf2[1],Rmse2_rf2[1],Rmse3_rf2[1],Rmse4_rf2[1],Rmse6_rf2[1]]\n",
    "Day_3_RF2=[Rmse1_rf2[2],Rmse2_rf2[2],Rmse3_rf2[2],Rmse4_rf2[2],Rmse6_rf2[2]]\n",
    "Day_4_RF2=[Rmse1_rf2[3],Rmse2_rf2[3],Rmse3_rf2[3],Rmse4_rf2[3],Rmse6_rf2[3]]\n",
    "Day_5_RF2=[Rmse1_rf2[4],Rmse2_rf2[4],Rmse3_rf2[4],Rmse4_rf2[4],Rmse6_rf2[4]]\n",
    "Day_6_RF2=[Rmse1_rf2[5],Rmse2_rf2[5],Rmse3_rf2[5],Rmse4_rf2[5],Rmse6_rf2[5]]\n",
    "Day_7_RF2=[Rmse1_rf2[6],Rmse2_rf2[6],Rmse3_rf2[6],Rmse4_rf2[6],Rmse6_rf2[6]]\n",
    "Day_8_RF2=[Rmse1_rf2[7],Rmse2_rf2[7],Rmse3_rf2[7],Rmse4_rf2[7],Rmse6_rf2[7]]\n",
    "Day_9_RF2=[Rmse1_rf2[8],Rmse2_rf2[8],Rmse3_rf2[8],Rmse4_rf2[8],Rmse6_rf2[8]]\n",
    "Day_10_RF2=[Rmse1_rf2[9],Rmse2_rf2[9],Rmse3_rf2[9],Rmse4_rf2[9],Rmse6_rf2[9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-reaction",
   "metadata": {},
   "source": [
    "Mean=(np.array(Rmse1_rf)+np.array(Rmse2_rf)+np.array(Rmse3_rf)+np.array(Rmse4_rf)+np.array(Rmse6_rf))/5\n",
    "Mean=list(Mean)+list(Mean)+list(Mean)+list(Mean)\n",
    "Mean=sorted(Mean)\n",
    "\n",
    "Oct=sorted(Rmse1_rf+Rmse1_rf+Rmse1_rf+Rmse1_rf)\n",
    "Nov=sorted(Rmse2_rf+Rmse2_rf+Rmse2_rf+Rmse2_rf)\n",
    "Dec=sorted(Rmse3_rf+Rmse3_rf+Rmse3_rf+Rmse3_rf)\n",
    "Jan=sorted(Rmse4_rf+Rmse4_rf+Rmse4_rf+Rmse4_rf)\n",
    "Mar=sorted(Rmse6_rf+Rmse6_rf+Rmse6_rf+Rmse6_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from IPython.display import Image\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "Day_1_MPI=[M1[0],M2[0],M3[0],M4[0]]#M5[0]]\n",
    "Day_2_MPI=[M1[1],M2[1],M3[1],M4[1]]#M5[1]]\n",
    "Day_3_MPI=[M1[2],M2[2],M3[2],M4[2]]#M5[2]]\n",
    "Day_4_MPI=[M1[3],M2[3],M3[3],M4[3]]#M5[3]]\n",
    "Day_5_MPI=[M1[4],M2[4],M3[4],M4[4]]#M5[4]]\n",
    "Day_6_MPI=[M1[5],M2[5],M3[5],M4[5]]#M5[5]]\n",
    "Day_7_MPI=[M1[6],M2[6],M3[6],M4[6]]#M5[6]]\n",
    "Day_8_MPI=[M1[7],M2[7],M3[7],M4[7]]#M5[7]]\n",
    "Day_9_MPI=[M1[8],M2[8],M3[8],M4[8]]#M5[8]]\n",
    "#Day_10_MPI=[M1[9],M2[9],M3[9],M4[9]]#M5[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "Day_1_MPI2=[M12[0],M22[0],M32[0],M42[0]]#,M52[0]]\n",
    "Day_2_MPI2=[M12[1],M22[1],M32[1],M42[1]]#,M52[1]]\n",
    "Day_3_MPI2=[M12[2],M22[2],M32[2],M42[2]]#,M52[2]]\n",
    "Day_4_MPI2=[M12[3],M22[3],M32[3],M42[3]]#,M52[3]]\n",
    "Day_5_MPI2=[M12[4],M22[4],M32[4],M42[4]]#,M52[4]]\n",
    "Day_6_MPI2=[M12[5],M22[5],M32[5],M42[5]]#,M52[5]]\n",
    "Day_7_MPI2=[M12[6],M22[6],M32[6],M42[6]]#,M52[6]]\n",
    "Day_8_MPI2=[M12[7],M22[7],M32[7],M42[7]]#,M52[7]]\n",
    "#Day_9_MPI2=[M12[8],M22[8],M32[8],M42[8]]#,M52[8]]\n",
    "#Day_10_MPI2=[M12[9],M22[9],M32[9],M42[9]]#,M52[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "Day_1_MPI3=[M13[0],M23[0],M33[0],M43[0]]#,M52[0]]\n",
    "Day_2_MPI3=[M13[1],M23[1],M33[1],M43[1]]#,M52[1]]\n",
    "Day_3_MPI3=[M13[2],M23[2],M33[2],M43[2]]#,M52[2]]\n",
    "Day_4_MPI3=[M13[3],M23[3],M33[3],M43[3]]#,M52[3]]\n",
    "Day_5_MPI3=[M13[4],M23[4],M33[4],M43[4]]#,M52[4]]\n",
    "Day_6_MPI3=[M13[5],M23[5],M33[5],M43[5]]#,M52[5]]\n",
    "Day_7_MPI3=[M13[6],M23[6],M33[6],M43[6]]#,M52[6]]\n",
    "Day_8_MPI3=[M13[7],M23[7],M33[7],M43[7]]#,M52[7]]\n",
    "#Day_9_MPI3=[M13[8],M23[8],M33[8],M43[8]]#,M52[8]]\n",
    "#Day_10_MPI3=[M13[9],M23[9],M33[9],M43[9]]#,M52[9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-italic",
   "metadata": {},
   "source": [
    "Day_1_ANN=[Rmse1_ann[0],Rmse2_ann[0],Rmse3_ann[0],Rmse4_ann[0],Rmse6_ann[0]]\n",
    "Day_2_ANN=[Rmse1_ann[1],Rmse2_ann[1],Rmse3_ann[1],Rmse4_ann[1],Rmse6_ann[1]]\n",
    "Day_3_ANN=[Rmse1_ann[2],Rmse2_ann[2],Rmse3_ann[2],Rmse4_ann[2],Rmse6_ann[2]]\n",
    "Day_4_ANN=[Rmse1_ann[3],Rmse2_ann[3],Rmse3_ann[3],Rmse4_ann[3],Rmse6_ann[3]]\n",
    "Day_5_ANN=[Rmse1_ann[4],Rmse2_ann[4],Rmse3_ann[4],Rmse4_ann[4],Rmse6_ann[4]]\n",
    "Day_6_ANN=[Rmse1_ann[5],Rmse2_ann[5],Rmse3_ann[5],Rmse4_ann[5],Rmse6_ann[5]]\n",
    "Day_7_ANN=[Rmse1_ann[6],Rmse2_ann[6],Rmse3_ann[6],Rmse4_ann[6],Rmse6_ann[6]]\n",
    "Day_8_ANN=[Rmse1_ann[7],Rmse2_ann[7],Rmse3_ann[7],Rmse4_ann[7],Rmse6_ann[7]]\n",
    "Day_9_ANN=[Rmse1_ann[8],Rmse2_ann[8],Rmse3_ann[8],Rmse4_ann[8],Rmse6_ann[8]]\n",
    "Day_10_ANN=[Rmse1_ann[9],Rmse2_ann[9],Rmse3_ann[9],Rmse4_ann[9],Rmse6_ann[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF_P=Day_1_rf+Day_2_rf+Day_3_rf+Day_4_rf+Day_5_rf+Day_6_rf+Day_7_rf+Day_8_rf+Day_9_rf+Day_10_rf\n",
    "#ANN_P=Day_1_ann+Day_2_ann+Day_3_ann+Day_4_ann+Day_5_ann+Day_6_ann+Day_7_ann+Day_8_ann+Day_9_ann+Day_10_ann\n",
    "#RF_R=Day_1_RF+Day_2_RF+Day_3_RF+Day_4_RF+Day_5_RF+Day_6_RF+Day_7_RF+Day_8_RF+Day_9_RF+Day_10_RF\n",
    "#RF_R2=Day_1_RF2+Day_2_RF2+Day_3_RF2+Day_4_RF2+Day_5_RF2+Day_6_RF2+Day_7_RF2+Day_8_RF2+Day_9_RF2+Day_10_RF2\n",
    "MPI=Day_1_MPI+Day_2_MPI+Day_3_MPI+Day_4_MPI+Day_5_MPI+Day_6_MPI+Day_7_MPI+Day_8_MPI#+Day_9_MPI+Day_10_MPI\n",
    "MPI2=Day_1_MPI2+Day_2_MPI2+Day_3_MPI2+Day_4_MPI2+Day_5_MPI2+Day_6_MPI2+Day_7_MPI2+Day_8_MPI2#+Day_9_MPI2+Day_10_MPI2\n",
    "MPI3=Day_1_MPI3+Day_2_MPI3+Day_3_MPI3+Day_4_MPI3+Day_5_MPI3+Day_6_MPI3+Day_7_MPI3+Day_8_MPI3#+Day_9_MPI3+Day_10_MPI3\n",
    "#ANN_R=Day_1_ANN+Day_2_ANN+Day_3_ANN+Day_4_ANN+Day_5_ANN+Day_6_ANN+Day_7_ANN+Day_8_ANN+Day_9_ANN+Day_10_ANN\n",
    "x0=['0' for i in range(4)]\n",
    "x1=['2' for i in range(4)]\n",
    "x2=['4' for i in range(4)]\n",
    "x3=['6' for i in range(4)]\n",
    "x4=['8' for i in range(4)]\n",
    "x5=['10' for i in range(4)]\n",
    "x6=['12' for i in range(4)]\n",
    "x7=['14' for i in range(4)]\n",
    "x8=['16' for i in range(4)]\n",
    "x9=['18' for i in range(4)]\n",
    "x10=['20' for i in range(4)]\n",
    "x11=['22' for i in range(4)]\n",
    "Reg=[10 for i in range(48)]\n",
    "Reg=[10 for i in range(48)]\n",
    "Spatial=[25 for i in range(60) ]\n",
    "Intervention=[30 for i in range(60) ]\n",
    "Hs_and_sp=[50 for i in range(60) ]\n",
    "reg=[0.9 for i in range(60)]\n",
    "spatial=[0.75 for i in range(60) ]\n",
    "intervention=[0.7 for i in range(60) ]\n",
    "\n",
    "x=x1+x2+x3+x4+x5+x6+x7+x8#+x9+x10\n",
    "X=x0+x1+x2+x3+x4+x5+x6+x7+x8+x9#+x10+x11\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio\n",
    "fig = go.Figure() \n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([1, 3, 2, 3, 1])\n",
    "# Defining x axis\n",
    "x = x\n",
    "\n",
    "\n",
    "\n",
    "fig.add_trace(go.Box(\n",
    "  \n",
    "    # defining y axis in corresponding\n",
    "    # to x-axis\n",
    "    y=MPI,\n",
    "    x=x,\n",
    "    #name=r'$CO$',\n",
    "    marker_color='darkblue',\n",
    "    showlegend=False\n",
    "   \n",
    "))\n",
    "fig.add_trace(go.Box(\n",
    "  \n",
    "    # defining y axis in corresponding\n",
    "    # to x-axis\n",
    "    y=MPI2,\n",
    "    x=x,\n",
    "    #name=r'$NO_2$',\n",
    "    marker_color='Teal',\n",
    "    showlegend=False\n",
    "   \n",
    "))\n",
    "\n",
    "fig.add_trace(go.Box(\n",
    "  \n",
    "    # defining y axis in corresponding\n",
    "     #to x-axis\n",
    "    y=MPI3,\n",
    "    x=x,\n",
    "    #name=r'$O_3$',\n",
    "    marker_color='darkgoldenrod',\n",
    "    showlegend=False\n",
    "   \n",
    "))\n",
    "\n",
    "\n",
    "#x = x\n",
    "#fig.add_trace(go.Box(\n",
    "  \n",
    "    # defining y axis in corresponding\n",
    "    # to x-axis\n",
    "   # y=RF_R2,\n",
    "    #x=x,\n",
    "    #name='R^2(NO2)',\n",
    "    #marker_color='teal',\n",
    "    #showlegend=True\n",
    "   \n",
    "\n",
    "#))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#fig.add_trace(go.Box(\n",
    "  \n",
    "    #defining y axis in corresponding\n",
    "   # to x-axis\n",
    "   # y=RF_R,\n",
    "    #x=x,\n",
    "    #name='SMAE',\n",
    "    #marker_color='#CD6600',\n",
    "    #showlegend=True\n",
    "   \n",
    "#))\n",
    "#fig.add_trace(go.Box(\n",
    "   #y=ANN_R,\n",
    "    #x=x,\n",
    "    #name='XGBoost(NMAE)',\n",
    "    #marker_color='deeppink',\n",
    "    #showlegend=True\n",
    "\n",
    "#))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=X,\n",
    "                y=Reg, \n",
    "                name=\"RC\",\n",
    "                mode = 'lines',\n",
    "                #marker_color='dodgerblue',\n",
    "                line = dict(shape = 'linear',width = 1.5, color = 'green', dash = 'dot'),\n",
    "                connectgaps = True,\n",
    "                showlegend=False\n",
    "                        ))\n",
    "fig.add_trace(go.Scatter(x=X,\n",
    "                y=Spatial, \n",
    "                name=\"SGS\",\n",
    "                mode = 'lines',\n",
    "                marker_color='dodgerblue',\n",
    "                line = dict(shape = 'linear',width = 1.5, color = 'purple', dash = 'dot'),\n",
    "                connectgaps = True,\n",
    "                showlegend=False\n",
    "                    \n",
    "                        ))\n",
    "fig.add_trace(go.Scatter(x=X,\n",
    "                y=Intervention, \n",
    "                name=\"IS/IM\",\n",
    "                mode = 'lines',\n",
    "                marker_color='dodgerblue',\n",
    "                line = dict(shape = 'linear',width = 1.5, color = 'orange', dash = 'dot'),\n",
    "                connectgaps = True,\n",
    "                showlegend=False\n",
    "                \n",
    "                        ))\n",
    "fig.add_trace(go.Scatter(x=X,\n",
    "                y=Hs_and_sp, \n",
    "                name=\"HA/SP\",\n",
    "                    \n",
    "                mode = 'lines',\n",
    "                marker_color='dodgerblue',\n",
    "                line = dict(shape = 'linear',width = 1.5, color = 'dodgerblue', dash = 'dot'),\n",
    "                connectgaps = True,\n",
    "                showlegend=False\n",
    "               \n",
    "                        ))\n",
    "\n",
    "  \n",
    "fig.update_layout(autosize=True,\n",
    "                 #title={'text': r\"$NO_2$\",\n",
    "        #'y':0.78,\n",
    "        #'x':0.5,\n",
    "        #'xanchor': 'center',\n",
    "        #'yanchor': 'top'\n",
    "                       #}, \n",
    "    width=1000,\n",
    "    height=500,\n",
    "                  \n",
    "  legend=dict( yanchor=\"bottom\",\n",
    "    y=0.865,\n",
    "    x=0.01,\n",
    "    orientation=\"h\"\n",
    "),\n",
    "    # group together boxes of the different\n",
    "    # traces for each value of x\n",
    "    boxmode='group',\n",
    "                  plot_bgcolor='rgba(0.0,0.0,0.0,0.0)'\n",
    "                 \n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Days of training\",tickfont = dict(size=16),\n",
    "                 titlefont = dict(size=24),linewidth=1.4, linecolor='black',tick0 = 2,\n",
    "        dtick = 2,\n",
    "                 mirror=True)\n",
    "fig.update_yaxes(title_text=\"Precision (%)\",tickfont = dict(size=16),range=[0.4,1],\n",
    "                 titlefont = dict(size=24),linewidth=1.4, linecolor='black',tick0 = 0.2,\n",
    "        dtick =0.2,\n",
    "                 mirror=True)\n",
    "fig.show()\n",
    "chart_studio.plotly.sign_in('vinylango', 'gybbJVWfRSUoTcRRSa6J')\n",
    "chart_studio.plotly.image.save_as(fig, filename='models_boxplot.png')\n",
    "#Image('models_boxplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-factory",
   "metadata": {},
   "source": [
    "Metric1=['RF' for i in range(len(RF))]\n",
    "Metric2=['XGBoost' for i in range(len(ANN))]\n",
    "Model=Metric1+Metric2\n",
    "Training=x+x\n",
    "Values=RF+ANN\n",
    "len(Values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-chaos",
   "metadata": {},
   "source": [
    "#Violin plot which also show the density of the distribution\n",
    "import plotly.express as px\n",
    "Metric1=['RF' for i in range(len(RF))]\n",
    "Metric2=['XGBoost' for i in range(len(ANN))]\n",
    "Model=Metric1+Metric2\n",
    "Training=x+x\n",
    "Values=RF+ANN\n",
    "lst=[[Training[i],Values[i],Model[i]] for i in range(len(Model))]\n",
    "df = pd.DataFrame(lst, columns =['Training Days', 'Pearson correlation (r)','Model'])\n",
    "\n",
    "#fig = px.violin( df,y=\"Performance\", x=\"Calibration Model\", color='Metric', box=True,points=\"all\",\n",
    "          #hover_data=df.columns)\n",
    "fig = px.violin( df,y=\"Pearson correlation (r)\", x=\"Training Days\", color='Model', box=True,\n",
    "          hover_data=df.columns)\n",
    "\n",
    "\n",
    "fig.update_layout(autosize=False,\n",
    "    width=900,\n",
    "    height=500)\n",
    "fig.show()\n",
    "#chart_studio.plotly.sign_in('vinylango', 'gybbJVWfRSUoTcRRSa6J')\n",
    "#chart_studio.plotly.image.save_as(fig, filename='models_violinplots.png')\n",
    "#Image('models_violinplots.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-anatomy",
   "metadata": {},
   "source": [
    "# Seasonal Calibration Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-house",
   "metadata": {},
   "source": [
    "# Fall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-anger",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1=[data_oct,data_nov]\n",
    "fall=pd.concat(frame1)\n",
    "#fall=fall.sample(frac=1)\n",
    "Day=[5*i for i in range(1,11) ]\n",
    "Fall=fall.resample('h').mean()\n",
    "Fall=Fall.dropna()\n",
    "#Fall=Fall.sample(frac=1)\n",
    "X=Fall[['Net Signal','Temp1','RH1','Month','Day_of_week','Day','Hour']]\n",
    "y=Fall['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "mean1=np.std(y)\n",
    "Rmse7_rf=[]\n",
    "RMSE7_rf=[]\n",
    "REU7=[]\n",
    "L_y7=[]\n",
    "A7=[]\n",
    "M7=[]\n",
    "B7=[]\n",
    "for i in range(1,9):\n",
    "    k=y_train[120*i:].to_list()\n",
    "    lv=max(y_train[120*i:])\n",
    "    regressor.fit(X_train[:120*i], y_train[:120*i])\n",
    "    pred=regressor.predict(X_train[120*i:])\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-100:])\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    #mse=round(relative_mean_absolute_error(y_test,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[120*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[120*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.25*np.array(y_train[120*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[120*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-100:])\n",
    "    p=precision(Pred,y_train[X_train.shape[0]-100:])\n",
    "    M7.append(p)\n",
    "    b=bias(Pred,y_train[X_train.shape[0]-100:])\n",
    "    B7.append(b)\n",
    "    Rmse7_rf.append(mse)\n",
    "    RMSE7_rf.append(rmse)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse7_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE7_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "M7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1=[data_oct2,data_nov2]\n",
    "fall2=pd.concat(frame1)\n",
    "#fall=fall.sample(frac=1)\n",
    "Day=[5*i for i in range(1,11) ]\n",
    "Fall2=fall2.resample('h').mean()\n",
    "Fall2=Fall2.dropna()\n",
    "#Fall=Fall.sample(frac=1)\n",
    "X=Fall2[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_O3']]\n",
    "y=Fall2['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "mean1=np.std(y)\n",
    "Rmse7_rf2=[]\n",
    "RMSE7_rf2=[]\n",
    "M72=[]\n",
    "B72=[]\n",
    "for i in range(1,8):\n",
    "    regressor.fit(X_train[:120*i], y_train[:120*i])\n",
    "    pred=regressor.predict(X_train[120*i:])\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    #mse=round(relative_mean_absolute_error(y_test,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[120*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[120*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.25*np.array(y_train[120*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[120*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-100:])\n",
    "    p=precision(Pred,y_train[X_train.shape[0]-100:])\n",
    "    M72.append(p)\n",
    "    b=bias(Pred,y_train[X_train.shape[0]-100:])\n",
    "    B72.append(b)\n",
    "    Rmse7_rf2.append(mse)\n",
    "    RMSE7_rf2.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse7_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE7_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "M72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1=[data_oct3,data_nov3]\n",
    "fall3=pd.concat(frame1)\n",
    "#fall=fall.sample(frac=1)\n",
    "Day=[5*i for i in range(1,11) ]\n",
    "Fall3=fall3.resample('h').mean()\n",
    "Fall3=Fall3.dropna()\n",
    "#Fall=Fall.sample(frac=1)\n",
    "X=Fall3[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_NO2']]\n",
    "y=Fall3['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001,shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "mean1=np.std(y)\n",
    "Rmse7_rf3=[]\n",
    "RMSE7_rf3=[]\n",
    "M73=[]\n",
    "B73=[]\n",
    "for i in range(1,8):\n",
    "    regressor.fit(X_train[:120*i], y_train[:120*i])\n",
    "    pred=regressor.predict(X_train[120*i:])\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    #mse=round(relative_mean_absolute_error(y_test,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[120*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[120*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.3*np.array(y_train[120*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[120*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-100:])\n",
    "    p=precision(Pred,y_train[X_train.shape[0]-100:])\n",
    "    M73.append(p)\n",
    "    b=bias(Pred,y_train[X_train.shape[0]-100:])\n",
    "    B73.append(b)\n",
    "    Rmse7_rf3.append(mse)\n",
    "    RMSE7_rf3.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse7_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE7_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "M73"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-maldives",
   "metadata": {},
   "source": [
    "# Winter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-distribution",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1=[data_dec,data_jan]#,data_feb\n",
    "winter=pd.concat(frame1)\n",
    "#winter=winter.sample(frac=1)\n",
    "Winter=winter.resample('h').mean()\n",
    "Winter=Winter.dropna()\n",
    "#Winter=Winter.sample(frac=1)\n",
    "X=Winter[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour']]\n",
    "y=Winter['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "mean2=np.std(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse8_rf=[]\n",
    "RMSE8_rf=[]\n",
    "REU8=[]\n",
    "L_y8=[]\n",
    "A8=[]\n",
    "M8=[]\n",
    "B8=[]\n",
    "for i in range(1,8):\n",
    "    k=y_train[120*i:].to_list()\n",
    "    lv=max(y_train[120*i:])\n",
    "    regressor.fit(X_train[:120*i], y_train[:120*i])\n",
    "    pred=regressor.predict(X_train[120*i:])\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    #mse=round(relative_mean_absolute_error(y_test,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[120*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[120*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.25*np.array(y_train[120*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[120*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-100:])\n",
    "    p=precision(Pred,y_train[X_train.shape[0]-100:])\n",
    "    M8.append(p)\n",
    "    b=bias(Pred,y_train[X_train.shape[0]-100:])\n",
    "    B8.append(b)\n",
    "    Rmse8_rf.append(mse)\n",
    "    RMSE8_rf.append(rmse)\n",
    "    reu=REF(pred,y_train[120*i:],1)\n",
    "    re=REF2(pred,y_train[120*i:],1,lv)\n",
    "    A8.append(re)\n",
    "    REU8.append(reu)\n",
    "    L_y8.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse8_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE8_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "M8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1=[data_dec2,data_jan2,data_feb2]\n",
    "winter2=pd.concat(frame1)\n",
    "#winter=winter.sample(frac=1)\n",
    "Winter2=winter2.resample('h').mean()\n",
    "Winter2=Winter2.dropna()\n",
    "X=Winter2[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_O3']]\n",
    "y=Winter2['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "mean2=np.std(y)\n",
    "Rmse8_rf2=[]\n",
    "RMSE8_rf2=[]\n",
    "M82=[]\n",
    "B82=[]\n",
    "for i in range(1,8):\n",
    "    \n",
    "    regressor.fit(X_train[:120*i], y_train[:120*i])\n",
    "    pred=regressor.predict(X_train[120*i:])\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    #mse=round(relative_mean_absolute_error(y_test,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[120*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[120*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.25*np.array(y_train[120*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[120*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-100:])\n",
    "    p=precision(Pred,y_train[X_train.shape[0]-100:])\n",
    "    M82.append(p)\n",
    "    b=bias(Pred,y_train[X_train.shape[0]-100:])\n",
    "    B82.append(b)\n",
    "    Rmse8_rf2.append(mse)\n",
    "    RMSE8_rf2.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse8_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE8_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "M82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1=[data_dec3,data_jan3,data_feb3]\n",
    "winter3=pd.concat(frame1)\n",
    "#winter=winter.sample(frac=1)\n",
    "Winter3=winter3.resample('h').mean()\n",
    "Winter3=Winter3.dropna()\n",
    "X=Winter3[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_NO2']]\n",
    "y=Winter3['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "mean2=np.std(y)\n",
    "Rmse8_rf3=[]\n",
    "RMSE8_rf3=[]\n",
    "M83=[]\n",
    "B83=[]\n",
    "for i in range(1,9):\n",
    "    \n",
    "    regressor.fit(X_train[:120*i], y_train[:120*i])\n",
    "    pred=regressor.predict(X_train[120*i:])\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    #mse=round(relative_mean_absolute_error(y_test,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[120*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[120*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.3*np.array(y_train[120*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[120*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-100:])\n",
    "    p=precision(Pred,y_train[X_train.shape[0]-100:])\n",
    "    M83.append(p)\n",
    "    b=bias(Pred,y_train[X_train.shape[0]-100:])\n",
    "    B83.append(b)\n",
    "    Rmse8_rf3.append(mse)\n",
    "    RMSE8_rf3.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse8_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE8_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "M83"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-general",
   "metadata": {},
   "source": [
    "# Spring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-consequence",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1=[data_mar,data_apr]\n",
    "spring=pd.concat(frame1)\n",
    "Spring=spring.resample('h').mean()\n",
    "Spring=Spring.dropna()\n",
    "#Spring=Spring.sample(frac=1)\n",
    "X=Spring[['Net Signal','Temp1','RH1','Month','Day_of_week','Day','Hour']]\n",
    "y=Spring['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "mean3=np.std(y)\n",
    "Rmse9_rf=[]\n",
    "RMSE9_rf=[]\n",
    "REU9=[]\n",
    "L_y9=[]\n",
    "A9=[]\n",
    "M9=[]\n",
    "B9=[]\n",
    "for i in range(1,8):\n",
    "    k=y_train[120*i:].to_list()\n",
    "    lv=20000\n",
    "    regressor.fit(X_train[:120*i], y_train[:120*i])\n",
    "    pred=regressor.predict(X_train[120*i:])\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    #mse=round(relative_mean_absolute_error(y,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[120*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[120*i:], pred), 2)\n",
    "    Rmse9_rf.append(mse)\n",
    "    RMSE9_rf.append(rmse)\n",
    "    U=np.sqrt(np.mean((0.25*np.array(y_train[120*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[120*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-100:])\n",
    "    p=precision(Pred,y_train[X_train.shape[0]-100:])\n",
    "    M9.append(p)\n",
    "    b=bias(Pred,y_train[X_train.shape[0]-100:])\n",
    "    B9.append(b)\n",
    "    reu=REF(pred,y_train[120*i:],1)\n",
    "    re=REF2(pred,y_train[120*i:],1,lv)\n",
    "    A9.append(re)\n",
    "    REU9.append(reu)\n",
    "    L_y9.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse9_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE9_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "M9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1=[data_mar2,data_apr2]\n",
    "spring2=pd.concat(frame1)\n",
    "Spring2=spring2.resample('h').mean()\n",
    "Spring2=Spring2.dropna()\n",
    "#Spring=Spring.sample(frac=1)\n",
    "X=Spring2[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_O3']]\n",
    "y=Spring2['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "mean3=np.std(y)\n",
    "Rmse9_rf2=[]\n",
    "RMSE9_rf2=[]\n",
    "M92=[]\n",
    "B92=[]\n",
    "for i in range(1,8):\n",
    "    regressor.fit(X_train[:120*i], y_train[:120*i])\n",
    "    pred=regressor.predict(X_train[120*i:])\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    #mse=round(relative_mean_absolute_error(y,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[120*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[120*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.25*np.array(y_train[120*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[120*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-100:])\n",
    "    p=precision(Pred,y_train[X_train.shape[0]-100:])\n",
    "    M92.append(p)\n",
    "    b=bias(Pred,y_train[X_train.shape[0]-100:])\n",
    "    B92.append(b)\n",
    "    Rmse9_rf2.append(mse)\n",
    "    RMSE9_rf2.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmse9_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE9_rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "M92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1=[data_mar3,data_apr3]\n",
    "spring3=pd.concat(frame1)\n",
    "Spring3=spring3.resample('h').mean()\n",
    "Spring3=Spring3.dropna()\n",
    "#Spring=Spring.sample(frac=1)\n",
    "X=Spring3[['Net Signal','Temp','RH','Month','Day_of_week','Day','Hour','Ref_NO2']]\n",
    "y=Spring3['Ref']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.001, shuffle=False)\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    "mean3=np.std(y)\n",
    "Rmse9_rf3=[]\n",
    "RMSE9_rf3=[]\n",
    "M93=[]\n",
    "B93=[]\n",
    "for i in range(1,8):\n",
    "    regressor.fit(X_train[:120*i], y_train[:120*i])\n",
    "    pred=regressor.predict(X_train[120*i:])\n",
    "    #mse=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y_test),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    #mse=round(relative_mean_absolute_error(y,pred),2)\n",
    "    #rmse=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "    mse=round(sMAE(y_train[120*i:], pred),2)\n",
    "    rmse=round(sm.r2_score(y_train[120*i:], pred), 2)\n",
    "    U=np.sqrt(np.mean((0.3*np.array(y_train[120*i:]))**2))\n",
    "    RMSE=np.sqrt(np.mean((np.array(pred)-np.array(y_train[120*i:]))**2))\n",
    "    m=RMSE/(1*U)\n",
    "    Pred=regressor.predict(X_train[X_train.shape[0]-100:])\n",
    "    p=precision(Pred,y_train[X_train.shape[0]-100:])\n",
    "    M93.append(p)\n",
    "    b=bias(Pred,y_train[X_train.shape[0]-100:])\n",
    "    B93.append(b)\n",
    "    Rmse9_rf3.append(mse)\n",
    "    RMSE9_rf3.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    " Rmse9_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-product",
   "metadata": {},
   "outputs": [],
   "source": [
    " RMSE9_rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-village",
   "metadata": {},
   "outputs": [],
   "source": [
    " M93"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-digit",
   "metadata": {},
   "source": [
    "#import chart_studio\n",
    "import plotly.express as px\n",
    "from IPython.display import Image\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "Day_1_rf=[RMSE7_rf[0],RMSE8_rf[0],RMSE9_rf[0]]\n",
    "Day_2_rf=[RMSE7_rf[1],RMSE8_rf[1],RMSE9_rf[1]]\n",
    "Day_3_rf=[RMSE7_rf[2],RMSE8_rf[2],RMSE9_rf[2]]\n",
    "Day_4_rf=[RMSE7_rf[3],RMSE8_rf[3],RMSE9_rf[3]]\n",
    "Day_5_rf=[RMSE7_rf[4],RMSE8_rf[4],RMSE9_rf[4]]\n",
    "Day_6_rf=[RMSE7_rf[5],RMSE8_rf[5],RMSE9_rf[5]]\n",
    "Day_7_rf=[RMSE7_rf[6],RMSE8_rf[6],RMSE9_rf[6]]\n",
    "Day_8_rf=[RMSE7_rf[7],RMSE8_rf[7],RMSE9_rf[7]]\n",
    "#Day_9_rf=[RMSE7_rf[8],RMSE8_rf[8],RMSE9_rf[8]]\n",
    "#Day_10_rf=[RMSE7_rf[9],RMSE8_rf[9],RMSE9_rf[9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-sharp",
   "metadata": {},
   "source": [
    "Day_1_ann=[RMSE7_ann[0],RMSE8_ann[0],RMSE9_ann[0]]\n",
    "Day_2_ann=[RMSE7_ann[1],RMSE8_ann[1],RMSE9_ann[1]]\n",
    "Day_3_ann=[RMSE7_ann[2],RMSE8_ann[2],RMSE9_ann[2]]\n",
    "Day_4_ann=[RMSE7_ann[3],RMSE8_ann[3],RMSE9_ann[3]]\n",
    "Day_5_ann=[RMSE7_ann[4],RMSE8_ann[4],RMSE9_ann[4]]\n",
    "Day_6_ann=[RMSE7_ann[5],RMSE8_ann[5],RMSE9_ann[5]]\n",
    "Day_7_ann=[RMSE7_ann[6],RMSE8_ann[6],RMSE9_ann[6]]\n",
    "Day_8_ann=[RMSE7_ann[7],RMSE8_ann[7],RMSE9_ann[7]]\n",
    "Day_9_ann=[RMSE7_ann[8],RMSE8_ann[8],RMSE9_ann[8]]\n",
    "Day_10_ann=[RMSE7_ann[9],RMSE8_ann[9],RMSE9_ann[9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-approach",
   "metadata": {},
   "source": [
    "Day_1_RF=[Rmse7_rf[0],Rmse8_rf[0],Rmse9_rf[0]]\n",
    "Day_2_RF=[Rmse7_rf[1],Rmse8_rf[1],Rmse9_rf[1]]\n",
    "Day_3_RF=[Rmse7_rf[2],Rmse8_rf[2],Rmse9_rf[2]]\n",
    "Day_4_RF=[Rmse7_rf[3],Rmse8_rf[3],Rmse9_rf[3]]\n",
    "Day_5_RF=[Rmse7_rf[4],Rmse8_rf[4],Rmse9_rf[4]]\n",
    "Day_6_RF=[Rmse7_rf[5],Rmse8_rf[5],Rmse9_rf[5]]\n",
    "Day_7_RF=[Rmse7_rf[6],Rmse8_rf[6],Rmse9_rf[6]]\n",
    "Day_8_RF=[Rmse7_rf[7],Rmse8_rf[7],Rmse9_rf[7]]\n",
    "#Day_9_RF=[Rmse7_rf[8],Rmse8_rf[8],Rmse9_rf[8]]\n",
    "#Day_10_RF=[Rmse7_rf[9],Rmse8_rf[9],Rmse9_rf[9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-luther",
   "metadata": {},
   "source": [
    "Day_1_RF2=[Rmse7_rf2[0],Rmse8_rf2[0],Rmse9_rf2[0]]\n",
    "Day_2_RF2=[Rmse7_rf2[1],Rmse8_rf2[1],Rmse9_rf2[1]]\n",
    "Day_3_RF2=[Rmse7_rf2[2],Rmse8_rf2[2],Rmse9_rf2[2]]\n",
    "Day_4_RF2=[Rmse7_rf2[3],Rmse8_rf2[3],Rmse9_rf2[3]]\n",
    "Day_5_RF2=[Rmse7_rf2[4],Rmse8_rf2[4],Rmse9_rf2[4]]\n",
    "Day_6_RF2=[Rmse7_rf2[5],Rmse8_rf2[5],Rmse9_rf2[5]]\n",
    "Day_7_RF2=[Rmse7_rf2[6],Rmse8_rf2[6],Rmse9_rf2[6]]\n",
    "Day_8_RF2=[Rmse7_rf2[7],Rmse8_rf2[7],Rmse9_rf2[7]]\n",
    "#Day_9_RF=[Rmse7_rf[8],Rmse8_rf[8],Rmse9_rf[8]]\n",
    "#Day_10_RF=[Rmse7_rf[9],Rmse8_rf[9],Rmse9_rf[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import chart_studio\n",
    "import plotly.express as px\n",
    "from IPython.display import Image\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "Day_1_MQI=[M7[0],M8[0],M9[0]]\n",
    "Day_2_MQI=[M7[1],M8[1],M9[1]]\n",
    "Day_3_MQI=[M7[2],M8[2],M9[2]]\n",
    "Day_4_MQI=[M7[3],M8[3],M9[3]]\n",
    "Day_5_MQI=[M7[4],M8[4],M9[4]]\n",
    "Day_6_MQI=[M7[5],M8[5],M9[5]]\n",
    "Day_7_MQI=[M7[6],M8[6],M9[6]]\n",
    "#Day_8_MQI=[M7[7],M8[7],M9[7]]\n",
    "\n",
    "Day_1_BQI=[B7[0],B8[0],B9[0]]\n",
    "Day_2_BQI=[B7[1],B8[1],B9[1]]\n",
    "Day_3_BQI=[B7[2],B8[2],B9[2]]\n",
    "Day_4_BQI=[B7[3],B8[3],B9[3]]\n",
    "Day_5_BQI=[B7[4],B8[4],B9[4]]\n",
    "Day_6_BQI=[B7[5],B8[5],B9[5]]\n",
    "Day_7_BQI=[B7[6],B8[6],B9[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "Day_1_MQI2=[M72[0],M82[0],M92[0]]\n",
    "Day_2_MQI2=[M72[1],M82[1],M92[1]]\n",
    "Day_3_MQI2=[M72[2],M82[2],M92[2]]\n",
    "Day_4_MQI2=[M72[3],M82[3],M92[3]]\n",
    "Day_5_MQI2=[M72[4],M82[4],M92[4]]\n",
    "Day_6_MQI2=[M72[5],M82[5],M92[5]]\n",
    "Day_7_MQI2=[M72[6],M82[6],M92[6]]\n",
    "#Day_8_MQI2=[M72[7],M92[7],M92[7]]\n",
    "\n",
    "Day_1_BQI2=[B72[0],B82[0],B92[0]]\n",
    "Day_2_BQI2=[B72[1],B82[1],B92[1]]\n",
    "Day_3_BQI2=[B72[2],B82[2],B92[2]]\n",
    "Day_4_BQI2=[B72[3],B82[3],B92[3]]\n",
    "Day_5_BQI2=[B72[4],B82[4],B92[4]]\n",
    "Day_6_BQI2=[B72[5],B82[5],B92[5]]\n",
    "Day_7_BQI2=[B72[6],B82[6],B92[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "Day_1_MQI3=[M73[0],M83[0],M93[0]]\n",
    "Day_2_MQI3=[M73[1],M83[1],M93[1]]\n",
    "Day_3_MQI3=[M73[2],M83[2],M93[2]]\n",
    "Day_4_MQI3=[M73[3],M83[3],M93[3]]\n",
    "Day_5_MQI3=[M73[4],M83[4],M93[4]]\n",
    "Day_6_MQI3=[M73[5],M83[5],M93[5]]\n",
    "Day_7_MQI3=[M73[6],M83[6],M93[6]]\n",
    "#Day_8_MQI2=[M72[7],M92[7],M92[7]]\n",
    "\n",
    "Day_1_BQI3=[B73[0],B83[0],B93[0]]\n",
    "Day_2_BQI3=[B73[1],B83[1],B93[1]]\n",
    "Day_3_BQI3=[B73[2],B83[2],B93[2]]\n",
    "Day_4_BQI3=[B73[3],B83[3],B93[3]]\n",
    "Day_5_BQI3=[B73[4],B83[4],B93[4]]\n",
    "Day_6_BQI3=[B73[5],B83[5],B93[5]]\n",
    "Day_7_BQI3=[B73[6],B83[6],B93[6]]\n",
    "#Day_8_MQI2=[M72[7],M92[7],M92[7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-opera",
   "metadata": {},
   "source": [
    "Day_1_ANN=[Rmse7_ann[0],Rmse8_ann[0],Rmse9_ann[0]]\n",
    "Day_2_ANN=[Rmse7_ann[1],Rmse8_ann[1],Rmse9_ann[1]]\n",
    "Day_3_ANN=[Rmse7_ann[2],Rmse8_ann[2],Rmse9_ann[2]]\n",
    "Day_4_ANN=[Rmse7_ann[3],Rmse8_ann[3],Rmse9_ann[3]]\n",
    "Day_5_ANN=[Rmse7_ann[4],Rmse8_ann[4],Rmse9_ann[4]]\n",
    "Day_6_ANN=[Rmse7_ann[5],Rmse8_ann[5],Rmse9_ann[5]]\n",
    "Day_7_ANN=[Rmse7_ann[6],Rmse8_ann[6],Rmse9_ann[6]]\n",
    "Day_8_ANN=[Rmse7_ann[7],Rmse8_ann[7],Rmse9_ann[7]]\n",
    "Day_9_ANN=[Rmse7_ann[8],Rmse8_ann[8],Rmse9_ann[8]]\n",
    "Day_10_ANN=[Rmse7_ann[9],Rmse8_ann[9],Rmse9_ann[9]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF_P=Day_1_rf+Day_2_rf+Day_3_rf+Day_4_rf+Day_5_rf+Day_6_rf+Day_7_rf+Day_8_rf\n",
    "#XGBoost_P=Day_1_ann+Day_2_ann+Day_3_ann+Day_4_ann+Day_5_ann+Day_6_ann+Day_7_ann+Day_8_ann+Day_9_ann+Day_10_ann\n",
    "#RF_R=Day_1_RF+Day_2_RF+Day_3_RF+Day_4_RF+Day_5_RF+Day_6_RF+Day_7_RF+Day_8_RF\n",
    "#RF_R2=Day_1_RF2+Day_2_RF2+Day_3_RF2+Day_4_RF2+Day_5_RF2+Day_6_RF2+Day_7_RF2+Day_8_RF2\n",
    "#XGBoost_R=Day_1_ANN+Day_2_ANN+Day_3_ANN+Day_4_ANN+Day_5_ANN+Day_6_ANN+Day_7_ANN+Day_8_ANN+Day_9_ANN+Day_10_ANN\n",
    "MQI=Day_1_MQI+Day_2_MQI+Day_3_MQI+Day_4_MQI+Day_5_MQI+Day_6_MQI+Day_7_MQI#+Day_8_MQI\n",
    "MQI2=Day_1_MQI2+Day_2_MQI2+Day_3_MQI2+Day_4_MQI2+Day_5_MQI2+Day_6_MQI2+Day_7_MQI2#+Day_8_MQI2\n",
    "MQI3=Day_1_MQI3+Day_2_MQI3+Day_3_MQI3+Day_4_MQI3+Day_5_MQI3+Day_6_MQI3+Day_7_MQI3\n",
    "\n",
    "BQI=Day_1_BQI+Day_2_BQI+Day_3_BQI+Day_4_BQI+Day_5_BQI+Day_6_BQI+Day_7_BQI#+Day_8_MQI\n",
    "BQI2=Day_1_BQI2+Day_2_BQI2+Day_3_BQI2+Day_4_BQI2+Day_5_BQI2+Day_6_BQI2+Day_7_BQI2#+Day_8_MQI2\n",
    "BQI3=Day_1_BQI3+Day_2_BQI3+Day_3_BQI3+Day_4_BQI3+Day_5_BQI3+Day_6_BQI3+Day_7_BQI3\n",
    "x0=['0' for i in range(3)]\n",
    "x1=['5' for i in range(3)]\n",
    "x2=['10' for i in range(3)]\n",
    "x3=['15' for i in range(3)]\n",
    "x4=['20' for i in range(3)]\n",
    "x5=['25' for i in range(3)]\n",
    "x6=['30' for i in range(3)]\n",
    "x7=['35' for i in range(3)]\n",
    "x8=['40' for i in range(3)]\n",
    "x9=['45' for i in range(3)]\n",
    "\n",
    "Reg=[10 for i in range(30)]\n",
    "Spatial=[25 for i in range(30) ]\n",
    "Intervention=[30 for i in range(30) ]\n",
    "Hs_and_sp=[50 for i in range(30) ]\n",
    "\n",
    "\n",
    "x=x1+x2+x3+x4+x5+x6+x7\n",
    "X=x0+x1+x2+x3+x4+x5+x6+x7+x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio\n",
    "fig = go.Figure() \n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([1, 3, 2, 3, 1])\n",
    "# Defining x axis\n",
    "x = x\n",
    "\n",
    "\n",
    "fig.add_trace(go.Box(\n",
    "  \n",
    "    # defining y axis in corresponding\n",
    "    # to x-axis\n",
    "    y=MQI,\n",
    "    x=x,\n",
    "    name='Accuracy',\n",
    "    marker_color='#8470FF',\n",
    "    showlegend=False\n",
    "   \n",
    "))\n",
    "#fig.add_trace(go.Box(\n",
    "  \n",
    "    # defining y axis in corresponding\n",
    "    # to x-axis\n",
    "    #y=MQI3,\n",
    "    #x=x,\n",
    "    #name=r'$O_3$',\n",
    "    #marker_color='#FF8000',\n",
    "    #showlegend=False\n",
    "   \n",
    "#))\n",
    "\n",
    "\n",
    "fig.add_trace(go.Box(\n",
    "  \n",
    "    # defining y axis in corresponding\n",
    "    # to x-axis\n",
    "    y=BQI,\n",
    "    x=x,\n",
    "    name='Bias',\n",
    "    marker_color='#FF8000',\n",
    "    showlegend=False\n",
    "   \n",
    "))\n",
    "\n",
    "#fig.add_trace(go.Box(\n",
    "  \n",
    "    #defining y axis in corresponding\n",
    "   # to x-axis\n",
    "    #y=RF_R,\n",
    "    #x=x,\n",
    "    #name='SMAE',\n",
    "    #marker_color='olive',\n",
    "   # showlegend=True\n",
    "   \n",
    "#))\n",
    "#fig.add_trace(go.Box(\n",
    "   #y=ANN_R,\n",
    "    #x=x,\n",
    "    #name='XGBoost(NMAE)',\n",
    "    #marker_color='orangered',\n",
    "    #showlegend=True\n",
    "\n",
    "\n",
    "#))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(autosize=True,\n",
    "                 title={'text':r\"$O_3$\",\n",
    "        'y':0.77,\n",
    "        'x':0.5,\n",
    "        #'xanchor': 'center',\n",
    "        #'yanchor': 'top'\n",
    "                       }, \n",
    "    width=430,\n",
    "    height=400,\n",
    "                  \n",
    "  legend=dict( yanchor=\"bottom\",\n",
    "    y=0.5,\n",
    "    x=0.6,\n",
    "    \n",
    "    orientation=\"v\"\n",
    "),\n",
    "             \n",
    "    # group together boxes of the different\n",
    "    # traces for each value of x\n",
    "    boxmode='group',\n",
    "                  plot_bgcolor='rgba(0,0,0,0)'\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Days of training\",tickfont = dict(size=16),\n",
    "                 titlefont = dict(size=24),linewidth=1.4, linecolor='black',tick0 = 5,\n",
    "        dtick = 5,mirror=True)\n",
    "fig.update_yaxes(title_text=\"Performance(%)\",range=[0,100],tickfont = dict(size=16),titlefont = dict(size=24),\n",
    "                 linewidth=1.4, linecolor='black',tick0 = 20,\n",
    "        dtick = 20,mirror=True)\n",
    "fig.show()\n",
    "chart_studio.plotly.sign_in('vinylango', 'gybbJVWfRSUoTcRRSa6J')\n",
    "chart_studio.plotly.image.save_as(fig, filename='models_boxplot.png')\n",
    "#Image('models_boxplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-intro",
   "metadata": {},
   "source": [
    "fig.add_trace(go.Scatter(x=X,\n",
    "                y=Reg, \n",
    "                name=\"RC\",\n",
    "                mode = 'lines',\n",
    "                #marker_color='dodgerblue',\n",
    "                line = dict(shape = 'linear',width = 2, color = 'green', dash = 'dot'),\n",
    "                connectgaps = True,\n",
    "                showlegend=False\n",
    "                        ))\n",
    "fig.add_trace(go.Scatter(x=X,\n",
    "                y=Spatial, \n",
    "                name=\"SGS\",\n",
    "                mode = 'lines',\n",
    "                #marker_color='dodgerblue',\n",
    "                line = dict(shape = 'linear',width = 2, color = 'purple', dash = 'dot'),\n",
    "                connectgaps = True,\n",
    "                showlegend=False\n",
    "                    \n",
    "                        ))\n",
    "fig.add_trace(go.Scatter(x=X,\n",
    "                y=Intervention, \n",
    "                name=\"IS/IM\",\n",
    "                mode = 'lines',\n",
    "                #marker_color='dodgerblue',\n",
    "                line = dict(shape = 'linear',width = 2, color = 'orange', dash = 'dot'),\n",
    "                connectgaps = True,\n",
    "                showlegend=False\n",
    "                \n",
    "                        ))\n",
    "fig.add_trace(go.Scatter(x=X,\n",
    "                y=Hs_and_sp, \n",
    "                name=\"HA/SP\",\n",
    "                    \n",
    "                mode = 'lines',\n",
    "                #marker_color='dodgerblue',\n",
    "                line = dict(shape = 'linear',width = 2, color = 'dodgerblue', dash = 'dot'),\n",
    "                connectgaps = True,\n",
    "                showlegend=False\n",
    "               \n",
    "                        ))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-elite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-traveler",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
