{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thick-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import MultiIndex, Int16Dtype\n",
    "Ref=pd.read_csv('Ref.csv')\n",
    "Ref[\"CO\"] = 1000 * Ref[\"CO\"]\n",
    "Ref['Date'] = pd.to_datetime(Ref['Date_Time'])\n",
    "Ref=Ref.set_index('Date')\n",
    "Ref.drop('Date_Time',axis = 1, inplace = True)\n",
    "Ref=Ref.resample('5min').mean()\n",
    "Ref=Ref[76463:137376]\n",
    "Ref_CO=Ref['CO'].to_list()\n",
    "Ref_NO2=Ref['NO2'].to_list()\n",
    "Ref_SO2=Ref['SO2'].to_list()\n",
    "Ref_O3=Ref['O3'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "premier-edward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab1</th>\n",
       "      <th>Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Net Signal</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-30 19:00:00</th>\n",
       "      <td>242.060716</td>\n",
       "      <td>18.870796</td>\n",
       "      <td>71.072939</td>\n",
       "      <td>188.915151</td>\n",
       "      <td>91.471325</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30 20:00:00</th>\n",
       "      <td>218.655079</td>\n",
       "      <td>18.056864</td>\n",
       "      <td>75.132153</td>\n",
       "      <td>178.704750</td>\n",
       "      <td>84.176485</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30 21:00:00</th>\n",
       "      <td>194.147868</td>\n",
       "      <td>17.090891</td>\n",
       "      <td>81.315038</td>\n",
       "      <td>161.421792</td>\n",
       "      <td>73.858294</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30 22:00:00</th>\n",
       "      <td>206.432889</td>\n",
       "      <td>16.714085</td>\n",
       "      <td>82.568155</td>\n",
       "      <td>197.744043</td>\n",
       "      <td>83.279611</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30 23:00:00</th>\n",
       "      <td>173.577429</td>\n",
       "      <td>16.365121</td>\n",
       "      <td>83.662401</td>\n",
       "      <td>162.157636</td>\n",
       "      <td>68.669099</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Lab1       Temp         RH         Ref  Net Signal  \\\n",
       "Date                                                                            \n",
       "2020-04-30 19:00:00  242.060716  18.870796  71.072939  188.915151   91.471325   \n",
       "2020-04-30 20:00:00  218.655079  18.056864  75.132153  178.704750   84.176485   \n",
       "2020-04-30 21:00:00  194.147868  17.090891  81.315038  161.421792   73.858294   \n",
       "2020-04-30 22:00:00  206.432889  16.714085  82.568155  197.744043   83.279611   \n",
       "2020-04-30 23:00:00  173.577429  16.365121  83.662401  162.157636   68.669099   \n",
       "\n",
       "                     Month  Day_of_week   Day  Hour  \n",
       "Date                                                 \n",
       "2020-04-30 19:00:00    4.0          3.0  30.0  19.0  \n",
       "2020-04-30 20:00:00    4.0          3.0  30.0  20.0  \n",
       "2020-04-30 21:00:00    4.0          3.0  30.0  21.0  \n",
       "2020-04-30 22:00:00    4.0          3.0  30.0  22.0  \n",
       "2020-04-30 23:00:00    4.0          3.0  30.0  23.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('CO.txt', header = None,low_memory=False)\n",
    "data.columns=['WE','AE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_CO=data\n",
    "Data_CO['Ref']=Ref_CO\n",
    "index_names = Data_CO[ (Data_CO['WE'] >1000)].index\n",
    "Data_CO.drop(index_names, inplace = True)\n",
    "WE=Data_CO['WE'].to_list()\n",
    "AE=Data_CO['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_CO['Net Signal']=signal\n",
    "Data_CO['Month']=Data_CO.index.month\n",
    "Data_CO['Day_of_week']=Data_CO.index.dayofweek\n",
    "Data_CO['Day']=Data_CO.index.day\n",
    "Data_CO['Hour']=Data_CO.index.hour\n",
    "CO_Data=Data_CO\n",
    "CO_Data=CO_Data[(CO_Data[CO_Data.columns] >= 0).all(axis=1)]\n",
    "CO_Data=CO_Data.dropna()\n",
    "data = pd.read_csv('Conc_CO.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab1','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_CO=data\n",
    "Data_CO.drop(index_names, inplace = True)\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_CO['Net Signal']=signal\n",
    "Data_CO['Month']=Data_CO.index.month\n",
    "Data_CO['Day_of_week']=Data_CO.index.dayofweek\n",
    "Data_CO['Day']=Data_CO.index.day\n",
    "Data_CO['Hour']=Data_CO.index.hour\n",
    "CO_Data=Data_CO\n",
    "CO_Data=CO_Data[(CO_Data[CO_Data.columns] >= 0).all(axis=1)]\n",
    "CO_Data=CO_Data.dropna()\n",
    "CO_Data=CO_Data.resample('h').mean()\n",
    "CO_Data=CO_Data.dropna()\n",
    "CO_Data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prime-morning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60913"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('O3.txt', header = None,low_memory=False)\n",
    "data.columns=['AE','WE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_O3=data\n",
    "Data_O3['Ref']=Ref_O3\n",
    "WE=Data_O3['WE'].to_list()\n",
    "AE=Data_O3['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_O3['Net Signal']=signal\n",
    "Data_O3['Month']=Data_O3.index.month\n",
    "Data_O3['Day_of_week']=Data_O3.index.dayofweek\n",
    "Data_O3['Day']=Data_O3.index.day\n",
    "Data_O3['Hour']=Data_O3.index.hour\n",
    "O3_Data=Data_O3\n",
    "O3_Data=O3_Data[(O3_Data[O3_Data.columns] >= 0).all(axis=1)]\n",
    "O3_Data=O3_Data.dropna()\n",
    "data = pd.read_csv('Conc_O3.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab1','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_O3=data\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_O3['Net Signal']=signal\n",
    "Data_O3['Month']=Data_O3.index.month\n",
    "Data_O3['Day_of_week']=Data_O3.index.dayofweek\n",
    "Data_O3['Day']=Data_O3.index.day\n",
    "Data_O3['Hour']=Data_O3.index.hour\n",
    "O3_Data=Data_O3\n",
    "O3_Data=O3_Data[(O3_Data[O3_Data.columns] >= 0).all(axis=1)]\n",
    "O3_Data=O3_Data.dropna() \n",
    "O3_Data=O3_Data.resample('h').mean()\n",
    "O3_Data=O3_Data.dropna()\n",
    "O3_Data.head()\n",
    "\n",
    "ref_O3=Data_O3['Ref'].to_list()\n",
    "len(ref_O3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "underlying-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('NO2.txt', header = None,low_memory=False)\n",
    "data.columns=['WE','AE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_NO2=data\n",
    "Data_NO2['Ref']=Ref_NO2\n",
    "WE=Data_NO2['WE'].to_list()\n",
    "AE=Data_NO2['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_NO2['Net Signal']=signal\n",
    "Data_NO2['Month']=Data_NO2.index.month\n",
    "Data_NO2['Day_of_week']=Data_NO2.index.dayofweek\n",
    "Data_NO2['Day']=Data_NO2.index.day\n",
    "Data_NO2['Hour']=Data_NO2.index.hour\n",
    "NO2_Data=Data_NO2\n",
    "NO2_Data=NO2_Data[(NO2_Data[NO2_Data.columns] >= 0).all(axis=1)]\n",
    "NO2_Data=NO2_Data.dropna()\n",
    "data = pd.read_csv('Conc_NO2.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab1','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "subscript = str.maketrans(\"0123456789\", \"₀₁₂₃₄₅₆₇₈₉\") \n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_NO2=data\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_NO2['Net Signal']=signal\n",
    "Data_NO2['Month']=Data_NO2.index.month\n",
    "Data_NO2['Day_of_week']=Data_NO2.index.dayofweek\n",
    "Data_NO2['Day']=Data_NO2.index.day\n",
    "Data_NO2['Hour']=Data_NO2.index.hour\n",
    "Data_NO2['Ref_O3']=ref_O3\n",
    "NO2_Data=Data_NO2\n",
    "NO2_Data=NO2_Data[(NO2_Data[NO2_Data.columns] >= 0).all(axis=1)]\n",
    "NO2_Data=NO2_Data.dropna()\n",
    "NO2_Data=NO2_Data.resample('h').mean()\n",
    "NO2_Data=NO2_Data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lyric-fifteen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab1</th>\n",
       "      <th>Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Net Signal</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Ref_NO2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-02 11:00:00</th>\n",
       "      <td>621.625704</td>\n",
       "      <td>26.378438</td>\n",
       "      <td>58.063437</td>\n",
       "      <td>46.094860</td>\n",
       "      <td>3.605625</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.230400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02 12:00:00</th>\n",
       "      <td>725.154408</td>\n",
       "      <td>25.795055</td>\n",
       "      <td>48.256857</td>\n",
       "      <td>57.532808</td>\n",
       "      <td>13.865109</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.384051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-07 10:00:00</th>\n",
       "      <td>108.196313</td>\n",
       "      <td>32.344264</td>\n",
       "      <td>37.260757</td>\n",
       "      <td>47.259008</td>\n",
       "      <td>11.447809</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.255772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-07 11:00:00</th>\n",
       "      <td>135.822676</td>\n",
       "      <td>34.926112</td>\n",
       "      <td>35.013036</td>\n",
       "      <td>42.114260</td>\n",
       "      <td>10.075221</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.268034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-07 12:00:00</th>\n",
       "      <td>203.757758</td>\n",
       "      <td>36.201221</td>\n",
       "      <td>31.829282</td>\n",
       "      <td>45.701366</td>\n",
       "      <td>7.624153</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.770444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Lab1       Temp         RH        Ref  Net Signal  \\\n",
       "Date                                                                           \n",
       "2019-10-02 11:00:00  621.625704  26.378438  58.063437  46.094860    3.605625   \n",
       "2019-10-02 12:00:00  725.154408  25.795055  48.256857  57.532808   13.865109   \n",
       "2019-10-07 10:00:00  108.196313  32.344264  37.260757  47.259008   11.447809   \n",
       "2019-10-07 11:00:00  135.822676  34.926112  35.013036  42.114260   10.075221   \n",
       "2019-10-07 12:00:00  203.757758  36.201221  31.829282  45.701366    7.624153   \n",
       "\n",
       "                     Month  Day_of_week  Day  Hour    Ref_NO2  \n",
       "Date                                                           \n",
       "2019-10-02 11:00:00   10.0          2.0  2.0  11.0  15.230400  \n",
       "2019-10-02 12:00:00   10.0          2.0  2.0  12.0   5.384051  \n",
       "2019-10-07 10:00:00   10.0          0.0  7.0  10.0   4.255772  \n",
       "2019-10-07 11:00:00   10.0          0.0  7.0  11.0  16.268034  \n",
       "2019-10-07 12:00:00   10.0          0.0  7.0  12.0  12.770444  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('O3.txt', header = None,low_memory=False)\n",
    "data.columns=['AE','WE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_O3=data\n",
    "Data_O3['Ref']=Ref_O3\n",
    "WE=Data_O3['WE'].to_list()\n",
    "AE=Data_O3['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_O3['Net Signal']=signal\n",
    "Data_O3['Month']=Data_O3.index.month\n",
    "Data_O3['Day_of_week']=Data_O3.index.dayofweek\n",
    "Data_O3['Day']=Data_O3.index.day\n",
    "Data_O3['Hour']=Data_O3.index.hour\n",
    "O3_Data=Data_O3\n",
    "O3_Data=O3_Data[(O3_Data[O3_Data.columns] >= 0).all(axis=1)]\n",
    "O3_Data=O3_Data.dropna()\n",
    "data = pd.read_csv('Conc_O3.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab1','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_O3=data\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_O3['Net Signal']=signal\n",
    "Data_O3['Month']=Data_O3.index.month\n",
    "Data_O3['Day_of_week']=Data_O3.index.dayofweek\n",
    "Data_O3['Day']=Data_O3.index.day\n",
    "Data_O3['Hour']=Data_O3.index.hour\n",
    "ref_NO2=Data_NO2['Ref'].to_list()\n",
    "Data_O3['Ref_NO2']=ref_NO2\n",
    "O3_Data=Data_O3\n",
    "O3_Data=O3_Data[(O3_Data[O3_Data.columns] >= 0).all(axis=1)]\n",
    "O3_Data=O3_Data.dropna()\n",
    "O3_Data=O3_Data.resample('h').mean()\n",
    "O3_Data=O3_Data.dropna()\n",
    "O3_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-spoke",
   "metadata": {},
   "source": [
    "# CO DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "empirical-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import sMAPE, smape_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import sklearn.metrics as sm\n",
    "import matplotlib.pyplot as plt\n",
    "#'Ref_NO2','Ref_SO2','Ref_O3',\n",
    "#,'Month','Day_of_week','Day','Hour'\n",
    "X=CO_Data[['Net Signal','Lab1','Temp','RH','Month','Day_of_week','Hour']]\n",
    "y=CO_Data['Ref']\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size = 0.2,shuffle=True)\n",
    "#train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "selective-tragedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from flaml.model import SKLearnEstimator\n",
    "# SKLearnEstimator is derived from BaseEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-ethernet",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel':  ['rbf']} \n",
    "  \n",
    "grid = GridSearchCV(SVR(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train.drop(['Lab1'], axis=1), y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-underground",
   "metadata": {},
   "source": [
    "from flaml.model import SKLearnEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-orientation",
   "metadata": {},
   "source": [
    "from flaml.model import SKLearnEstimator\n",
    "# SKLearnEstimator is derived from BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "class RandomForestRegressor(SKLearnEstimator):\n",
    "    def __init__(self, task=\"binary\", **config):\n",
    "        super().__init__(task, **config)\n",
    "\n",
    "        if task in CLASSIFICATION:\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "            self.estimator_class =RandomForestClassifier \n",
    "        else:\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "            self.estimator_class =RandomForestRegressor\n",
    "\n",
    "    @classmethod\n",
    "    def search_space(cls, data_size, task):\n",
    "        space = {\n",
    "            \"n_estimators\": {\n",
    "                \"domain\": {\"domain\": tune.loguniform(lower=100, upper=20000)},\n",
    "                \"low_cost_init_value\": 100,\n",
    "            },\n",
    "            \"max_features\": {\n",
    "                \"domain\": tune.loguniform(lower=0.1, upper=1),\n",
    "                \"low_cost_init_value\": 0.1,\n",
    "            },\n",
    "            \"max_leaf_nodes\": {\n",
    "                \"domain\": tune.lograndint(lower=100, upper=2500),\n",
    "                \"low_cost_init_value\": 100,},\n",
    "            \"min_samples_split\": {\"domain\": tune.lograndint(lower=1, upper=20),\n",
    "            \"init_value\": 20,},\n",
    "            \n",
    "            \"min_samples_leaf\": {\n",
    "                \"domain\": tune.lograndint(lower=1, upper=20),\n",
    "                \"init_value\": 20,\n",
    "            },\n",
    "        }\n",
    "        return space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-equity",
   "metadata": {},
   "source": [
    "from flaml import AutoML\n",
    "from flaml import tune\n",
    "automl = AutoML()\n",
    "automl.add_learner(\"rfr\",RandomForestRegressor )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-token",
   "metadata": {},
   "source": [
    "automl_settings = {\n",
    "    \"time_budget\": 1000,  # in seconds\n",
    "    \"metric\": 'rmse',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"california.log\",\n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train.drop(['Lab1'], axis=1), y_train=y_train,**automl_settings,estimator_list=[\"rfr\"])\n",
    "pred=automl.predict(X_test.drop(['Lab1'], axis=1))\n",
    "R2=round(sm.r2_score(y_test, pred), 2)\n",
    "r=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "RMSE=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y),2)\n",
    "print(r,R2,RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-cabinet",
   "metadata": {},
   "source": [
    "#  NO2 DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reliable-steel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3778, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=NO2_Data[['Net Signal','Lab1','Temp','RH','Month','Day_of_week','Hour','Ref_O3']]#'Ref_O3'\n",
    "y=NO2_Data['Ref']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "#len(X_test)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-threshold",
   "metadata": {},
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 200,  # in seconds\n",
    "    \"metric\": 'rmse',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"california.log\",\n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train.drop(['Lab1'], axis=1), y_train=y_train,**automl_settings,estimator_list=[\"xgboost\"])\n",
    "pred=automl.predict(X_test.drop(['Lab1'], axis=1))\n",
    "R2=round(sm.r2_score(y_test, pred), 2)\n",
    "r=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "RMSE=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y),2)\n",
    "print(r,R2,RMSE)\n",
    "# Predict\n",
    "#print(automl.predict(X_test))\n",
    "# Print the best model\n",
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-powder",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel':  ['rbf', 'poly', 'sigmoid']} \n",
    "  \n",
    "grid = GridSearchCV(SVR(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train.drop(['Lab1'], axis=1), y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-winning",
   "metadata": {},
   "source": [
    "# O3 DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "convertible-initial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3534"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import sklearn.metrics as sm\n",
    "import matplotlib.pyplot as plt\n",
    "#,'Ref_CO','Ref_NO2','Ref_SO2'\n",
    "X=O3_Data[['Net Signal','Lab1','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]#,'Ref_NO2'\n",
    "y=O3_Data['Ref']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-freight",
   "metadata": {},
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 200,  # in seconds\n",
    "    \"metric\": 'rmse',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"california.log\",\n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train.drop(['Lab1'], axis=1), y_train=y_train,**automl_settings,estimator_list=[\"xgboost\"])\n",
    "pred=automl.predict(X_test.drop(['Lab1'], axis=1))\n",
    "R2=round(sm.r2_score(y_test, pred), 2)\n",
    "r=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "RMSE=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y),2)\n",
    "print(r,R2,RMSE)\n",
    "# Predict\n",
    "#print(automl.predict(X_test))\n",
    "# Print the best model\n",
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-insider",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel':  ['rbf', 'poly', 'sigmoid']} \n",
    "  \n",
    "grid = GridSearchCV(SVR(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train.drop(['Lab1'], axis=1), y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-romance",
   "metadata": {},
   "source": [
    "# SO2 DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Ref=pd.read_csv('Ref.csv')\n",
    "Ref[\"CO\"] = 1000 * Ref[\"CO\"]\n",
    "Ref['Date'] = pd.to_datetime(Ref['Date_Time'])\n",
    "Ref=Ref.set_index('Date')\n",
    "Ref.drop('Date_Time',axis = 1, inplace = True)\n",
    "Ref=Ref.resample('5min').mean()\n",
    "Ref=Ref[76463:137376]\n",
    "Ref_CO=Ref['CO'].to_list()\n",
    "Ref_NO2=Ref['NO2'].to_list()\n",
    "Ref_SO2=Ref['SO2'].to_list()\n",
    "Ref_O3=Ref['O3'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('Conc_SO2.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab2','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_SO2=data\n",
    "Data_so2=data\n",
    "#signal=np.array(WE)-np.array(AE)\n",
    "#Data_SO2['Net Signal']=signal\n",
    "Data_SO2['Month']=Data_SO2.index.month\n",
    "Data_SO2['Day_of_week']=Data_SO2.index.dayofweek\n",
    "Data_SO2['Day']=Data_SO2.index.day\n",
    "Data_SO2['Hour']=Data_SO2.index.hour\n",
    "SO2_Data=Data_SO2\n",
    "SO2_Data=SO2_Data.resample('5min').mean()\n",
    "SO2_Data=SO2_Data[(SO2_Data[SO2_Data.columns] >= 0).all(axis=1)]\n",
    "SO2_Data=SO2_Data.dropna() \n",
    "data = pd.read_csv('SO2.txt', header = None,low_memory=False)\n",
    "data.columns=['WE','AE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_SO2=data\n",
    "Data_SO2['Ref']=Ref_SO2\n",
    "WE=Data_SO2['WE'].to_list()\n",
    "AE=Data_SO2['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_SO2['Lab2']=Data_so2['Lab2'].to_list()\n",
    "Data_SO2['Net Signal']=signal\n",
    "Data_SO2['Month']=Data_SO2.index.month\n",
    "Data_SO2['Day_of_week']=Data_SO2.index.dayofweek\n",
    "Data_SO2['Day']=Data_SO2.index.day\n",
    "Data_SO2['Hour']=Data_SO2.index.hour\n",
    "SO2_Data=Data_SO2\n",
    "SO2_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "SO2_Data=SO2_Data[(SO2_Data[SO2_Data.columns] >= 0).all(axis=1)]\n",
    "SO2_Data=SO2_Data.dropna()\n",
    "SO2_Data=SO2_Data.resample('h').mean()\n",
    "SO2_Data=SO2_Data.dropna()\n",
    "SO2_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import sklearn.metrics as sm\n",
    "import matplotlib.pyplot as plt\n",
    "#'Ref_CO','Ref_NO2','Ref_O3',\n",
    "X=SO2_Data[['Net Signal','Lab2','Temp','RH','Month','Day_of_week','Hour']]\n",
    "y=SO2_Data['Ref']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 21600,  # in seconds\n",
    "    \"metric\": 'rmse',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"california.log\",\n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train.drop(['Lab2'], axis=1), y_train=y_train,**automl_settings)\n",
    "pred=automl.predict(X_test.drop(['Lab2'], axis=1))\n",
    "R2=round(sm.r2_score(y_test, pred), 2)\n",
    "r=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "RMSE=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y),2)\n",
    "print(r,R2,RMSE)\n",
    "# Predict\n",
    "#print(automl.predict(X_test))\n",
    "# Print the best model\n",
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-ending",
   "metadata": {},
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 200,  # in seconds\n",
    "    \"metric\": 'rmse',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"california.log\",\n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train.drop(['Lab2'], axis=1), y_train=y_train,**automl_settings,estimator_list=[\"xgboost\"])\n",
    "pred=automl.predict(X_test.drop(['Lab2'], axis=1))\n",
    "R2=round(sm.r2_score(y_test, pred), 2)\n",
    "r=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "RMSE=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y),2)\n",
    "print(r,R2,RMSE)\n",
    "# Predict\n",
    "#print(automl.predict(X_test))\n",
    "# Print the best model\n",
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-carolina",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel':  ['rbf', 'poly', 'sigmoid']} \n",
    "  \n",
    "grid = GridSearchCV(SVR(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train.drop(['Lab2'], axis=1), y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
