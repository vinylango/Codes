{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thick-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import MultiIndex, Int16Dtype\n",
    "Ref=pd.read_csv('Ref.csv')\n",
    "Ref[\"CO\"] = 1000 * Ref[\"CO\"]\n",
    "Ref['Date'] = pd.to_datetime(Ref['Date_Time'])\n",
    "Ref=Ref.set_index('Date')\n",
    "Ref.drop('Date_Time',axis = 1, inplace = True)\n",
    "Ref=Ref.resample('5min').mean()\n",
    "Ref=Ref[76463:137376]\n",
    "Ref_CO=Ref['CO'].to_list()\n",
    "Ref_NO2=Ref['NO2'].to_list()\n",
    "Ref_SO2=Ref['SO2'].to_list()\n",
    "Ref_O3=Ref['O3'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "premier-edward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab1</th>\n",
       "      <th>Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Net Signal</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-30 19:00:00</th>\n",
       "      <td>242.060716</td>\n",
       "      <td>18.870796</td>\n",
       "      <td>71.072939</td>\n",
       "      <td>188.915151</td>\n",
       "      <td>91.471325</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30 20:00:00</th>\n",
       "      <td>218.655079</td>\n",
       "      <td>18.056864</td>\n",
       "      <td>75.132153</td>\n",
       "      <td>178.704750</td>\n",
       "      <td>84.176485</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30 21:00:00</th>\n",
       "      <td>194.147868</td>\n",
       "      <td>17.090891</td>\n",
       "      <td>81.315038</td>\n",
       "      <td>161.421792</td>\n",
       "      <td>73.858294</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30 22:00:00</th>\n",
       "      <td>206.432889</td>\n",
       "      <td>16.714085</td>\n",
       "      <td>82.568155</td>\n",
       "      <td>197.744043</td>\n",
       "      <td>83.279611</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30 23:00:00</th>\n",
       "      <td>173.577429</td>\n",
       "      <td>16.365121</td>\n",
       "      <td>83.662401</td>\n",
       "      <td>162.157636</td>\n",
       "      <td>68.669099</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Lab1       Temp         RH         Ref  Net Signal  \\\n",
       "Date                                                                            \n",
       "2020-04-30 19:00:00  242.060716  18.870796  71.072939  188.915151   91.471325   \n",
       "2020-04-30 20:00:00  218.655079  18.056864  75.132153  178.704750   84.176485   \n",
       "2020-04-30 21:00:00  194.147868  17.090891  81.315038  161.421792   73.858294   \n",
       "2020-04-30 22:00:00  206.432889  16.714085  82.568155  197.744043   83.279611   \n",
       "2020-04-30 23:00:00  173.577429  16.365121  83.662401  162.157636   68.669099   \n",
       "\n",
       "                     Month  Day_of_week   Day  Hour  \n",
       "Date                                                 \n",
       "2020-04-30 19:00:00    4.0          3.0  30.0  19.0  \n",
       "2020-04-30 20:00:00    4.0          3.0  30.0  20.0  \n",
       "2020-04-30 21:00:00    4.0          3.0  30.0  21.0  \n",
       "2020-04-30 22:00:00    4.0          3.0  30.0  22.0  \n",
       "2020-04-30 23:00:00    4.0          3.0  30.0  23.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('CO.txt', header = None,low_memory=False)\n",
    "data.columns=['WE','AE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_CO=data\n",
    "Data_CO['Ref']=Ref_CO\n",
    "index_names = Data_CO[ (Data_CO['WE'] >1000)].index\n",
    "Data_CO.drop(index_names, inplace = True)\n",
    "WE=Data_CO['WE'].to_list()\n",
    "AE=Data_CO['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_CO['Net Signal']=signal\n",
    "Data_CO['Month']=Data_CO.index.month\n",
    "Data_CO['Day_of_week']=Data_CO.index.dayofweek\n",
    "Data_CO['Day']=Data_CO.index.day\n",
    "Data_CO['Hour']=Data_CO.index.hour\n",
    "CO_Data=Data_CO\n",
    "CO_Data=CO_Data[(CO_Data[CO_Data.columns] >= 0).all(axis=1)]\n",
    "CO_Data=CO_Data.dropna()\n",
    "data = pd.read_csv('Conc_CO.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab1','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_CO=data\n",
    "Data_CO.drop(index_names, inplace = True)\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_CO['Net Signal']=signal\n",
    "Data_CO['Month']=Data_CO.index.month\n",
    "Data_CO['Day_of_week']=Data_CO.index.dayofweek\n",
    "Data_CO['Day']=Data_CO.index.day\n",
    "Data_CO['Hour']=Data_CO.index.hour\n",
    "CO_Data=Data_CO\n",
    "CO_Data=CO_Data[(CO_Data[CO_Data.columns] >= 0).all(axis=1)]\n",
    "CO_Data=CO_Data.dropna()\n",
    "CO_Data=CO_Data.resample('h').mean()\n",
    "CO_Data=CO_Data.dropna()\n",
    "CO_Data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prime-morning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60913"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('O3.txt', header = None,low_memory=False)\n",
    "data.columns=['AE','WE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_O3=data\n",
    "Data_O3['Ref']=Ref_O3\n",
    "WE=Data_O3['WE'].to_list()\n",
    "AE=Data_O3['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_O3['Net Signal']=signal\n",
    "Data_O3['Month']=Data_O3.index.month\n",
    "Data_O3['Day_of_week']=Data_O3.index.dayofweek\n",
    "Data_O3['Day']=Data_O3.index.day\n",
    "Data_O3['Hour']=Data_O3.index.hour\n",
    "O3_Data=Data_O3\n",
    "O3_Data=O3_Data[(O3_Data[O3_Data.columns] >= 0).all(axis=1)]\n",
    "O3_Data=O3_Data.dropna()\n",
    "data = pd.read_csv('Conc_O3.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab1','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_O3=data\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_O3['Net Signal']=signal\n",
    "Data_O3['Month']=Data_O3.index.month\n",
    "Data_O3['Day_of_week']=Data_O3.index.dayofweek\n",
    "Data_O3['Day']=Data_O3.index.day\n",
    "Data_O3['Hour']=Data_O3.index.hour\n",
    "O3_Data=Data_O3\n",
    "O3_Data=O3_Data[(O3_Data[O3_Data.columns] >= 0).all(axis=1)]\n",
    "O3_Data=O3_Data.dropna() \n",
    "O3_Data=O3_Data.resample('h').mean()\n",
    "O3_Data=O3_Data.dropna()\n",
    "O3_Data.head()\n",
    "\n",
    "ref_O3=Data_O3['Ref'].to_list()\n",
    "len(ref_O3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "underlying-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('NO2.txt', header = None,low_memory=False)\n",
    "data.columns=['WE','AE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_NO2=data\n",
    "Data_NO2['Ref']=Ref_NO2\n",
    "WE=Data_NO2['WE'].to_list()\n",
    "AE=Data_NO2['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_NO2['Net Signal']=signal\n",
    "Data_NO2['Month']=Data_NO2.index.month\n",
    "Data_NO2['Day_of_week']=Data_NO2.index.dayofweek\n",
    "Data_NO2['Day']=Data_NO2.index.day\n",
    "Data_NO2['Hour']=Data_NO2.index.hour\n",
    "NO2_Data=Data_NO2\n",
    "NO2_Data=NO2_Data[(NO2_Data[NO2_Data.columns] >= 0).all(axis=1)]\n",
    "NO2_Data=NO2_Data.dropna()\n",
    "data = pd.read_csv('Conc_NO2.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab1','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "subscript = str.maketrans(\"0123456789\", \"₀₁₂₃₄₅₆₇₈₉\") \n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_NO2=data\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_NO2['Net Signal']=signal\n",
    "Data_NO2['Month']=Data_NO2.index.month\n",
    "Data_NO2['Day_of_week']=Data_NO2.index.dayofweek\n",
    "Data_NO2['Day']=Data_NO2.index.day\n",
    "Data_NO2['Hour']=Data_NO2.index.hour\n",
    "Data_NO2['Ref_O3']=ref_O3\n",
    "NO2_Data=Data_NO2\n",
    "NO2_Data=NO2_Data[(NO2_Data[NO2_Data.columns] >= 0).all(axis=1)]\n",
    "NO2_Data=NO2_Data.dropna()\n",
    "NO2_Data=NO2_Data.resample('h').mean()\n",
    "NO2_Data=NO2_Data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lyric-fifteen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab1</th>\n",
       "      <th>Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Net Signal</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Ref_NO2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-02 11:00:00</th>\n",
       "      <td>621.625704</td>\n",
       "      <td>26.378438</td>\n",
       "      <td>58.063437</td>\n",
       "      <td>46.094860</td>\n",
       "      <td>3.605625</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.230400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-02 12:00:00</th>\n",
       "      <td>725.154408</td>\n",
       "      <td>25.795055</td>\n",
       "      <td>48.256857</td>\n",
       "      <td>57.532808</td>\n",
       "      <td>13.865109</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.384051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-07 10:00:00</th>\n",
       "      <td>108.196313</td>\n",
       "      <td>32.344264</td>\n",
       "      <td>37.260757</td>\n",
       "      <td>47.259008</td>\n",
       "      <td>11.447809</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.255772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-07 11:00:00</th>\n",
       "      <td>135.822676</td>\n",
       "      <td>34.926112</td>\n",
       "      <td>35.013036</td>\n",
       "      <td>42.114260</td>\n",
       "      <td>10.075221</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.268034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-07 12:00:00</th>\n",
       "      <td>203.757758</td>\n",
       "      <td>36.201221</td>\n",
       "      <td>31.829282</td>\n",
       "      <td>45.701366</td>\n",
       "      <td>7.624153</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.770444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Lab1       Temp         RH        Ref  Net Signal  \\\n",
       "Date                                                                           \n",
       "2019-10-02 11:00:00  621.625704  26.378438  58.063437  46.094860    3.605625   \n",
       "2019-10-02 12:00:00  725.154408  25.795055  48.256857  57.532808   13.865109   \n",
       "2019-10-07 10:00:00  108.196313  32.344264  37.260757  47.259008   11.447809   \n",
       "2019-10-07 11:00:00  135.822676  34.926112  35.013036  42.114260   10.075221   \n",
       "2019-10-07 12:00:00  203.757758  36.201221  31.829282  45.701366    7.624153   \n",
       "\n",
       "                     Month  Day_of_week  Day  Hour    Ref_NO2  \n",
       "Date                                                           \n",
       "2019-10-02 11:00:00   10.0          2.0  2.0  11.0  15.230400  \n",
       "2019-10-02 12:00:00   10.0          2.0  2.0  12.0   5.384051  \n",
       "2019-10-07 10:00:00   10.0          0.0  7.0  10.0   4.255772  \n",
       "2019-10-07 11:00:00   10.0          0.0  7.0  11.0  16.268034  \n",
       "2019-10-07 12:00:00   10.0          0.0  7.0  12.0  12.770444  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('O3.txt', header = None,low_memory=False)\n",
    "data.columns=['AE','WE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_O3=data\n",
    "Data_O3['Ref']=Ref_O3\n",
    "WE=Data_O3['WE'].to_list()\n",
    "AE=Data_O3['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_O3['Net Signal']=signal\n",
    "Data_O3['Month']=Data_O3.index.month\n",
    "Data_O3['Day_of_week']=Data_O3.index.dayofweek\n",
    "Data_O3['Day']=Data_O3.index.day\n",
    "Data_O3['Hour']=Data_O3.index.hour\n",
    "O3_Data=Data_O3\n",
    "O3_Data=O3_Data[(O3_Data[O3_Data.columns] >= 0).all(axis=1)]\n",
    "O3_Data=O3_Data.dropna()\n",
    "data = pd.read_csv('Conc_O3.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab1','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_O3=data\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_O3['Net Signal']=signal\n",
    "Data_O3['Month']=Data_O3.index.month\n",
    "Data_O3['Day_of_week']=Data_O3.index.dayofweek\n",
    "Data_O3['Day']=Data_O3.index.day\n",
    "Data_O3['Hour']=Data_O3.index.hour\n",
    "ref_NO2=Data_NO2['Ref'].to_list()\n",
    "Data_O3['Ref_NO2']=ref_NO2\n",
    "O3_Data=Data_O3\n",
    "O3_Data=O3_Data[(O3_Data[O3_Data.columns] >= 0).all(axis=1)]\n",
    "O3_Data=O3_Data.dropna()\n",
    "O3_Data=O3_Data.resample('h').mean()\n",
    "O3_Data=O3_Data.dropna()\n",
    "O3_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hundred-apartment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WE</th>\n",
       "      <th>AE</th>\n",
       "      <th>Temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Lab2</th>\n",
       "      <th>Net Signal</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-10 04:00:00</th>\n",
       "      <td>344.013811</td>\n",
       "      <td>342.484305</td>\n",
       "      <td>18.332589</td>\n",
       "      <td>82.373211</td>\n",
       "      <td>1.190555</td>\n",
       "      <td>9.990807</td>\n",
       "      <td>1.529506</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-10 05:00:00</th>\n",
       "      <td>347.947204</td>\n",
       "      <td>342.688948</td>\n",
       "      <td>18.160512</td>\n",
       "      <td>83.041499</td>\n",
       "      <td>1.517400</td>\n",
       "      <td>21.173371</td>\n",
       "      <td>5.258256</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-10 06:00:00</th>\n",
       "      <td>349.586425</td>\n",
       "      <td>342.643169</td>\n",
       "      <td>18.294731</td>\n",
       "      <td>80.755815</td>\n",
       "      <td>1.596648</td>\n",
       "      <td>26.255508</td>\n",
       "      <td>6.943256</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-10 07:00:00</th>\n",
       "      <td>348.280332</td>\n",
       "      <td>342.545156</td>\n",
       "      <td>21.874264</td>\n",
       "      <td>74.161148</td>\n",
       "      <td>1.518688</td>\n",
       "      <td>22.449829</td>\n",
       "      <td>5.735176</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-10 08:00:00</th>\n",
       "      <td>352.303813</td>\n",
       "      <td>345.041354</td>\n",
       "      <td>29.141688</td>\n",
       "      <td>59.611152</td>\n",
       "      <td>1.379748</td>\n",
       "      <td>23.209242</td>\n",
       "      <td>7.262459</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             WE          AE       Temp         RH       Ref  \\\n",
       "Date                                                                          \n",
       "2019-10-10 04:00:00  344.013811  342.484305  18.332589  82.373211  1.190555   \n",
       "2019-10-10 05:00:00  347.947204  342.688948  18.160512  83.041499  1.517400   \n",
       "2019-10-10 06:00:00  349.586425  342.643169  18.294731  80.755815  1.596648   \n",
       "2019-10-10 07:00:00  348.280332  342.545156  21.874264  74.161148  1.518688   \n",
       "2019-10-10 08:00:00  352.303813  345.041354  29.141688  59.611152  1.379748   \n",
       "\n",
       "                          Lab2  Net Signal  Month  Day_of_week   Day  Hour  \n",
       "Date                                                                        \n",
       "2019-10-10 04:00:00   9.990807    1.529506   10.0          3.0  10.0   4.0  \n",
       "2019-10-10 05:00:00  21.173371    5.258256   10.0          3.0  10.0   5.0  \n",
       "2019-10-10 06:00:00  26.255508    6.943256   10.0          3.0  10.0   6.0  \n",
       "2019-10-10 07:00:00  22.449829    5.735176   10.0          3.0  10.0   7.0  \n",
       "2019-10-10 08:00:00  23.209242    7.262459   10.0          3.0  10.0   8.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('Conc_SO2.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab2','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_SO2=data\n",
    "Data_so2=data\n",
    "#signal=np.array(WE)-np.array(AE)\n",
    "#Data_SO2['Net Signal']=signal\n",
    "Data_SO2['Month']=Data_SO2.index.month\n",
    "Data_SO2['Day_of_week']=Data_SO2.index.dayofweek\n",
    "Data_SO2['Day']=Data_SO2.index.day\n",
    "Data_SO2['Hour']=Data_SO2.index.hour\n",
    "SO2_Data=Data_SO2\n",
    "SO2_Data=SO2_Data.resample('5min').mean()\n",
    "SO2_Data=SO2_Data[(SO2_Data[SO2_Data.columns] >= 0).all(axis=1)]\n",
    "SO2_Data=SO2_Data.dropna() \n",
    "data = pd.read_csv('SO2.txt', header = None,low_memory=False)\n",
    "data.columns=['WE','AE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_SO2=data\n",
    "Data_SO2['Ref']=Ref_SO2\n",
    "WE=Data_SO2['WE'].to_list()\n",
    "AE=Data_SO2['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_SO2['Lab2']=Data_so2['Lab2'].to_list()\n",
    "Data_SO2['WE']=WE\n",
    "Data_SO2['Net Signal']=signal\n",
    "Data_SO2['Month']=Data_SO2.index.month\n",
    "Data_SO2['Day_of_week']=Data_SO2.index.dayofweek\n",
    "Data_SO2['Day']=Data_SO2.index.day\n",
    "Data_SO2['Hour']=Data_SO2.index.hour\n",
    "SO2_Data=Data_SO2\n",
    "SO2_Data.shape\n",
    "SO2_Data=SO2_Data[(SO2_Data[SO2_Data.columns] >= 0).all(axis=1)]\n",
    "SO2_Data=SO2_Data.dropna()\n",
    "SO2_Data=SO2_Data.resample('h').mean()\n",
    "SO2_Data=SO2_Data.dropna()\n",
    "SO2_Data_Scaled= (SO2_Data-SO2_Data.min())/(SO2_Data.max()-SO2_Data.min())\n",
    "SO2_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-spoke",
   "metadata": {},
   "source": [
    "# CO DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "medium-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=[x for _, x in SO2_Data.groupby('Month')]\n",
    "data_oct=df1[4]\n",
    "#data_oct=data_oct.sample(frac=1)\n",
    "data_nov=df1[5]\n",
    "#data_nov=data_nov.sample(frac=1)\n",
    "data_dec=df1[6]\n",
    "#data_dec=data_dec.sample(frac=1)\n",
    "data_jan=df1[0]\n",
    "#data_jan=data_jan.sample(frac=1)\n",
    "data_feb=df1[1]\n",
    "#data_feb=data_feb.sample(frac=1)\n",
    "data_mar=df1[2]\n",
    "\n",
    "data_Oct=data_oct.resample('60min').mean()\n",
    "data_Oct=data_Oct.dropna()\n",
    "data_Oct1=data_Oct[:int(0.8*data_Oct.shape[0])]\n",
    "data_Oct2=data_Oct[int(0.8*data_Oct.shape[0]):]\n",
    "data_Nov=data_nov.resample('60min').mean()\n",
    "data_Nov=data_Nov.dropna()\n",
    "data_Nov1=data_Nov[:int(0.8*data_Nov.shape[0])]\n",
    "data_Nov2=data_Nov[int(0.8*data_Nov.shape[0]):]\n",
    "data_Dec=data_dec.resample('60min').mean()\n",
    "data_Dec=data_Dec.dropna()\n",
    "data_Dec1=data_Dec[:int(0.8*data_Dec.shape[0])]\n",
    "data_Dec2=data_Dec[int(0.8*data_Dec.shape[0]):]\n",
    "data_Jan=data_jan.resample('60min').mean()\n",
    "data_Jan=data_Jan.dropna()\n",
    "data_Jan1=data_Jan[:int(0.8*data_Jan.shape[0])]\n",
    "data_Jan2=data_Jan[int(0.8*data_Jan.shape[0]):]\n",
    "data_Feb=data_feb.resample('60min').mean()\n",
    "data_Feb=data_Feb.dropna()\n",
    "data_Feb1=data_Feb[:int(0.8*data_Feb.shape[0])]\n",
    "data_Feb2=data_Feb[int(0.8*data_Feb.shape[0]):]\n",
    "data_Mar=data_mar.resample('60min').mean()\n",
    "data_Mar=data_Mar.dropna()\n",
    "data_Mar1=data_Mar[:int(0.8*data_Mar.shape[0])]\n",
    "data_Mar2=data_Mar[int(0.8*data_Mar.shape[0]):]\n",
    "frame1=[data_Oct1,data_Nov1,data_Dec1,data_Jan1,data_Feb1,data_Mar1]\n",
    "frame2=[data_Oct2,data_Nov2,data_Dec2,data_Jan2,data_Feb2,data_Mar2]\n",
    "CO_data1=pd.concat(frame1)\n",
    "CO_data2=pd.concat(frame2)\n",
    "CO_data=pd.concat([CO_data1,CO_data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "empirical-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import sMAPE, smape_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import sklearn.metrics as sm\n",
    "import matplotlib.pyplot as plt\n",
    "#'Ref_NO2','Ref_SO2','Ref_O3',\n",
    "#,'Month','Day_of_week','Day','Hour'\n",
    "X=CO_data[['Net Signal','Lab2','Temp','RH','Month','Day_of_week','Hour']]\n",
    "y=CO_data['Ref']\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size = 0.2,shuffle=False)\n",
    "#train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "selective-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.model import SKLearnEstimator\n",
    "# SKLearnEstimator is derived from BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "diverse-functionality",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 02-16 11:00:25] {2599} INFO - task = regression\n",
      "[flaml.automl: 02-16 11:00:25] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 02-16 11:00:25] {2604} INFO - Evaluation method: cv\n",
      "[flaml.automl: 02-16 11:00:25] {2726} INFO - Minimizing error metric: mae\n",
      "[flaml.automl: 02-16 11:00:25] {2870} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl: 02-16 11:00:25] {3166} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:26] {3296} INFO - Estimated sufficient time budget=799s. Estimated necessary time budget=1s.\n",
      "[flaml.automl: 02-16 11:00:26] {3343} INFO -  at 0.1s,\testimator xgboost's best error=0.7784,\tbest estimator xgboost's best error=0.7784\n",
      "[flaml.automl: 02-16 11:00:26] {3166} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:26] {3343} INFO -  at 0.2s,\testimator xgboost's best error=0.7784,\tbest estimator xgboost's best error=0.7784\n",
      "[flaml.automl: 02-16 11:00:26] {3166} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:26] {3343} INFO -  at 0.3s,\testimator xgboost's best error=0.5100,\tbest estimator xgboost's best error=0.5100\n",
      "[flaml.automl: 02-16 11:00:26] {3166} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:26] {3343} INFO -  at 0.3s,\testimator xgboost's best error=0.4702,\tbest estimator xgboost's best error=0.4702\n",
      "[flaml.automl: 02-16 11:00:26] {3166} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:26] {3343} INFO -  at 0.4s,\testimator xgboost's best error=0.4702,\tbest estimator xgboost's best error=0.4702\n",
      "[flaml.automl: 02-16 11:00:26] {3166} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:26] {3343} INFO -  at 0.4s,\testimator xgboost's best error=0.4523,\tbest estimator xgboost's best error=0.4523\n",
      "[flaml.automl: 02-16 11:00:26] {3166} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:26] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.4523,\tbest estimator xgboost's best error=0.4523\n",
      "[flaml.automl: 02-16 11:00:26] {3166} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:26] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.4523,\tbest estimator xgboost's best error=0.4523\n",
      "[flaml.automl: 02-16 11:00:26] {3166} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:26] {3343} INFO -  at 0.7s,\testimator xgboost's best error=0.4523,\tbest estimator xgboost's best error=0.4523\n",
      "[flaml.automl: 02-16 11:00:26] {3166} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:26] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.4421,\tbest estimator xgboost's best error=0.4421\n",
      "[flaml.automl: 02-16 11:00:26] {3166} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:26] {3343} INFO -  at 0.9s,\testimator xgboost's best error=0.4421,\tbest estimator xgboost's best error=0.4421\n",
      "[flaml.automl: 02-16 11:00:26] {3166} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:26] {3343} INFO -  at 1.0s,\testimator xgboost's best error=0.4421,\tbest estimator xgboost's best error=0.4421\n",
      "[flaml.automl: 02-16 11:00:26] {3166} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:27] {3343} INFO -  at 1.2s,\testimator xgboost's best error=0.4358,\tbest estimator xgboost's best error=0.4358\n",
      "[flaml.automl: 02-16 11:00:27] {3166} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:27] {3343} INFO -  at 1.3s,\testimator xgboost's best error=0.4358,\tbest estimator xgboost's best error=0.4358\n",
      "[flaml.automl: 02-16 11:00:27] {3166} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:27] {3343} INFO -  at 1.4s,\testimator xgboost's best error=0.4358,\tbest estimator xgboost's best error=0.4358\n",
      "[flaml.automl: 02-16 11:00:27] {3166} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:27] {3343} INFO -  at 1.5s,\testimator xgboost's best error=0.4358,\tbest estimator xgboost's best error=0.4358\n",
      "[flaml.automl: 02-16 11:00:27] {3166} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:27] {3343} INFO -  at 1.6s,\testimator xgboost's best error=0.4358,\tbest estimator xgboost's best error=0.4358\n",
      "[flaml.automl: 02-16 11:00:27] {3166} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:27] {3343} INFO -  at 1.7s,\testimator xgboost's best error=0.4358,\tbest estimator xgboost's best error=0.4358\n",
      "[flaml.automl: 02-16 11:00:27] {3166} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:27] {3343} INFO -  at 1.8s,\testimator xgboost's best error=0.4358,\tbest estimator xgboost's best error=0.4358\n",
      "[flaml.automl: 02-16 11:00:27] {3166} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:27] {3343} INFO -  at 2.0s,\testimator xgboost's best error=0.4358,\tbest estimator xgboost's best error=0.4358\n",
      "[flaml.automl: 02-16 11:00:27] {3166} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:28] {3343} INFO -  at 2.1s,\testimator xgboost's best error=0.4129,\tbest estimator xgboost's best error=0.4129\n",
      "[flaml.automl: 02-16 11:00:28] {3166} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:28] {3343} INFO -  at 2.2s,\testimator xgboost's best error=0.4129,\tbest estimator xgboost's best error=0.4129\n",
      "[flaml.automl: 02-16 11:00:28] {3166} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:28] {3343} INFO -  at 2.4s,\testimator xgboost's best error=0.4129,\tbest estimator xgboost's best error=0.4129\n",
      "[flaml.automl: 02-16 11:00:28] {3166} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:28] {3343} INFO -  at 2.4s,\testimator xgboost's best error=0.4129,\tbest estimator xgboost's best error=0.4129\n",
      "[flaml.automl: 02-16 11:00:28] {3166} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:28] {3343} INFO -  at 2.6s,\testimator xgboost's best error=0.4129,\tbest estimator xgboost's best error=0.4129\n",
      "[flaml.automl: 02-16 11:00:28] {3166} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:28] {3343} INFO -  at 2.7s,\testimator xgboost's best error=0.4129,\tbest estimator xgboost's best error=0.4129\n",
      "[flaml.automl: 02-16 11:00:28] {3166} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:28] {3343} INFO -  at 2.9s,\testimator xgboost's best error=0.3842,\tbest estimator xgboost's best error=0.3842\n",
      "[flaml.automl: 02-16 11:00:28] {3166} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:29] {3343} INFO -  at 3.1s,\testimator xgboost's best error=0.3842,\tbest estimator xgboost's best error=0.3842\n",
      "[flaml.automl: 02-16 11:00:29] {3166} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:29] {3343} INFO -  at 3.3s,\testimator xgboost's best error=0.3842,\tbest estimator xgboost's best error=0.3842\n",
      "[flaml.automl: 02-16 11:00:29] {3166} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:29] {3343} INFO -  at 3.4s,\testimator xgboost's best error=0.3842,\tbest estimator xgboost's best error=0.3842\n",
      "[flaml.automl: 02-16 11:00:29] {3166} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:29] {3343} INFO -  at 3.8s,\testimator xgboost's best error=0.3722,\tbest estimator xgboost's best error=0.3722\n",
      "[flaml.automl: 02-16 11:00:29] {3166} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:29] {3343} INFO -  at 4.1s,\testimator xgboost's best error=0.3722,\tbest estimator xgboost's best error=0.3722\n",
      "[flaml.automl: 02-16 11:00:29] {3166} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:30] {3343} INFO -  at 4.6s,\testimator xgboost's best error=0.3715,\tbest estimator xgboost's best error=0.3715\n",
      "[flaml.automl: 02-16 11:00:30] {3166} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:30] {3343} INFO -  at 5.0s,\testimator xgboost's best error=0.3715,\tbest estimator xgboost's best error=0.3715\n",
      "[flaml.automl: 02-16 11:00:30] {3166} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:31] {3343} INFO -  at 5.3s,\testimator xgboost's best error=0.3697,\tbest estimator xgboost's best error=0.3697\n",
      "[flaml.automl: 02-16 11:00:31] {3166} INFO - iteration 35, current learner xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 02-16 11:00:32] {3343} INFO -  at 6.2s,\testimator xgboost's best error=0.3697,\tbest estimator xgboost's best error=0.3697\n",
      "[flaml.automl: 02-16 11:00:32] {3166} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:32] {3343} INFO -  at 6.4s,\testimator xgboost's best error=0.3697,\tbest estimator xgboost's best error=0.3697\n",
      "[flaml.automl: 02-16 11:00:32] {3166} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:32] {3343} INFO -  at 6.8s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:32] {3166} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:33] {3343} INFO -  at 7.2s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:33] {3166} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:33] {3343} INFO -  at 7.7s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:33] {3166} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:33] {3343} INFO -  at 8.0s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:33] {3166} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:34] {3343} INFO -  at 8.2s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:34] {3166} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:34] {3343} INFO -  at 9.0s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:34] {3166} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:35] {3343} INFO -  at 9.6s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:35] {3166} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:35] {3343} INFO -  at 9.9s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:35] {3166} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:36] {3343} INFO -  at 10.5s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:36] {3166} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:36] {3343} INFO -  at 10.7s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:36] {3166} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:36] {3343} INFO -  at 10.9s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:36] {3166} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:37] {3343} INFO -  at 11.3s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:37] {3166} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:37] {3343} INFO -  at 11.8s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:37] {3166} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:38] {3343} INFO -  at 12.3s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:38] {3166} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:39] {3343} INFO -  at 13.1s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:39] {3166} INFO - iteration 52, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:39] {3343} INFO -  at 13.4s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:39] {3166} INFO - iteration 53, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:39] {3343} INFO -  at 13.8s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:39] {3166} INFO - iteration 54, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:40] {3343} INFO -  at 14.2s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:40] {3166} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:40] {3343} INFO -  at 14.5s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:40] {3166} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:40] {3343} INFO -  at 14.8s,\testimator xgboost's best error=0.3597,\tbest estimator xgboost's best error=0.3597\n",
      "[flaml.automl: 02-16 11:00:40] {3166} INFO - iteration 57, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:41] {3343} INFO -  at 15.9s,\testimator xgboost's best error=0.3547,\tbest estimator xgboost's best error=0.3547\n",
      "[flaml.automl: 02-16 11:00:41] {3166} INFO - iteration 58, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:42] {3343} INFO -  at 16.4s,\testimator xgboost's best error=0.3547,\tbest estimator xgboost's best error=0.3547\n",
      "[flaml.automl: 02-16 11:00:42] {3166} INFO - iteration 59, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:42] {3343} INFO -  at 17.0s,\testimator xgboost's best error=0.3547,\tbest estimator xgboost's best error=0.3547\n",
      "[flaml.automl: 02-16 11:00:42] {3166} INFO - iteration 60, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:45] {3343} INFO -  at 19.2s,\testimator xgboost's best error=0.3547,\tbest estimator xgboost's best error=0.3547\n",
      "[flaml.automl: 02-16 11:00:45] {3166} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:46] {3343} INFO -  at 20.6s,\testimator xgboost's best error=0.3512,\tbest estimator xgboost's best error=0.3512\n",
      "[flaml.automl: 02-16 11:00:46] {3166} INFO - iteration 62, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:47] {3343} INFO -  at 21.6s,\testimator xgboost's best error=0.3512,\tbest estimator xgboost's best error=0.3512\n",
      "[flaml.automl: 02-16 11:00:47] {3166} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:49] {3343} INFO -  at 23.2s,\testimator xgboost's best error=0.3512,\tbest estimator xgboost's best error=0.3512\n",
      "[flaml.automl: 02-16 11:00:49] {3166} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:50] {3343} INFO -  at 24.2s,\testimator xgboost's best error=0.3501,\tbest estimator xgboost's best error=0.3501\n",
      "[flaml.automl: 02-16 11:00:50] {3166} INFO - iteration 65, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:50] {3343} INFO -  at 24.4s,\testimator xgboost's best error=0.3501,\tbest estimator xgboost's best error=0.3501\n",
      "[flaml.automl: 02-16 11:00:50] {3166} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:54] {3343} INFO -  at 28.1s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:00:54] {3166} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl: 02-16 11:00:59] {3343} INFO -  at 34.1s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:00:59] {3166} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:01] {3343} INFO -  at 35.9s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:01] {3166} INFO - iteration 69, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:11] {3343} INFO -  at 45.1s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:11] {3166} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:12] {3343} INFO -  at 46.5s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:12] {3166} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:16] {3343} INFO -  at 50.5s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:16] {3166} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:19] {3343} INFO -  at 53.2s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 02-16 11:01:19] {3166} INFO - iteration 73, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:21] {3343} INFO -  at 55.6s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:21] {3166} INFO - iteration 74, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:24] {3343} INFO -  at 58.4s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:24] {3166} INFO - iteration 75, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:27] {3343} INFO -  at 61.7s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:27] {3166} INFO - iteration 76, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:32] {3343} INFO -  at 66.8s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:32] {3166} INFO - iteration 77, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:34] {3343} INFO -  at 68.7s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:34] {3166} INFO - iteration 78, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:38] {3343} INFO -  at 72.6s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:38] {3166} INFO - iteration 79, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:43] {3343} INFO -  at 77.7s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:43] {3166} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:46] {3343} INFO -  at 80.7s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:46] {3166} INFO - iteration 81, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:49] {3343} INFO -  at 83.9s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:49] {3166} INFO - iteration 82, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:53] {3343} INFO -  at 87.9s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:53] {3166} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl: 02-16 11:01:57] {3343} INFO -  at 91.1s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:01:57] {3166} INFO - iteration 84, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:00] {3343} INFO -  at 94.6s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:02:00] {3166} INFO - iteration 85, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:02] {3343} INFO -  at 96.2s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:02:02] {3166} INFO - iteration 86, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:09] {3343} INFO -  at 103.4s,\testimator xgboost's best error=0.3448,\tbest estimator xgboost's best error=0.3448\n",
      "[flaml.automl: 02-16 11:02:09] {3166} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:14] {3343} INFO -  at 108.7s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:02:14] {3166} INFO - iteration 88, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:17] {3343} INFO -  at 112.0s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:02:17] {3166} INFO - iteration 89, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:23] {3343} INFO -  at 117.2s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:02:23] {3166} INFO - iteration 90, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:26] {3343} INFO -  at 120.6s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:02:26] {3166} INFO - iteration 91, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:28] {3343} INFO -  at 122.9s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:02:28] {3166} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:32] {3343} INFO -  at 127.0s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:02:32] {3166} INFO - iteration 93, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:35] {3343} INFO -  at 129.3s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:02:35] {3166} INFO - iteration 94, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:41] {3343} INFO -  at 135.4s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:02:41] {3166} INFO - iteration 95, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:43] {3343} INFO -  at 137.6s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:02:43] {3166} INFO - iteration 96, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:47] {3343} INFO -  at 142.0s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:02:47] {3166} INFO - iteration 97, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:51] {3343} INFO -  at 145.8s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:02:51] {3166} INFO - iteration 98, current learner xgboost\n",
      "[flaml.automl: 02-16 11:02:58] {3343} INFO -  at 152.5s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:02:58] {3166} INFO - iteration 99, current learner xgboost\n",
      "[flaml.automl: 02-16 11:03:01] {3343} INFO -  at 155.3s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:03:01] {3166} INFO - iteration 100, current learner xgboost\n",
      "[flaml.automl: 02-16 11:03:05] {3343} INFO -  at 159.2s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:03:05] {3166} INFO - iteration 101, current learner xgboost\n",
      "[flaml.automl: 02-16 11:03:16] {3343} INFO -  at 170.1s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:03:16] {3166} INFO - iteration 102, current learner xgboost\n",
      "[flaml.automl: 02-16 11:03:18] {3343} INFO -  at 172.3s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:03:18] {3166} INFO - iteration 103, current learner xgboost\n",
      "[flaml.automl: 02-16 11:03:22] {3343} INFO -  at 176.7s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:03:22] {3166} INFO - iteration 104, current learner xgboost\n",
      "[flaml.automl: 02-16 11:03:27] {3343} INFO -  at 181.4s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:03:27] {3166} INFO - iteration 105, current learner xgboost\n",
      "[flaml.automl: 02-16 11:03:30] {3343} INFO -  at 184.1s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:03:30] {3166} INFO - iteration 106, current learner xgboost\n",
      "[flaml.automl: 02-16 11:03:39] {3343} INFO -  at 193.2s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:03:39] {3166} INFO - iteration 107, current learner xgboost\n",
      "[flaml.automl: 02-16 11:03:42] {3343} INFO -  at 196.1s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:03:42] {3166} INFO - iteration 108, current learner xgboost\n",
      "[flaml.automl: 02-16 11:03:49] {3343} INFO -  at 203.1s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:03:49] {3166} INFO - iteration 109, current learner xgboost\n",
      "[flaml.automl: 02-16 11:03:51] {3343} INFO -  at 205.3s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 02-16 11:03:51] {3166} INFO - iteration 110, current learner xgboost\n",
      "[flaml.automl: 02-16 11:03:55] {3343} INFO -  at 209.5s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:03:55] {3166} INFO - iteration 111, current learner xgboost\n",
      "[flaml.automl: 02-16 11:03:57] {3343} INFO -  at 211.7s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:03:57] {3166} INFO - iteration 112, current learner xgboost\n",
      "[flaml.automl: 02-16 11:04:05] {3343} INFO -  at 219.4s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:04:05] {3166} INFO - iteration 113, current learner xgboost\n",
      "[flaml.automl: 02-16 11:04:08] {3343} INFO -  at 222.2s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:04:08] {3166} INFO - iteration 114, current learner xgboost\n",
      "[flaml.automl: 02-16 11:04:10] {3343} INFO -  at 224.1s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:04:10] {3166} INFO - iteration 115, current learner xgboost\n",
      "[flaml.automl: 02-16 11:04:11] {3343} INFO -  at 225.7s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:04:11] {3166} INFO - iteration 116, current learner xgboost\n",
      "[flaml.automl: 02-16 11:04:29] {3343} INFO -  at 243.4s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:04:29] {3166} INFO - iteration 117, current learner xgboost\n",
      "[flaml.automl: 02-16 11:04:36] {3343} INFO -  at 250.2s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:04:36] {3166} INFO - iteration 118, current learner xgboost\n",
      "[flaml.automl: 02-16 11:04:38] {3343} INFO -  at 252.5s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:04:38] {3166} INFO - iteration 119, current learner xgboost\n",
      "[flaml.automl: 02-16 11:04:40] {3343} INFO -  at 254.9s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:04:40] {3166} INFO - iteration 120, current learner xgboost\n",
      "[flaml.automl: 02-16 11:04:48] {3343} INFO -  at 263.0s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:04:48] {3166} INFO - iteration 121, current learner xgboost\n",
      "[flaml.automl: 02-16 11:04:54] {3343} INFO -  at 268.2s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:04:54] {3166} INFO - iteration 122, current learner xgboost\n",
      "[flaml.automl: 02-16 11:04:59] {3343} INFO -  at 273.2s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:04:59] {3166} INFO - iteration 123, current learner xgboost\n",
      "[flaml.automl: 02-16 11:05:02] {3343} INFO -  at 277.0s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:05:02] {3166} INFO - iteration 124, current learner xgboost\n",
      "[flaml.automl: 02-16 11:05:05] {3343} INFO -  at 279.8s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:05:05] {3166} INFO - iteration 125, current learner xgboost\n",
      "[flaml.automl: 02-16 11:05:08] {3343} INFO -  at 282.1s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:05:08] {3166} INFO - iteration 126, current learner xgboost\n",
      "[flaml.automl: 02-16 11:05:17] {3343} INFO -  at 291.6s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:05:17] {3166} INFO - iteration 127, current learner xgboost\n",
      "[flaml.automl: 02-16 11:05:19] {3343} INFO -  at 293.5s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:05:19] {3166} INFO - iteration 128, current learner xgboost\n",
      "[flaml.automl: 02-16 11:05:34] {3343} INFO -  at 308.6s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:05:34] {3166} INFO - iteration 129, current learner xgboost\n",
      "[flaml.automl: 02-16 11:05:35] {3343} INFO -  at 310.0s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:05:35] {3166} INFO - iteration 130, current learner xgboost\n",
      "[flaml.automl: 02-16 11:05:41] {3343} INFO -  at 316.0s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:05:41] {3166} INFO - iteration 131, current learner xgboost\n",
      "[flaml.automl: 02-16 11:05:47] {3343} INFO -  at 321.8s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:05:47] {3166} INFO - iteration 132, current learner xgboost\n",
      "[flaml.automl: 02-16 11:05:51] {3343} INFO -  at 326.0s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:05:51] {3166} INFO - iteration 133, current learner xgboost\n",
      "[flaml.automl: 02-16 11:05:54] {3343} INFO -  at 329.0s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:05:54] {3166} INFO - iteration 134, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:00] {3343} INFO -  at 334.6s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:06:00] {3166} INFO - iteration 135, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:03] {3343} INFO -  at 337.2s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:06:03] {3166} INFO - iteration 136, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:07] {3343} INFO -  at 341.9s,\testimator xgboost's best error=0.3415,\tbest estimator xgboost's best error=0.3415\n",
      "[flaml.automl: 02-16 11:06:07] {3166} INFO - iteration 137, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:12] {3343} INFO -  at 346.9s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:12] {3166} INFO - iteration 138, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:19] {3343} INFO -  at 353.4s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:19] {3166} INFO - iteration 139, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:21] {3343} INFO -  at 355.7s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:21] {3166} INFO - iteration 140, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:23] {3343} INFO -  at 357.8s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:23] {3166} INFO - iteration 141, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:25] {3343} INFO -  at 359.5s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:25] {3166} INFO - iteration 142, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:27] {3343} INFO -  at 361.9s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:27] {3166} INFO - iteration 143, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:30] {3343} INFO -  at 364.7s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:30] {3166} INFO - iteration 144, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:32] {3343} INFO -  at 366.6s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:32] {3166} INFO - iteration 145, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:36] {3343} INFO -  at 370.3s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:36] {3166} INFO - iteration 146, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:40] {3343} INFO -  at 374.7s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 02-16 11:06:40] {3166} INFO - iteration 147, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:43] {3343} INFO -  at 377.4s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:43] {3166} INFO - iteration 148, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:45] {3343} INFO -  at 379.4s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:45] {3166} INFO - iteration 149, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:47] {3343} INFO -  at 381.8s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:47] {3166} INFO - iteration 150, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:50] {3343} INFO -  at 384.5s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:50] {3166} INFO - iteration 151, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:55] {3343} INFO -  at 389.5s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:55] {3166} INFO - iteration 152, current learner xgboost\n",
      "[flaml.automl: 02-16 11:06:59] {3343} INFO -  at 393.8s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:06:59] {3166} INFO - iteration 153, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:01] {3343} INFO -  at 395.9s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:07:01] {3166} INFO - iteration 154, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:06] {3343} INFO -  at 400.7s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:07:06] {3166} INFO - iteration 155, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:08] {3343} INFO -  at 402.3s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:07:08] {3166} INFO - iteration 156, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:13] {3343} INFO -  at 407.6s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:07:13] {3166} INFO - iteration 157, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:19] {3343} INFO -  at 413.2s,\testimator xgboost's best error=0.3391,\tbest estimator xgboost's best error=0.3391\n",
      "[flaml.automl: 02-16 11:07:19] {3166} INFO - iteration 158, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:21] {3343} INFO -  at 415.6s,\testimator xgboost's best error=0.3390,\tbest estimator xgboost's best error=0.3390\n",
      "[flaml.automl: 02-16 11:07:21] {3166} INFO - iteration 159, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:22] {3343} INFO -  at 416.6s,\testimator xgboost's best error=0.3390,\tbest estimator xgboost's best error=0.3390\n",
      "[flaml.automl: 02-16 11:07:22] {3166} INFO - iteration 160, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:23] {3343} INFO -  at 418.0s,\testimator xgboost's best error=0.3390,\tbest estimator xgboost's best error=0.3390\n",
      "[flaml.automl: 02-16 11:07:23] {3166} INFO - iteration 161, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:26] {3343} INFO -  at 421.0s,\testimator xgboost's best error=0.3390,\tbest estimator xgboost's best error=0.3390\n",
      "[flaml.automl: 02-16 11:07:26] {3166} INFO - iteration 162, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:28] {3343} INFO -  at 423.0s,\testimator xgboost's best error=0.3390,\tbest estimator xgboost's best error=0.3390\n",
      "[flaml.automl: 02-16 11:07:28] {3166} INFO - iteration 163, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:34] {3343} INFO -  at 428.8s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:07:34] {3166} INFO - iteration 164, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:36] {3343} INFO -  at 430.4s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:07:36] {3166} INFO - iteration 165, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:39] {3343} INFO -  at 433.6s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:07:39] {3166} INFO - iteration 166, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:45] {3343} INFO -  at 439.7s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:07:45] {3166} INFO - iteration 167, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:47] {3343} INFO -  at 441.9s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:07:47] {3166} INFO - iteration 168, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:49] {3343} INFO -  at 443.9s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:07:49] {3166} INFO - iteration 169, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:53] {3343} INFO -  at 448.0s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:07:53] {3166} INFO - iteration 170, current learner xgboost\n",
      "[flaml.automl: 02-16 11:07:56] {3343} INFO -  at 450.7s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:07:56] {3166} INFO - iteration 171, current learner xgboost\n",
      "[flaml.automl: 02-16 11:08:00] {3343} INFO -  at 454.6s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:08:00] {3166} INFO - iteration 172, current learner xgboost\n",
      "[flaml.automl: 02-16 11:08:09] {3343} INFO -  at 463.1s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:08:09] {3166} INFO - iteration 173, current learner xgboost\n",
      "[flaml.automl: 02-16 11:08:12] {3343} INFO -  at 466.8s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:08:12] {3166} INFO - iteration 174, current learner xgboost\n",
      "[flaml.automl: 02-16 11:08:17] {3343} INFO -  at 471.8s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:08:17] {3166} INFO - iteration 175, current learner xgboost\n",
      "[flaml.automl: 02-16 11:08:24] {3343} INFO -  at 478.1s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:08:24] {3166} INFO - iteration 176, current learner xgboost\n",
      "[flaml.automl: 02-16 11:08:25] {3343} INFO -  at 480.0s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:08:25] {3166} INFO - iteration 177, current learner xgboost\n",
      "[flaml.automl: 02-16 11:08:29] {3343} INFO -  at 483.6s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:08:29] {3166} INFO - iteration 178, current learner xgboost\n",
      "[flaml.automl: 02-16 11:08:34] {3343} INFO -  at 488.1s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:08:34] {3166} INFO - iteration 179, current learner xgboost\n",
      "[flaml.automl: 02-16 11:08:37] {3343} INFO -  at 491.9s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:08:37] {3166} INFO - iteration 180, current learner xgboost\n",
      "[flaml.automl: 02-16 11:08:43] {3343} INFO -  at 497.7s,\testimator xgboost's best error=0.3374,\tbest estimator xgboost's best error=0.3374\n",
      "[flaml.automl: 02-16 11:08:45] {3602} INFO - retrain xgboost for 1.7s\n",
      "[flaml.automl: 02-16 11:08:45] {3609} INFO - retrained model: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
      "             colsample_bynode=1, colsample_bytree=1.0, gamma=0, gpu_id=-1,\n",
      "             grow_policy='lossguide', importance_type='gain',\n",
      "             interaction_constraints='', learning_rate=0.06390708031382199,\n",
      "             max_delta_step=0, max_depth=0, max_leaves=51,\n",
      "             min_child_weight=0.10848415458921998, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=1464, n_jobs=-1,\n",
      "             num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0.004028264655233534, reg_lambda=0.072086129428632,\n",
      "             scale_pos_weight=1, subsample=0.9444531464743854,\n",
      "             tree_method='hist', use_label_encoder=False, validate_parameters=1,\n",
      "             verbosity=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 02-16 11:08:45] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 02-16 11:08:45] {2902} INFO - Time taken to find the best model: 428.80761981010437\n",
      "[flaml.automl: 02-16 11:08:45] {2913} WARNING - Time taken to find the best model is 86% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38 -0.0 0.4\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
      "             colsample_bynode=1, colsample_bytree=1.0, gamma=0, gpu_id=-1,\n",
      "             grow_policy='lossguide', importance_type='gain',\n",
      "             interaction_constraints='', learning_rate=0.06390708031382199,\n",
      "             max_delta_step=0, max_depth=0, max_leaves=51,\n",
      "             min_child_weight=0.10848415458921998, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=1464, n_jobs=-1,\n",
      "             num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0.004028264655233534, reg_lambda=0.072086129428632,\n",
      "             scale_pos_weight=1, subsample=0.9444531464743854,\n",
      "             tree_method='hist', use_label_encoder=False, validate_parameters=1,\n",
      "             verbosity=0)\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 500,  # in seconds\n",
    "    \"metric\": 'mae',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"california.log\",\n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train, y_train=y_train,\n",
    "           **automl_settings,estimator_list=[\"xgboost\"])#,estimator_list=[\"xgboost\"]\n",
    "pred=automl.predict(X_test)\n",
    "R2=round(sm.r2_score(y_test, pred), 2)\n",
    "r=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "RMSE=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y),2)\n",
    "print(r,R2,RMSE)\n",
    "# Predict\n",
    "#print(automl.predict(X_test))\n",
    "# Print the best model\n",
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-ethernet",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel':  ['rbf']} \n",
    "  \n",
    "grid = GridSearchCV(SVR(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train.drop(['Lab1'], axis=1), y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-underground",
   "metadata": {},
   "source": [
    "from flaml.model import SKLearnEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-orientation",
   "metadata": {},
   "source": [
    "from flaml.model import SKLearnEstimator\n",
    "# SKLearnEstimator is derived from BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "class RandomForestRegressor(SKLearnEstimator):\n",
    "    def __init__(self, task=\"binary\", **config):\n",
    "        super().__init__(task, **config)\n",
    "\n",
    "        if task in CLASSIFICATION:\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "            self.estimator_class =RandomForestClassifier \n",
    "        else:\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "            self.estimator_class =RandomForestRegressor\n",
    "\n",
    "    @classmethod\n",
    "    def search_space(cls, data_size, task):\n",
    "        space = {\n",
    "            \"n_estimators\": {\n",
    "                \"domain\": {\"domain\": tune.loguniform(lower=100, upper=20000)},\n",
    "                \"low_cost_init_value\": 100,\n",
    "            },\n",
    "            \"max_features\": {\n",
    "                \"domain\": tune.loguniform(lower=0.1, upper=1),\n",
    "                \"low_cost_init_value\": 0.1,\n",
    "            },\n",
    "            \"max_leaf_nodes\": {\n",
    "                \"domain\": tune.lograndint(lower=100, upper=2500),\n",
    "                \"low_cost_init_value\": 100,},\n",
    "            \"min_samples_split\": {\"domain\": tune.lograndint(lower=1, upper=20),\n",
    "            \"init_value\": 20,},\n",
    "            \n",
    "            \"min_samples_leaf\": {\n",
    "                \"domain\": tune.lograndint(lower=1, upper=20),\n",
    "                \"init_value\": 20,\n",
    "            },\n",
    "        }\n",
    "        return space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-equity",
   "metadata": {},
   "source": [
    "from flaml import AutoML\n",
    "from flaml import tune\n",
    "automl = AutoML()\n",
    "automl.add_learner(\"rfr\",RandomForestRegressor )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-token",
   "metadata": {},
   "source": [
    "automl_settings = {\n",
    "    \"time_budget\": 1000,  # in seconds\n",
    "    \"metric\": 'rmse',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"california.log\",\n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train.drop(['Lab1'], axis=1), y_train=y_train,**automl_settings,estimator_list=[\"rfr\"])\n",
    "pred=automl.predict(X_test.drop(['Lab1'], axis=1))\n",
    "R2=round(sm.r2_score(y_test, pred), 2)\n",
    "r=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "RMSE=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y),2)\n",
    "print(r,R2,RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-cabinet",
   "metadata": {},
   "source": [
    "#  NO2 DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=NO2_Data[['Net Signal','Lab1','Temp','RH','Month','Day_of_week','Hour','Ref_O3']]#'Ref_O3'\n",
    "y=NO2_Data['Ref']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "#len(X_test)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-threshold",
   "metadata": {},
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 200,  # in seconds\n",
    "    \"metric\": 'rmse',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"california.log\",\n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train.drop(['Lab1'], axis=1), y_train=y_train,**automl_settings,estimator_list=[\"xgboost\"])\n",
    "pred=automl.predict(X_test.drop(['Lab1'], axis=1))\n",
    "R2=round(sm.r2_score(y_test, pred), 2)\n",
    "r=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "RMSE=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y),2)\n",
    "print(r,R2,RMSE)\n",
    "# Predict\n",
    "#print(automl.predict(X_test))\n",
    "# Print the best model\n",
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-powder",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel':  ['rbf', 'poly', 'sigmoid']} \n",
    "  \n",
    "grid = GridSearchCV(SVR(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train.drop(['Lab1'], axis=1), y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-winning",
   "metadata": {},
   "source": [
    "# O3 DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import sklearn.metrics as sm\n",
    "import matplotlib.pyplot as plt\n",
    "#,'Ref_CO','Ref_NO2','Ref_SO2'\n",
    "X=O3_Data[['Net Signal','Lab1','Temp','RH','Month','Day_of_week','Hour','Ref_NO2']]#,'Ref_NO2'\n",
    "y=O3_Data['Ref']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-freight",
   "metadata": {},
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 200,  # in seconds\n",
    "    \"metric\": 'rmse',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"california.log\",\n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train.drop(['Lab1'], axis=1), y_train=y_train,**automl_settings,estimator_list=[\"xgboost\"])\n",
    "pred=automl.predict(X_test.drop(['Lab1'], axis=1))\n",
    "R2=round(sm.r2_score(y_test, pred), 2)\n",
    "r=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "RMSE=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y),2)\n",
    "print(r,R2,RMSE)\n",
    "# Predict\n",
    "#print(automl.predict(X_test))\n",
    "# Print the best model\n",
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel':  ['rbf', 'poly', 'sigmoid']} \n",
    "  \n",
    "grid = GridSearchCV(SVR(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train.drop(['Lab1'], axis=1), y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-romance",
   "metadata": {},
   "source": [
    "# SO2 DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Ref=pd.read_csv('Ref.csv')\n",
    "Ref[\"CO\"] = 1000 * Ref[\"CO\"]\n",
    "Ref['Date'] = pd.to_datetime(Ref['Date_Time'])\n",
    "Ref=Ref.set_index('Date')\n",
    "Ref.drop('Date_Time',axis = 1, inplace = True)\n",
    "Ref=Ref.resample('5min').mean()\n",
    "Ref=Ref[76463:137376]\n",
    "Ref_CO=Ref['CO'].to_list()\n",
    "Ref_NO2=Ref['NO2'].to_list()\n",
    "Ref_SO2=Ref['SO2'].to_list()\n",
    "Ref_O3=Ref['O3'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = pd.read_csv('Conc_SO2.txt', header = None,low_memory=False)\n",
    "data.columns=['Lab2','Temp','RH','Time','Ref']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_SO2=data\n",
    "Data_so2=data\n",
    "#signal=np.array(WE)-np.array(AE)\n",
    "#Data_SO2['Net Signal']=signal\n",
    "Data_SO2['Month']=Data_SO2.index.month\n",
    "Data_SO2['Day_of_week']=Data_SO2.index.dayofweek\n",
    "Data_SO2['Day']=Data_SO2.index.day\n",
    "Data_SO2['Hour']=Data_SO2.index.hour\n",
    "SO2_Data=Data_SO2\n",
    "SO2_Data=SO2_Data.resample('5min').mean()\n",
    "SO2_Data=SO2_Data[(SO2_Data[SO2_Data.columns] >= 0).all(axis=1)]\n",
    "SO2_Data=SO2_Data.dropna() \n",
    "data = pd.read_csv('SO2.txt', header = None,low_memory=False)\n",
    "data.columns=['WE','AE','Temp','RH','Time']\n",
    "Time=data['Time'].to_list()\n",
    "time=[]\n",
    "for i in range(len(Time)):\n",
    "    time.append(float(abs(Time[i])))\n",
    "Time=np.array(time)\n",
    "Date=pd.to_datetime(Time-719529,unit='d').round('s')\n",
    "data['Date'] = Date.tolist()\n",
    "data=data.set_index('Date')\n",
    "data.drop('Time',axis = 1, inplace = True)\n",
    "data=data.resample('5min').mean()\n",
    "Data_SO2=data\n",
    "Data_SO2['Ref']=Ref_SO2\n",
    "WE=Data_SO2['WE'].to_list()\n",
    "AE=Data_SO2['AE'].to_list()\n",
    "signal=np.array(WE)-np.array(AE)\n",
    "Data_SO2['Lab2']=Data_so2['Lab2'].to_list()\n",
    "Data_SO2['Net Signal']=signal\n",
    "Data_SO2['Month']=Data_SO2.index.month\n",
    "Data_SO2['Day_of_week']=Data_SO2.index.dayofweek\n",
    "Data_SO2['Day']=Data_SO2.index.day\n",
    "Data_SO2['Hour']=Data_SO2.index.hour\n",
    "SO2_Data=Data_SO2\n",
    "SO2_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "SO2_Data=SO2_Data[(SO2_Data[SO2_Data.columns] >= 0).all(axis=1)]\n",
    "SO2_Data=SO2_Data.dropna()\n",
    "SO2_Data=SO2_Data.resample('h').mean()\n",
    "SO2_Data=SO2_Data.dropna()\n",
    "SO2_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import sklearn.metrics as sm\n",
    "import matplotlib.pyplot as plt\n",
    "#'Ref_CO','Ref_NO2','Ref_O3',\n",
    "X=SO2_Data[['Net Signal','Lab2','Temp','RH','Month','Day_of_week','Hour']]\n",
    "y=SO2_Data['Ref']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-ending",
   "metadata": {},
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 200,  # in seconds\n",
    "    \"metric\": 'rmse',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"california.log\",\n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train.drop(['Lab2'], axis=1), y_train=y_train,**automl_settings,estimator_list=[\"xgboost\"])\n",
    "pred=automl.predict(X_test.drop(['Lab2'], axis=1))\n",
    "R2=round(sm.r2_score(y_test, pred), 2)\n",
    "r=round(np.corrcoef(y_test, pred)[0, 1],2)\n",
    "RMSE=round(np.sqrt(sm.mean_squared_error(y_test, pred))/np.mean(y),2)\n",
    "print(r,R2,RMSE)\n",
    "# Predict\n",
    "#print(automl.predict(X_test))\n",
    "# Print the best model\n",
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-carolina",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel':  ['rbf', 'poly', 'sigmoid']} \n",
    "  \n",
    "grid = GridSearchCV(SVR(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train.drop(['Lab2'], axis=1), y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
